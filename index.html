<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />










  <meta name="baidu-site-verification" content="i0w0IGpafr" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="HJY的装逼小站">
<meta property="og:type" content="website">
<meta property="og:title" content="HJY">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="HJY">
<meta property="og:description" content="HJY的装逼小站">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HJY">
<meta name="twitter:description" content="HJY的装逼小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'HR62QHMRVP',
      apiKey: '5003cc57039452aa0e152bdb9198ed17',
      indexName: 'dev_NAME',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>HJY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HJY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">昨夜西风凋碧树，独上高楼望尽天涯路。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/30/算法学习二/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/30/算法学习二/" itemprop="url">算法学习二</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-30T09:25:47+08:00">
                2019-04-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这是算法学习的第二篇博客，本文将聚焦于图搜索相关的算法。</p>
<h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><p>所谓的图(Graph)由节点和边构成，节点代表变量，边表示相互关系，通常具有一定的权重。图的搜索算法可以解决一些基本的问题，比如最短路径问题。</p>
<h2 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a>广度优先搜索</h2><p>广度优先搜索的特征从起点开始，由近及远进行广泛地搜索。下面我们定义一个图(如下图)，这是个无向图，我们从某个节点出发分别进行广度优先搜索和深度优先搜索。<img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/BFS_DFS.png" alt=""><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">"A"</span>: [<span class="string">"B"</span>, <span class="string">"C"</span>],</span><br><span class="line">    <span class="string">"B"</span>: [<span class="string">"A"</span>, <span class="string">"C"</span>, <span class="string">"D"</span>],</span><br><span class="line">    <span class="string">"C"</span>: [<span class="string">"A"</span>, <span class="string">"B"</span>, <span class="string">"D"</span>, <span class="string">"E"</span>], </span><br><span class="line">    <span class="string">"D"</span>: [<span class="string">"B"</span>, <span class="string">"C"</span>, <span class="string">"E"</span>, <span class="string">"F"</span>],</span><br><span class="line">    <span class="string">"E"</span>: [<span class="string">"C"</span>, <span class="string">"D"</span>],</span><br><span class="line">    <span class="string">"F"</span>: [<span class="string">"D"</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 广度优先搜索</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BFS</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    queue = []</span><br><span class="line">    queue.append(s)</span><br><span class="line">    seen = set()</span><br><span class="line">    seen.add(s)</span><br><span class="line">    <span class="comment"># parent = &#123;s: None&#125;</span></span><br><span class="line">    <span class="keyword">while</span>(len(queue) &gt; <span class="number">0</span>):</span><br><span class="line">        vertex = queue.pop(<span class="number">0</span>)</span><br><span class="line">        nodes = graph[vertex]</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                queue.append(w)</span><br><span class="line">                seen.add(w)</span><br><span class="line">                <span class="comment"># parent[w] = vertex</span></span><br><span class="line">        print(vertex)</span><br><span class="line">    <span class="comment"># return parent</span></span><br></pre></td></tr></table></figure></p>
<h2 id="深度优先搜索"><a href="#深度优先搜索" class="headerlink" title="深度优先搜索"></a>深度优先搜索</h2><p>深度优先搜索和广度有限搜索一样，都是对图进行搜索的算法，目的都是从起点开始到达指定顶点(终点)。深度优先搜索会沿着一条路径不断往下搜索直到不能再继续为止，然后再折返，开始搜索下一条候补路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 深度优先搜索</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DFS</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    stack = []</span><br><span class="line">    stack.append(s)</span><br><span class="line">    seen = set()</span><br><span class="line">    seen.add(s)</span><br><span class="line">    <span class="keyword">while</span>(len(stack) &gt; <span class="number">0</span>):</span><br><span class="line">        vertex = stack.pop()</span><br><span class="line">        nodes = graph[vertex]</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                stack.append(w)</span><br><span class="line">                seen.add(w)</span><br><span class="line">        print(vertex)</span><br></pre></td></tr></table></figure>
<h1 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h1><p>下面我们看一些求最短路径的算法，贝尔曼-福特算法，Dijkstra算法，还有A-star算法。求下面的图 $A$ 到其它节点的最短路径。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/graph_with_weight.png" alt=""></p>
<h2 id="贝尔曼-福特算法-Bellman-ford"><a href="#贝尔曼-福特算法-Bellman-ford" class="headerlink" title="贝尔曼-福特算法(Bellman-ford)"></a>贝尔曼-福特算法(Bellman-ford)</h2><p>贝尔曼-福特算法是求最短路的一种算法，该算法是以松弛操作为基础，集估计的最短路径值逐渐被更加精确的值代替，直至得到最优解。该算法的缺点是时间复杂度较高 $O(|V||E|)$，其中 $|V|$ 代表节点数量，$|E|$代表边的数量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getEdges</span><span class="params">(G)</span>:</span></span><br><span class="line">     <span class="string">""" 输入图G，返回其边与端点的列表 """</span></span><br><span class="line">     v1 = []     <span class="comment"># 出发点         </span></span><br><span class="line">     v2 = []     <span class="comment"># 对应的相邻到达点</span></span><br><span class="line">     w  = []     <span class="comment"># 顶点v1到顶点v2的边的权值</span></span><br><span class="line">     <span class="keyword">for</span> i <span class="keyword">in</span> G:</span><br><span class="line">         <span class="keyword">for</span> j <span class="keyword">in</span> G[i]:</span><br><span class="line">             <span class="keyword">if</span> G[i][j] != <span class="number">0</span>:</span><br><span class="line">                 w.append(G[i][j])</span><br><span class="line">                 v1.append(i)</span><br><span class="line">                 v2.append(j)</span><br><span class="line">     <span class="keyword">return</span> v1,v2,w</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CycleError</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Bellman_Ford</span><span class="params">(G, s)</span>:</span></span><br><span class="line">    v1,v2,w = getEdges(G)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化源点与所有点之间的最短距离</span></span><br><span class="line">    distance = dict((k, math.inf) <span class="keyword">for</span> k <span class="keyword">in</span> G.keys())</span><br><span class="line">    distance[s] = <span class="number">0</span></span><br><span class="line">    parent = &#123;s: <span class="keyword">None</span>&#125;</span><br><span class="line">    <span class="comment"># 核心算法</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(len(G)<span class="number">-1</span>):   <span class="comment"># 循环 n-1轮</span></span><br><span class="line">        check = <span class="number">0</span>           <span class="comment"># 用于标记本轮松弛中distance是否发生更新</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):     <span class="comment"># 对每条边进行一次松弛操作</span></span><br><span class="line">            <span class="keyword">if</span> distance[v1[i]] + w[i] &lt; distance[v2[i]]:</span><br><span class="line">                distance[v2[i]] = distance[v1[i]] + w[i]</span><br><span class="line">                check = <span class="number">1</span></span><br><span class="line">                parent[v2[i]] = v1[i]</span><br><span class="line">        <span class="keyword">if</span> check == <span class="number">0</span>: <span class="keyword">break</span></span><br><span class="line">     </span><br><span class="line">     <span class="comment"># 检测负权回路</span></span><br><span class="line">     <span class="comment"># 如果在 n-1 次松弛之后，最短路径依然发生变化，则该图必然存在负权回路</span></span><br><span class="line">    flag = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):             <span class="comment"># 对每条边再尝试进行一次松弛操作</span></span><br><span class="line">        <span class="keyword">if</span> distance[v1[i]] + w[i] &lt; distance[v2[i]]: </span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span>:</span><br><span class="line"> <span class="comment">#         raise CycleError()</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> distance, parent</span><br></pre></td></tr></table></figure></p>
<h2 id="Dijkstra算法"><a href="#Dijkstra算法" class="headerlink" title="Dijkstra算法"></a>Dijkstra算法</h2><p>Dijkstra算法可以看作是广度优先搜索在有权图上的推广，<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Dijkstra_Animation.gif?token=ADYM746NFLENH4KLL5QSKXK4ZD7OU" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">"A"</span>: &#123;<span class="string">"B"</span>: <span class="number">5</span>, <span class="string">"C"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">    <span class="string">"B"</span>: &#123;<span class="string">"A"</span>: <span class="number">5</span>, <span class="string">"C"</span>: <span class="number">2</span>, <span class="string">"D"</span>: <span class="number">1</span>&#125;,</span><br><span class="line">    <span class="string">"C"</span>: &#123;<span class="string">"A"</span>: <span class="number">1</span>, <span class="string">"B"</span>: <span class="number">2</span>, <span class="string">"D"</span>: <span class="number">4</span>, <span class="string">"E"</span>: <span class="number">8</span>&#125;, </span><br><span class="line">    <span class="string">"D"</span>: &#123;<span class="string">"B"</span>: <span class="number">1</span>, <span class="string">"C"</span>: <span class="number">4</span>, <span class="string">"E"</span>: <span class="number">3</span>, <span class="string">"F"</span>: <span class="number">6</span>&#125;,</span><br><span class="line">    <span class="string">"E"</span>: &#123;<span class="string">"C"</span>: <span class="number">8</span>, <span class="string">"D"</span>: <span class="number">3</span>&#125;,</span><br><span class="line">    <span class="string">"F"</span>: &#123;<span class="string">"D"</span>: <span class="number">6</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_distance</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    distance = &#123;s: <span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">for</span> vertex <span class="keyword">in</span> graph:</span><br><span class="line">        <span class="keyword">if</span> vertex != s:</span><br><span class="line">            distance[vertex] = math.inf</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dijkstra</span><span class="params">(graph, s)</span>:</span></span><br><span class="line">    pqueue = []</span><br><span class="line">    heapq.heappush(pqueue, (<span class="number">0</span>, s))</span><br><span class="line">    seen = set()</span><br><span class="line">    seen.add(s)</span><br><span class="line">    parent = &#123;s: <span class="keyword">None</span>&#125;</span><br><span class="line"></span><br><span class="line">    distance = init_distance(graph, s)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(len(pqueue) &gt; <span class="number">0</span>):</span><br><span class="line">        pair = heapq.heappop(pqueue)</span><br><span class="line">        distance = pair[<span class="number">0</span>]</span><br><span class="line">        vertex = pair[<span class="number">1</span>]</span><br><span class="line">        seen.add(vertex)</span><br><span class="line"></span><br><span class="line">        nodes = graph[vertex].keys()</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> seen:</span><br><span class="line">                <span class="keyword">if</span> distance + graph[vertex][w] &lt; distance[w]:</span><br><span class="line">                    heapq.heappush(pqueue, (distance + graph[vertex][w], w))</span><br><span class="line">                    parent[w] = vertex</span><br><span class="line">                    distance[w] = distance + graph[vertex][w]</span><br><span class="line">    <span class="keyword">return</span> parent, distance</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    parent, distance= dijkstra(graph, <span class="string">"A"</span>)</span><br><span class="line">    print(parent, distance)</span><br><span class="line"></span><br><span class="line">    v = <span class="string">"B"</span></span><br><span class="line">    <span class="keyword">while</span> v != <span class="keyword">None</span>:</span><br><span class="line">        print(v)</span><br><span class="line">        v = parent[v]</span><br></pre></td></tr></table></figure>
<p>虽然Doijkstra算法和Bellman ford算法一样可以求解有向图中的最短路径问题，但是当图中有负数权重时，Dijkstar算法无法得到正确的答案。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/27/算法学习一/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/27/算法学习一/" itemprop="url">算法学习一</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-27T20:50:49+08:00">
                2019-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近写论文写不动，然后又不知道干点啥来荒废时间，正好看到了一本挺有意思的算法书《我的第一本算法书》，准备读一读，结合一些开源的程序，学习一下，并实现一下。本文的主要内容来自于《我的第一本算法书》和维基百科。</p>
<h1 id="算法的时间复杂度"><a href="#算法的时间复杂度" class="headerlink" title="算法的时间复杂度"></a>算法的时间复杂度</h1><p>算法的时间复杂度通常用 $O$ 符号来表示，它的意思是忽略重要项以外的内容，比如说 $O(n^2)$ 表示算法的运行时间最长为 $n^2$ 的常数倍。</p>
<ol>
<li>如果链表中的数据量为 $n$，我们从链表头部线性查找，如果目标在链表最后，需要的时间为 $o(n)$。链表中添加数据只需要更改两个指针的指向，所以耗费的时间与 $n$ 无关。如果到达了添加(删除)数据的位置，那么添加(删除)只需要 $O(1)$ 的时间。</li>
<li>数组与链表不同，数据是通过下表确定内存地址的，所以访问 $n$ 个数据的某个数据仅为恒定的 $O(1)$ 时间。若向数组中添加数据，则需要将目标位置的数据之后的数据一个个移开，如果在头部添加数据则需要 $O(n)$ 时间，删除同理。</li>
<li>在哈希表中，可以采用哈希函数快速访问到数组中的目标数据，如果发生哈希冲突，我们就使用链表进行存储。</li>
<li>在堆中，假设有 $n$ 个节点，根据堆的特点我们可以知道堆的高度为 $log_2\ n$ (类似于等比数列求和)，那么对堆进行排序时间复杂度为 $O(log\ n)$。</li>
<li>二叉搜索树的比较次数取决于树的高度，如果节点为 $n$，树的的形状又较为均衡的话，比较的大小和移动的次数最多为 $log_2\ n$， 因此时间复杂度为 $O(log\ n)$。</li>
</ol>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p>所谓排序就是讲数据按照升序的方式调整顺寻，下面将介绍几种常见的排序算法。</p>
<h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><p>冒泡算法重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。冒泡排序对 $n$ 个数据的排序的时间复杂度 $O(n^2)$ 。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sorted</span><span class="params">(iterable)</span>:</span></span><br><span class="line">    new_list = list(iterable)</span><br><span class="line">    list_len = len(new_list)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(list_len - <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(list_len - <span class="number">1</span>, i, <span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> new_list[j] &lt; new_list[j - <span class="number">1</span>]:</span><br><span class="line">                new_list[j], new_list[j - <span class="number">1</span>] = new_list[j - <span class="number">1</span>], new_list[j]</span><br><span class="line">    <span class="keyword">return</span> new_list</span><br><span class="line">    </span><br><span class="line">testlist = [<span class="number">27</span>, <span class="number">33</span>, <span class="number">28</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">26</span>, <span class="number">13</span>, <span class="number">35</span>, <span class="number">8</span>, <span class="number">14</span>]</span><br><span class="line">print(<span class="string">'sorted:'</span>, bubble_sorted(testlist))</span><br></pre></td></tr></table></figure></p>
<h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><p>选择排序是一种简单直接的排序算法。它的工作原理如下：首先找到未排序列中最小的元素，存放在<br>排序序列的其实位置，然后再从剩余未排序元素中寻找最小元素，然后放到一排序序列的末尾，一次类推，知道所有元素排序完毕，如下图所示。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Selection-Sort-Animation.gif" width="10%" height="10%"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selection_sort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)):</span><br><span class="line">        minIndex=i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,len(arr)):</span><br><span class="line">            <span class="keyword">if</span> arr[minIndex]&gt;arr[j]:</span><br><span class="line">                minIndex=j</span><br><span class="line">        <span class="keyword">if</span> i==minIndex:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arr[i],arr[minIndex]=arr[minIndex],arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    testlist = [<span class="number">17</span>, <span class="number">23</span>, <span class="number">20</span>, <span class="number">14</span>, <span class="number">12</span>, <span class="number">25</span>, <span class="number">1</span>, <span class="number">20</span>, <span class="number">81</span>, <span class="number">14</span>, <span class="number">11</span>, <span class="number">12</span>]</span><br><span class="line">    print(selection_sort(testlist))</span><br></pre></td></tr></table></figure></p>
<h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><p>插入排序的工作原理是通过构建有序序列，对于为排序数据，在一排序序列中从后向前扫描，找到相应位置并插入，如下图所示。算法的时间复杂度为 $O(n^2)$。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Insertion-sort-example-300px.gif" alt=""><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertion_sort</span><span class="params">(lst)</span>:</span></span><br><span class="line">    n=len(lst)</span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">1</span>: <span class="keyword">return</span> lst</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> lst[j]&lt;lst[j<span class="number">-1</span>]: </span><br><span class="line">                lst[j],lst[j<span class="number">-1</span>]=lst[j<span class="number">-1</span>],lst[j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> lst</span><br></pre></td></tr></table></figure></p>
<h2 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h2><p>堆排序是指利用对这种数据结构设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子节点的键值或索引总是小于(或者大于)它的父节点。堆排序的顺序是将元素进行重排，以匹配堆的条件。下图中排序过程之前简单地绘出了堆树的结构。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/Sorting_heapsort_anim.gif" alt=""><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sift_down</span><span class="params">(start, end)</span>:</span></span><br><span class="line">        <span class="string">"""最大堆调整"""</span></span><br><span class="line">        root = start</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            child = <span class="number">2</span> * root + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> child &gt; end:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> child + <span class="number">1</span> &lt;= end <span class="keyword">and</span> lst[child] &lt; lst[child + <span class="number">1</span>]:</span><br><span class="line">                child += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> lst[root] &lt; lst[child]:</span><br><span class="line">                lst[root], lst[child] = lst[child], lst[root]</span><br><span class="line">                root = child</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建最大堆</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> range((len(lst) - <span class="number">2</span>) // <span class="number">2</span>, <span class="number">-1</span>, <span class="number">-1</span>): <span class="comment">## 从最后一个子节点出开始进行最## 大堆调整</span></span><br><span class="line">        sift_down(start, len(lst) - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 堆排序</span></span><br><span class="line">    <span class="keyword">for</span> end <span class="keyword">in</span> range(len(lst) - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        lst[<span class="number">0</span>], lst[end] = lst[end], lst[<span class="number">0</span>]</span><br><span class="line">        sift_down(<span class="number">0</span>, end - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    l = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    print(heap_sort(l))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><p>归并排序会将序列分成长度相同的来那个子序列，当无法继续往下分时(也就是每个子序列只有一个数据时)，就对子序列归并。归并指的是把来那个排好序的子序列合并成一个有序序列。该操作会一直进行，知道所有子序列都归并为一个整体为止。归并排序的算法时间复杂度为 $O(nlog\ n)$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Recursively implementation of Merge Sort</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">while</span> left <span class="keyword">and</span> right:</span><br><span class="line">        <span class="keyword">if</span> left[<span class="number">0</span>] &lt;= right[<span class="number">0</span>]:</span><br><span class="line">            result.append(left.pop(<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(right.pop(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">if</span> left:</span><br><span class="line">        result += left</span><br><span class="line">    <span class="keyword">if</span> right:</span><br><span class="line">        result += right</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(L)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(L) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># When D&amp;C to 1 element, just return it</span></span><br><span class="line">        <span class="keyword">return</span> L</span><br><span class="line">    mid = len(L) // <span class="number">2</span></span><br><span class="line">    left = L[:mid]</span><br><span class="line">    right = L[mid:]</span><br><span class="line"></span><br><span class="line">    left = merge_sort(left)</span><br><span class="line">    right = merge_sort(right)</span><br><span class="line">    <span class="comment"># conquer sub-problem recursively</span></span><br><span class="line">    <span class="keyword">return</span> merge(left, right)</span><br><span class="line">    <span class="comment"># return the answer of sub-problem</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    test = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3.6</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">25</span>, <span class="number">-34</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    print(<span class="string">"original:"</span>, test)</span><br><span class="line">    print(<span class="string">"Sorted:"</span>, merge_sort(test))</span><br></pre></td></tr></table></figure>
<h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h2><p>快速排序是在数列中挑选一个元素作为基准(pivot)，然后将数列按照“比基准小的数”和“比基准大的数”分为两类，然后进行使用快速排序进行递归排序“比基准小的数”和比“基准大的数”。快速排序的算法平均时间复杂度为 $O(nlog\ n)$，因为其内部循环可以再大部分框架上很有效率的完成，所以称之为快速算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(lst)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(lst) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> lst</span><br><span class="line">    less = []</span><br><span class="line">    greater = []</span><br><span class="line">    pivot = lst.pop()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> lst:</span><br><span class="line">        <span class="keyword">if</span> item &lt; pivot:</span><br><span class="line">            less.append(item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            greater.append(item)</span><br><span class="line">    lst.append(pivot)</span><br><span class="line">    <span class="keyword">return</span> quick_sort(less) + [pivot] + quick_sort(greater)</span><br></pre></td></tr></table></figure>
<h1 id="P问题，NP问题，NP-Complete问题，NP困难问题"><a href="#P问题，NP问题，NP-Complete问题，NP困难问题" class="headerlink" title="P问题，NP问题，NP Complete问题，NP困难问题"></a>P问题，NP问题，NP Complete问题，NP困难问题</h1><p>这部分是偶然看到的，和这里关系不大。<br>P问题是指在多项式时间内可以解决的问题；NP问题是指在多项式时间内可以判断的问题；NP Complete是指在多项式时间内判断，不能在多项式时间内解决的问题。NP困难问题是指如果所有的NP问题都可以在多项式时间内归约到某个问题。<br>具体上面问题的分布情况可以参照下面的图，目前普遍认为 $P \neq NP$，如果$P \neq NP$，那么这个世界确实会很不一样，人人都能成为莫扎特系列。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/Algorithms/800px-P_np_np-complete_np-hard.svg.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/23/深度学习医学图像方向大佬/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/23/深度学习医学图像方向大佬/" itemprop="url">深度学习医学图像方向大佬</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-23T14:48:42+08:00">
                2019-04-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工作/" itemprop="url" rel="index">
                    <span itemprop="name">工作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Demetri-Terzopoulos"><a href="#Demetri-Terzopoulos" class="headerlink" title="Demetri Terzopoulos"></a>Demetri Terzopoulos</h1><p>就职于UCLA(University of California, Los Angeles )，<a href="http://web.cs.ucla.edu/~dt/" target="_blank" rel="noopener">个人主页</a>，<a href="http://www.magix.ucla.edu/index.html" target="_blank" rel="noopener">实验室主页(UCLA Computer Graphics &amp; Vision Laboratory)</a>。主要研究方向应该是计算机图像学方向，主要采用几何的方法研究图像。</p>
<h1 id="Daniel-Rueckert"><a href="#Daniel-Rueckert" class="headerlink" title="Daniel Rueckert"></a>Daniel Rueckert</h1><p>就职于Imperial College London，<a href="http://wp.doc.ic.ac.uk/dr/" target="_blank" rel="noopener">个人主页</a>，<a href="https://biomedia.doc.ic.ac.uk/" target="_blank" rel="noopener">实验室主页(BioMedIA)</a>。该课题组规模较大，研究范围非常的广，涉及到图像的重建、分割。</p>
<h1 id="Milan-Sonka"><a href="#Milan-Sonka" class="headerlink" title="Milan Sonka"></a>Milan Sonka</h1><p>就职于University of lowa，<a href="http://user.engineering.uiowa.edu/~sonka/research.php" target="_blank" rel="noopener">个人主页</a>。相对应的课题组有关于深度学习与图论方法的文章，可以看一看。</p>
<h1 id="Dimitris-N-Metaxas"><a href="#Dimitris-N-Metaxas" class="headerlink" title="Dimitris N. Metaxas"></a>Dimitris N. Metaxas</h1><p>就职于Rutgers University，和Ian Goodfellow有联系，self-attention gan文章中有他的名字。<a href="https://www.cs.rutgers.edu/~dnm/" target="_blank" rel="noopener">个人主页</a>。</p>
<h1 id="Paul-Suetens"><a href="#Paul-Suetens" class="headerlink" title="Paul Suetens"></a>Paul Suetens</h1><p>就职于 KU Leuven ESAT/PSI，他们做了许多的关于中风方面的工作，其中ischemic stroke lesion becnmark 有他的参与。</p>
<h1 id="Dinggang-Shen"><a href="#Dinggang-Shen" class="headerlink" title="Dinggang Shen"></a>Dinggang Shen</h1><p><a href="https://www.med.unc.edu/bric/ideagroup/" target="_blank" rel="noopener">实验室主页</a></p>
<h1 id="Simon-Keith-Warfield"><a href="#Simon-Keith-Warfield" class="headerlink" title="Simon Keith Warfield"></a>Simon Keith Warfield</h1><p>就职于Harvard Medical School，<a href="http://crl.med.harvard.edu/" target="_blank" rel="noopener">实验室主页</a>。</p>
<h1 id="Antonio-Criminisi"><a href="#Antonio-Criminisi" class="headerlink" title="Antonio Criminisi"></a>Antonio Criminisi</h1><p>就职于微软，<a href="https://www.microsoft.com/en-us/research/people/antcrim/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fantcrim%2F" target="_blank" rel="noopener">个人主页</a>，用到的Autofocus layer就是对应组的工作，跟Konstantinos Kamnitsas有联系。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/07/文献整理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/07/文献整理/" itemprop="url">文献整理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-07T16:24:07+08:00">
                2019-04-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工作/" itemprop="url" rel="index">
                    <span itemprop="name">工作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文整理了最近看的论文，主要方向是脑肿瘤分割，由论文链接，论文出发点，以及论文的创新点构成。</p>
<h1 id="Densely-Connected-Convolutional-Networks"><a href="#Densely-Connected-Convolutional-Networks" class="headerlink" title="Densely Connected Convolutional Networks"></a>Densely Connected Convolutional Networks</h1><p><a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">Huang G, Liu Z, Van Der Maaten L, et al. Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4700-4708.</a></p>
<h2 id="Standpoint"><a href="#Standpoint" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output.</p>
<h2 id="Innovation"><a href="#Innovation" class="headerlink" title="Innovation"></a>Innovation</h2><p>Design densely connected convolutional networks with shorter connections.</p>
<h1 id="DRINet-for-Medical-Image-Segmenation"><a href="#DRINet-for-Medical-Image-Segmenation" class="headerlink" title="DRINet for Medical Image Segmenation"></a>DRINet for Medical Image Segmenation</h1><p><a href="https://ieeexplore.ieee.org/abstract/document/8357580" target="_blank" rel="noopener">Chen L, Bentley P, Mori K, et al. DRINet for medical image segmentation[J]. IEEE transactions on medical imaging, 2018, 37(11): 2453-2462.</a></p>
<h2 id="Standpoint-1"><a href="#Standpoint-1" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>These convolution layers learn representative features of input images and construct segmentation based on the features. However, the features learned by standard convolution layers are not distinctive when the differences among different categoriesare subtle in terms of intensity, location,shape, and size.</p>
<h2 id="Innovation-1"><a href="#Innovation-1" class="headerlink" title="Innovation"></a>Innovation</h2><p>A novel combination of the dense connections with the inception structure to address segmentation problems. The use of dense connection blocks, residual inception blocks, and the unpooling blocks achieve high performance while maintaining computational efficiency;</p>
<h1 id="Autofocus-Layer-for-Semantic-Segmentation"><a href="#Autofocus-Layer-for-Semantic-Segmentation" class="headerlink" title="Autofocus Layer for Semantic Segmentation"></a>Autofocus Layer for Semantic Segmentation</h1><p><a href="https://arxiv.org/pdf/1805.08403.pdf" target="_blank" rel="noopener">Qin Y, Kamnitsas K, Ancha S, et al. Autofocus layer for semantic segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018: 603-611.</a></p>
<h2 id="Standpoint-2"><a href="#Standpoint-2" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>For high performance, segmentation algorithms are required to use multi-scale context [6], while still aiming for pixel-level accuracy. Multi-scale processing provides detailed cues, such as texture information of a structure, combined with contextual information, such as a structure’s surroundings, which can facilitate decisions that are ambiguous when based only on local context.</p>
<h2 id="Innovation-2"><a href="#Innovation-2" class="headerlink" title="Innovation"></a>Innovation</h2><p>They propose the autofocus convolutional layer for semantic segmentation with the objective of enhancing the capabilities of neural networks for multi-scale processing. Autofocus layers adaptively change the size of the e_ective receptive field based on the processed context to generate more powerful features. This is achieved by parallelising mul-tiple convolutional layers with di_erent dilation rates, combined by an attention mechanism that learns to focus on the optimal scales driven by context.</p>
<h1 id="Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks"><a href="#Efficient-Brain-Tumor-Segmentation-with-Multiscale-Two-Pathway-Group-Conventional-Neural-Networks" class="headerlink" title="Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks"></a>Efficient Brain Tumor Segmentation with Multiscale Two-Pathway-Group Conventional Neural Networks</h1><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481481" target="_blank" rel="noopener">Razzak I, Imran M, Xu G. Efficient brain tumor segmentation with multiscale two-pathway-group conventional neural networks[J]. IEEE journal of biomedical and health informatics, 2018.</a></p>
<h2 id="Standpoint-3"><a href="#Standpoint-3" class="headerlink" title="Standpoint"></a>Standpoint</h2><ol>
<li><p>Manual segmentation of the brain tumors for cancerdiagnosis from MRI images is a difficult, tedious and timeconsuming task. The accuracy and the robustness of brain tumor segmentation, therefore, are crucial for the diagnosis, treatment planning, and treatment outcome evaluation.</p>
</li>
<li><p>Traditional methods of Deep learning such as Convolutional Neural Networks require a large amount of annotated data to learn from, which is often difficult to obtain in the medical domain.</p>
</li>
</ol>
<h2 id="Innovation-3"><a href="#Innovation-3" class="headerlink" title="Innovation"></a>Innovation</h2><p>They describe a new model Two-Pathway-Group CNN architecture for brain tumor segmentation, which exploits local features and global contextual features simultaneously.</p>
<h1 id="Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation"><a href="#Efficient-Multi-scale-3D-CNN-with-Fully-Connected-CRF-for-Accurate-Brain-lesion-Segmentation" class="headerlink" title="Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation"></a>Efficient Multi-scale 3D CNN with Fully Connected CRF for Accurate Brain lesion Segmentation</h1><p><a href="https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841516X00084/1-s2.0-S1361841516301839/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFoaCXVzLWVhc3QtMSJHMEUCIQCsuiUnmXyD1We5Tahtd1Ldmgji9yslyjwGHfhjWGrTiQIgZI2%2BSICLI%2BYwirHiDv%2FTGDXrqzMMTAnO5VipOujh940q2gMIIxACGgwwNTkwMDM1NDY4NjUiDOhYw6AGmMFoYimUsiq3A%2FnJoakde5OPvuBW9NTk4RD1uQJfiKzq5%2FdL8VVSGt0uujA4qFZjyFNLFImg8WtHa8N72KURPf%2F%2FlECf7quq6thriQ0IWcKRggEmnVyrb5S75twqjs9lMB8wJAS42NwKBogUAnv7a%2FKHlyI8bYvJvCYZfvrlvFkwfoqPN0pvd9qRc22UwUp0osCTlucrynSxWlDakHV20ZOyw985%2FS8ERhfyMNmK%2B3poagUKTzXbwy1oA8CJ8njLfuV7uNiL2GXJrWnv4XD%2FrS7R%2BedMGzNCK%2Fel7pAff6%2B5Q6Mzd4%2FmtnA9UYvyGCJiY4qOlxib%2FG8oFexAZohS20ZIqgpWg4BUz%2FG5%2BqWxHxPB6htlq503UBMvXYqp86NIZ7%2B2tbZ7bKWr7Lj27885H0t6YEQjB4Bec0wVQLnEfpo4vI2b0zxlItdgpALLT9XuYog9rBvCa6G943RX4qA5wO0MtkZl3mcTqgDpImX7qsYnhY9cZWWgOqxYiNX0ksUDoggLES6QI9s1XVaKh4fd0bTQ%2BF9kBw8s%2BJ%2FaVU1TwFWWLJDHmMPwL6ZUV6bvMdmjPcG6aFz3lru8gPARpK0YlmQwu6Ol5QU6tAFf7vS%2B1BXojpfdrukDGETT2BJQlXwWYhY%2F4SH2PnmzSW%2BOWqFiVeuSGtpzWetonvYspUAAt9zO24zb0Ap2SSIzKn8Zd6qnzjEZzI8rLe3i9CmoZ%2BlfC41rZvNeYEqxWapay%2F8ygSZUDYTvHj93Vj4eFdu1uHVL5Tm2vFs8ukNDDlS6hdp3Zk3UaM1QfDkLksa8fEjCwFldyOdIcfhoykJHNM8%2FpdBmA%2Ffqz%2FBk7HaV8kgtL9Y%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYQ3ZV253X&amp;Expires=1554601073&amp;Signature=OeSwkuAFTu2MZ2agSyHzQz7OZww%3D&amp;hash=0185f4d47582fa2a2ee2c35cf986b0fd9e15d14bd40721c8e67816d7851da17e&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1361841516301839&amp;tid=spdf-b5e3157c-b347-43ad-bbd6-0d660c93b8f7&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client" target="_blank" rel="noopener">Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.</a></p>
<h2 id="Standpoint-4"><a href="#Standpoint-4" class="headerlink" title="Standpoint"></a>Standpoint</h2><p> The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules. It is thus highly non-trivial to delineate contu- sions, oedema and haemorrhages in TBI, or sub-components of brain tumours such as proliferating cells and necrotic core.</p>
<h2 id="Innovation-4"><a href="#Innovation-4" class="headerlink" title="Innovation"></a>Innovation</h2><p> They  propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. </p>
<h1 id="HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation"><a href="#HyperDense-Net-A-Hyper-densely-Connected-CNN-for-Multi-modal-Image-Segmentation" class="headerlink" title="HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation"></a>HyperDense-Net: A Hyper-densely Connected CNN for Multi-modal Image Segmentation</h1><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8515234" target="_blank" rel="noopener">Dolz J, Gopinath K, Yuan J, et al. HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation[J]. IEEE transactions on medical imaging, 2018.</a></p>
<h2 id="Standpoint-5"><a href="#Standpoint-5" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>Dense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks.</p>
<h2 id="Innovation-5"><a href="#Innovation-5" class="headerlink" title="Innovation"></a>Innovation</h2><p>They propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths.</p>
<h1 id="A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation"><a href="#A-Deep-Learning-model-integrating-FCNNs-and-CRFs-for-brain-tumor-segmentation" class="headerlink" title="A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation"></a>A Deep Learning model integrating FCNNs and CRFs for brain tumor segmentation</h1><p><a href="https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841517X0008X/1-s2.0-S136184151730141X/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIQCmFiL2ekwH7KF8z%2Fc0vWR0Ac9yL8K5oGv5DOeBI7VJhQIgfy%2FpbMeHw7IWu30Pc%2FGwfPGxvuI5Calk%2Bgjx2fm5U8wq2gMIJBACGgwwNTkwMDM1NDY4NjUiDIGTbcyCi60TQJ8PRyq3A1%2Fzz%2B3VHHOekK%2FJw6MU%2FZqrd9oySC4b6nKbDevYilRhqIjYFRKlF1Ij0YgzO2xl2qPCJA1Luoh3fIm4CfQomsuNh0vwUU4VcwwTOdRKW4Biycm5IxXEePAh2xuIUSBB%2B%2BRbOIwmmHKraKf8UaAlFLz%2FxDHEPqk%2Ft8WllncOm3fus26FVvSt6tBpAiUmIlWi%2B8a%2BiJ6GF61aZBjlsGbZhDHS%2BtsTXMdRysCnSdGTClkKbVshva2YJUU7dM%2BqzxrrGCTCDCFYq%2Fo%2FCszl%2BTV%2BperpIIltFrMZdVk1g%2FnAmD35O%2Bsgk1V4iQiYrdXAvCcNO1Vt7gmaTg8k4lZjXacSw52vrDW76YcU%2FOWq7BYkFB8v3CTeIH0pPvvDmLRbSOYt7HmYWMuSTR5AS5DgrJvY2al3UczqOK8rYSN4qcu5GdgNa7fzvQaouXF2SHQ%2FVj9sH8agALf0MbOzTOH43EadU5ATM8X3JYwWEh9bP7mPor3cQm1VHvDz0Eq9NtduHt2r9EYQ0nqR22AmBAfSYbaf1yz55k6bwUtqukP5IJm6BCeeaVbaz9zB0rVbAHdUCh3tgnqsds%2Fvlf4wy7%2Bl5QU6tAFpdYJnVeDFfg8QKDDpZ9fcsFs5bdMoGPRaU8hY495aNV4QleUmufJAirYtZvSZAQbZGelsALa1gT7OwuMDACZ76e3FyfsRjc9sgQIWXy73%2FvnbUIiSAH%2F0BUiE0Sfq%2FXB2gzShepFEjd1nIf9nrzmKl8TLiMxWQm%2F7txg8Y4ndrsBnq1YWoYn9nkg6MF4a5Hy6M4W2hBk%2FOq1MpN1%2Bh20l%2FhkH%2BUDkInb5ni4zsRTuPDTvgi0%3D&amp;AWSAccessKeyId=ASIAQ3PHCVTYRA73P2UO&amp;Expires=1554605840&amp;Signature=mupLWqHKaKQuDReHsSReahixCgc%3D&amp;hash=d7e362b71f1842d8657ac4a022fe9b558190b5ecd29082efd89e41cda056cd25&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S136184151730141X&amp;tid=spdf-ff9d6147-ba0b-4dfc-b397-32911281b48b&amp;sid=2a768add952a0346b77ac6a49311fd650ab7gxrqa&amp;type=client" target="_blank" rel="noopener">Zhao X, Wu Y, Song G, et al. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation[J]. Medical image analysis, 2018, 43: 98-111</a></p>
<h2 id="Standpoint-6"><a href="#Standpoint-6" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation.</p>
<h2 id="Innovation-6"><a href="#Innovation-6" class="headerlink" title="Innovation"></a>Innovation</h2><p>Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency.</p>
<h1 id="U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation"><a href="#U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation" class="headerlink" title="U-Net: Convolutional Networks for Biomedical Image Segmentation"></a>U-Net: Convolutional Networks for Biomedical Image Segmentation</h1><p><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="noopener">Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241.</a></p>
<h2 id="Standpoint-7"><a href="#Standpoint-7" class="headerlink" title="Standpoint"></a>Standpoint</h2><p>There is large consent that successful training of deep networks requires many thousand annotated training samples.</p>
<h2 id="Innovation-7"><a href="#Innovation-7" class="headerlink" title="Innovation"></a>Innovation</h2><p>In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently.</p>
<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p>This architecture is very useful in many medical image segmentation task, so is it the best architecture?</p>
<p>The novel architecture is not emphasized in this paper, but this paper propose U-Net that has been a popular network architecture.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/28/Brain-tumor-segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/28/Brain-tumor-segmentation/" itemprop="url">基于卷积神经网络的脑肿瘤分割</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-28T22:09:38+08:00">
                2019-02-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本人一直研究脑肿瘤分割，脑肿瘤分割对于患者的后续治疗以及对疾病的检测有着重要的意义，同时也是人工智能处理医学图像的重要方向之一。目前开源的代码都比较复杂，不适合入门研究，另外 Pytorch 作为一个容易上手的深度学习框架，具有很强的灵活性，适合新手或者是科研工作者，所以本文的代码将使用深度学习框架 Pytorch1.0 和 Python3.6 进行编程构建卷积神经网络来进行脑肿瘤分割。卷积神经网络不仅在自然图像而且在医学图像在内的其他图像都有着广泛地应用。另外，卷积神经网络广泛地应用于图像的分类，检测等计算机视觉任务中。</p>
<h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>我们这里使用 BraTs2015 的部分数据集，数据集可以从<a href="https://github.com/yaq007/Autofocus-Layer" target="_blank" rel="noopener">这里下载</a>，完整的BraTs2015 数据集可以在这里<a href="https://www.smir.ch/BRATS/Start2015" target="_blank" rel="noopener">注册下载</a>。</p>
<p>本文使用的数据集共有20例样本用于训练，54例样本用于测试(可自行调整)，每个样本中共有4个模态的数据和Mask和真值数据，其中4个模态分别为FLAIR， T1，T1c，T2。真值数据共有5个标签：</p>
<ul>
<li>label 1: necrosis</li>
<li>label 2: edema</li>
<li>label 3: non-enhacing tumor</li>
<li>label 4: enhancing tumor</li>
<li>label 0：everything else</li>
</ul>
<p>脑肿瘤分割主要有3个部分，Whole tumor， Tumor core， Enhance tumor。这3个部分的标签如下所示：</p>
<ul>
<li>Whole tumor: label 1, 2, 3, 4</li>
<li>Enhance tumor: label 4</li>
<li>Tumor core: 1, 3, 4</li>
</ul>
<p>BraTs2015 使用 Dice 作为评价指标，这个评价指标主要是衡量预测结果与真值之间重叠部分。 Dice 的公式计算如下：<br>$$ Dice = \frac{2 TP}{2TP + FP + FN} $$</p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>前面我们知道 BraTs 2015 共有4个模态的数据，下面我们介绍两个能够在程序中读取医学图像的包：SimpleITK 和 Nibabel。SimpleITK能够读取的格式更加多，具体可以参考 SimpleITK 的文档。</p>
<h3 id="SimpleITK"><a href="#SimpleITK" class="headerlink" title="SimpleITK"></a>SimpleITK</h3><p>SimpleITK 读取医学图像示例代码：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> SimpleITK as sitk</span><br><span class="line"><span class="built_in">image</span> = sitk.ReadImage(<span class="string">'image.nii'</span>)</span><br><span class="line"><span class="built_in">image</span> = sitk.GetArrayFromImage(<span class="built_in">image</span>)</span><br></pre></td></tr></table></figure></p>
<p>SimpleITK 读取的图片维度是通道优先的，所以图像的维度的第1位是医学图像的维数。另外我还使用到了 SimpleITK 将输出预测结果保存为医学图像格式，这部分代码如下：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">image</span> = sitk.GetImageFromArray(<span class="built_in">image</span>)</span><br><span class="line">sitk.WriteImage(<span class="built_in">image</span>, <span class="string">'image.mha'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="Nibabel"><a href="#Nibabel" class="headerlink" title="Nibabel"></a>Nibabel</h3><p>Nibabel 读取医学图像示例代码：<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nibabel as nib </span><br><span class="line"><span class="built_in">image</span> = nib.load(<span class="string">'image.nii.gz'</span>).get_fdata()</span><br><span class="line"><span class="built_in">image</span> = <span class="built_in">image</span>.transpse(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>不同于 SimpleITK， Nibabel 读取图像的维度的通道数位于最后 1 位，但是 Nibabel 将图像旋转了 $90^{\circ}$，可以使用上面代码的第三行旋转为一般维数分布方式。比如脑图中，如果不旋转变换转变 Nibabel 读取的方式，脑图就是横着的。</p>
<h3 id="3D-Slicer-可视化"><a href="#3D-Slicer-可视化" class="headerlink" title="3D Slicer 可视化"></a>3D Slicer 可视化</h3><p>SimpleITK 和 Nibabel 是可以在程序中读取医学图像的包，灵活性不强，另外不适合了解医学图像的基本特性，下面我们使用 3D Slicer 来可视化我们的医学图像数据。<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_axis.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_sagittal.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/FLAIR_coronal.png" alt=""></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_axis.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/t1_sagittal.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/T1_coronal.png" alt=""></div></div></div></div><br>上图中，第一行为 FLAIR 模态，从左到有依次为横断面(Axis plane)，矢状面(Sagittal plane)，冠状面(Coronal plane)，第二行为 T1 模态，从左到右顺序与 FLAIR 相同，另外两个模态因为篇幅的关系不做具体地展示。下面是脑图的 mask 和手工分割肿瘤的真值(可以看做是金标准，但是个人认为还是有区别的)：<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_axis.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_sagittal.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/mask_coronal.png" alt=""></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_axis.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_sagittal.png" alt=""></div><div class="group-picture-column" style="width: 33.333333333333336%;"><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/ground_truth_coronal.png" alt=""></div></div></div></div><br>本人使用的数据库来自于项目[2] 中，具体如何得到的 mask 数据并不是很清楚，不过通过 3D slicer 可以手工生成mask数据，这里时间有限，不准备写了。上图中第二行是三个维度的真值图，其中外围浅蓝色为剔除肿瘤之外的区域(label 0)，绿色为 edema(label 2)，红色为 enhance tumor(label 4)，深蓝色区域为 necrosis(label 1)，黄色区域为 non-enhance tumor(label 3)。注：这里使用的 Brats 2015 采用了这5个标签，之后的该数据集进行了调整，将non-enhncing 和 necrosis 合并为 label 1。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本文使用卷积神经网络，主要结构参考[1]中的结构，不同之处在于为了方便理解，我们只是用了一条通道。模型如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/brain_tumor_segmentation_CNN/brain_tumor_segmentation_model.png" alt=""><br>训练使用交叉熵作为损失函数，利用 RMSprop 作为优化器，学习率设为 $1e-3$，可以对学习率随着epoch进行调整，这里没有改变，读者可以根据自己的想法进行调整。具体代码可以在我的github[3]中查看，喜欢记得点个小星星。</p>
<h1 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h1><p>训练部分采用随机裁剪图片大小为 $75\times75\times75$ ，输入到神经网络中，最后得到$47\times47\times47$ (因为卷积中没有采用padding，所以出现了输出小于输入的情况)。测试部分使用完全大小的图像 $240 \times 240 \times 225$，输入到网络中得到大小为$212 \times 212 \times 197$，因为脑图的边缘是无效的信息，所以输出的大小与输入和真值维度不一致，不会有影响，只需要补全就行了。</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>最后网络在三个子区域的分割指标 Dice 为：Whole score 0.6764， Enhancing tumor 0.4478, Tumor core 0.4819，这个结果并不是非常的好，读者如需更高准确度的分割结果，可以调整测试时候的输入图像的维数，将其保持为与训练时输入的图像维数一致，另外可以参考最新的脑肿瘤分割的工作，对代码进行改进。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Kamnitsas K, Ledig C, Newcombe V F J, et al. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation[J]. Medical image analysis, 2017, 36: 61-78.<br>[2] <a href="https://github.com/yaq007/Autofocus-Layer" target="_blank" rel="noopener">https://github.com/yaq007/Autofocus-Layer</a><br>[3] <a href="https://github.com/hjyai94/Half_Pathway_DeepMedic" target="_blank" rel="noopener">https://github.com/hjyai94/Half_Pathway_DeepMedic</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/07/医学图像可视化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/07/医学图像可视化/" itemprop="url">医学图像可视化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-07T15:43:57+08:00">
                2019-01-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近经常使用到之前写的对医学图像进行可视化，下面我将这部分代码和相关内容整理成该博客，分成一下三个部分，第一部分是医学图像的格式，第二部分是医学图像的读取，第三部分是医学图像的可视化。</p>
<h1 id="医学图像格式"><a href="#医学图像格式" class="headerlink" title="医学图像格式"></a>医学图像格式</h1><p>医学图像常见的有6种主要格式，分别为DICOM(医学数字成像和通讯)、NIFTI(神经影像信息技术)、PAR/REC(Philips磁共振扫描格式)、ANALYZE(Mayo医学成像)、NRRD(近原始栅格数据)和MNIC。<br>目前我就处理过DICOM和NIFTI格式的数据，下面主要对这两种格式进行解释。</p>
<h2 id="DICOM"><a href="#DICOM" class="headerlink" title="DICOM"></a>DICOM</h2><h2 id="NIFTI"><a href="#NIFTI" class="headerlink" title="NIFTI"></a>NIFTI</h2><p>s</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/07/进化算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/07/进化算法/" itemprop="url">进化算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-07T20:30:01+08:00">
                2018-12-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/编程/" itemprop="url" rel="index">
                    <span itemprop="name">编程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。"><a href="#准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。" class="headerlink" title="准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。"></a>准备在博客中新开一个分类，这个分类将记录一些实现的代码，又从别人那里借鉴来的，或者是自己写的之类的。</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/29/CRF进行图像分割/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/29/CRF进行图像分割/" itemprop="url">CRF进行图像分割</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-29T15:58:49+08:00">
                2018-11-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><p>最近，十分困惑条件随机场是如何工作的，为什么可以加在卷积神经网络的后面作为后处理的部分。虽然理论部分前面的博客也有写过，做过一些总结，不过因为没有实现过代码，所以仍有困惑解决不了，每念至此，心绪不宁，遂作此文，以供参考。</p>
<h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><p>本文将实现全连接随机场对非RGB的图像进行分割，主要参考文献[1]以及对应的<a href="https://github.com/lucasb-eyer/pydensecrf" target="_blank" rel="noopener">github</a>代码，另外本文需要安装pydensecrf，可以通过<code>pip install pydensecrf</code>安装，安装时需注意，pydensecrf依赖于cython，需要先安装cython。</p>
<h2 id="对非RGB图像分割"><a href="#对非RGB图像分割" class="headerlink" title="对非RGB图像分割"></a>对非RGB图像分割</h2><p>本文的代码放在了我的github中命名为CRF的仓库库中，<a href="https://github.com/hjyai94/CRF/blob/master/examples/Non%20RGB%20Example.ipynb" target="_blank" rel="noopener">链接地址</a>，这里的代码来自于<a href="https://github.com/lucasb-eyer/pydensecrf" target="_blank" rel="noopener">pydensecrf</a>。</p>
<h3 id="一元势"><a href="#一元势" class="headerlink" title="一元势"></a>一元势</h3><p>一元势包含了每个像素对应的类别，这些可以来自随机森林或者是深度神经网络的softmax。这里，我们共有两个类别，一个是前景，一个是背景，这里大小设置为$400\times 512$。我们建立了两个二维的高斯分布，并且平面显示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"></span><br><span class="line">H, W, NLABELS = <span class="number">400</span>, <span class="number">512</span>, <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This creates a gaussian blob...</span></span><br><span class="line">pos = np.stack(np.mgrid[<span class="number">0</span>:H, <span class="number">0</span>:W], axis=<span class="number">2</span>)</span><br><span class="line">print(pos.shape)</span><br><span class="line">rv = multivariate_normal([H//<span class="number">2</span>, W//<span class="number">2</span>], (H//<span class="number">4</span>)*(W//<span class="number">4</span>))</span><br><span class="line">probs = rv.pdf(pos)</span><br><span class="line">print(probs.shape)</span><br><span class="line"><span class="comment"># ...which we project into the range [0.4, 0.6]</span></span><br><span class="line">probs = (probs-probs.min()) / (probs.max()-probs.min())</span><br><span class="line">probs = <span class="number">0.5</span> + <span class="number">0.2</span> * (probs<span class="number">-0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The first dimension needs to be equal to the number of classes.</span></span><br><span class="line"><span class="comment"># Let's have one "foreground" and one "background" class.</span></span><br><span class="line"><span class="comment"># So replicate the gaussian blob but invert it to create the probability</span></span><br><span class="line"><span class="comment"># of the "background" class to be the opposite of "foreground".</span></span><br><span class="line">probs = np.tile(probs[np.newaxis,:,:],(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">probs[<span class="number">1</span>,:,:] = <span class="number">1</span> - probs[<span class="number">0</span>,:,:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's have a look:</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>); plt.imshow(probs[<span class="number">0</span>,:,:]); plt.title(<span class="string">'Foreground probability'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>); plt.imshow(probs[<span class="number">1</span>,:,:]); plt.title(<span class="string">'Background probability'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_9_1.png" alt="output_9_1.png"></p>
<h3 id="使用一元势进行推断"><a href="#使用一元势进行推断" class="headerlink" title="使用一元势进行推断"></a>使用一元势进行推断</h3><p>这里我们可以使用一元势进行推断，也就是说这里我们不考虑像素间的相互关联。这样做并不是很好的推断，但是可以这么做。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inference without pair-wise terms</span></span><br><span class="line">U = unary_from_softmax(probs)  <span class="comment"># <span class="doctag">note:</span> num classes is first dim</span></span><br><span class="line">d = dcrf.DenseCRF2D(W, H, NLABELS)</span><br><span class="line">d.setUnaryEnergy(U)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run inference for 10 iterations</span></span><br><span class="line">Q_unary = d.inference(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The Q is now the approximate posterior, we can get a MAP estimate using argmax.</span></span><br><span class="line">map_soln_unary = np.argmax(Q_unary, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Unfortunately, the DenseCRF flattens everything, so get it back into picture form.</span></span><br><span class="line">map_soln_unary = map_soln_unary.reshape((H,W))</span><br><span class="line"><span class="comment"># And let's have a look.</span></span><br><span class="line">plt.imshow(map_soln_unary); plt.axis(<span class="string">'off'</span>); plt.title(<span class="string">'MAP Solution without pairwise terms'</span>);</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_12_0.png" alt="output_12_0.png"></p>
<h3 id="二元势"><a href="#二元势" class="headerlink" title="二元势"></a>二元势</h3><p>图像处理中，我们经常使用像素间的双边关系，也就是说，我们认为有相似颜色的或者是相似的位置的像素认为是同一类。下面我们建立这样的双边关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">NCHAN=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create simple image which will serve as bilateral.</span></span><br><span class="line"><span class="comment"># Note that we put the channel dimension last here,</span></span><br><span class="line"><span class="comment"># but we could also have it be the first dimension and</span></span><br><span class="line"><span class="comment"># just change the `chdim` parameter to `0` further down.</span></span><br><span class="line">img = np.zeros((H,W,NCHAN), np.uint8)</span><br><span class="line">img[H//<span class="number">3</span>:<span class="number">2</span>*H//<span class="number">3</span>,W//<span class="number">4</span>:<span class="number">3</span>*W//<span class="number">4</span>,:] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.imshow(img[:,:,<span class="number">0</span>]); plt.title(<span class="string">'Bilateral image'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the pairwise bilateral term from the above image.</span></span><br><span class="line"><span class="comment"># The two `s&#123;dims,chan&#125;` parameters are model hyper-parameters defining</span></span><br><span class="line"><span class="comment"># the strength of the location and image content bilaterals, respectively.</span></span><br><span class="line">pairwise_energy = create_pairwise_bilateral(sdims=(<span class="number">10</span>,<span class="number">10</span>), schan=(<span class="number">0.01</span>,), img=img, chdim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pairwise_energy now contains as many dimensions as the DenseCRF has features,</span></span><br><span class="line"><span class="comment"># which in this case is 3: (x,y,channel1)</span></span><br><span class="line">img_en = pairwise_energy.reshape((<span class="number">-1</span>, H, W))  <span class="comment"># Reshape just for plotting</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>); plt.imshow(img_en[<span class="number">0</span>]); plt.title(<span class="string">'Pairwise bilateral [x]'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>); plt.imshow(img_en[<span class="number">1</span>]); plt.title(<span class="string">'Pairwise bilateral [y]'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>); plt.imshow(img_en[<span class="number">2</span>]); plt.title(<span class="string">'Pairwise bilateral [c]'</span>); plt.axis(<span class="string">'off'</span>); plt.colorbar();</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_17_0.png" alt="output_17_0.png"><br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_18_0.png" alt="output_17_0.png"></p>
<h3 id="使用完整的条件随机场进行推断"><a href="#使用完整的条件随机场进行推断" class="headerlink" title="使用完整的条件随机场进行推断"></a>使用完整的条件随机场进行推断</h3><p>下面我们将一元势与二元势结合起来进行推断，执行不同的迭代次数，有下面的结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">d = dcrf.DenseCRF2D(W, H, NLABELS)</span><br><span class="line">d.setUnaryEnergy(U)</span><br><span class="line">d.addPairwiseEnergy(pairwise_energy, compat=<span class="number">10</span>)  <span class="comment"># `compat` is the "strength" of this potential.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This time, let's do inference in steps ourselves</span></span><br><span class="line"><span class="comment"># so that we can look at intermediate solutions</span></span><br><span class="line"><span class="comment"># as well as monitor KL-divergence, which indicates</span></span><br><span class="line"><span class="comment"># how well we have converged.</span></span><br><span class="line"><span class="comment"># PyDenseCRF also requires us to keep track of two</span></span><br><span class="line"><span class="comment"># temporary buffers it needs for computations.</span></span><br><span class="line">Q, tmp1, tmp2 = d.startInference()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    d.stepInference(Q, tmp1, tmp2)</span><br><span class="line">kl1 = d.klDivergence(Q) / (H*W)</span><br><span class="line">map_soln1 = np.argmax(Q, axis=<span class="number">0</span>).reshape((H,W))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    d.stepInference(Q, tmp1, tmp2)</span><br><span class="line">kl2 = d.klDivergence(Q) / (H*W)</span><br><span class="line">map_soln2 = np.argmax(Q, axis=<span class="number">0</span>).reshape((H,W))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">50</span>):</span><br><span class="line">    d.stepInference(Q, tmp1, tmp2)</span><br><span class="line">kl3 = d.klDivergence(Q) / (H*W)</span><br><span class="line">map_soln3 = np.argmax(Q, axis=<span class="number">0</span>).reshape((H,W))</span><br><span class="line"></span><br><span class="line">img_en = pairwise_energy.reshape((<span class="number">-1</span>, H, W))  <span class="comment"># Reshape just for plotting</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>); plt.imshow(map_soln1);</span><br><span class="line">plt.title(<span class="string">'MAP Solution with DenseCRF\n(5 steps, KL=&#123;:.2f&#125;)'</span>.format(kl1)); plt.axis(<span class="string">'off'</span>);</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>); plt.imshow(map_soln2);</span><br><span class="line">plt.title(<span class="string">'MAP Solution with DenseCRF\n(20 steps, KL=&#123;:.2f&#125;)'</span>.format(kl2)); plt.axis(<span class="string">'off'</span>);</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>); plt.imshow(map_soln3);</span><br><span class="line">plt.title(<span class="string">'MAP Solution with DenseCRF\n(75 steps, KL=&#123;:.2f&#125;)'</span>.format(kl3)); plt.axis(<span class="string">'off'</span>);</span><br></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/output_21_0.png" alt="output_21_0.png"></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] Krähenbühl P, Koltun V. Efficient inference in fully connected crfs with gaussian edge potentials[C]//Advances in neural information processing systems. 2011: 109-117.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/27/KL散度/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/27/KL散度/" itemprop="url">KL散度</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-27T15:59:48+08:00">
                2018-11-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>很久没有推导过公式了，感觉水平退步显著，今日看变分推断内容，看到了计算两个高斯分布间的KL散度，下面我自己推导了一下。</p>
<h1 id="高斯分布间的KL散度"><a href="#高斯分布间的KL散度" class="headerlink" title="高斯分布间的KL散度"></a>高斯分布间的KL散度</h1><p>现有先验分布$p_{\theta}(z) = \boldsymbol{N}(0, \boldsymbol{I})$，后验分布$q_{\phi}(\boldsymbol{z}\mid \boldsymbol{x}^{(i)})$同样是高斯分布。变量$z$的维数是$J$。其中，$\boldsymbol{u}$和$\boldsymbol{\sigma}$记作点$i$的均值和标准差。另外，$\mu_j$和$\sigma_j$是均值和方差向量的第$j$个因子。<br>KL散度的公式如下：<br>\begin{equation}\begin{split}<br>D_{KL}(q_{\phi}(\boldsymbol{z})|| p_{\theta}(\boldsymbol{z})) &amp;= \int q_{\phi}(\boldsymbol{z}) log \frac{q_{\phi}(\boldsymbol{z})} {p_{\theta}(\boldsymbol{z})} d\boldsymbol{z}\\<br>&amp;= \int q_{\phi}(\boldsymbol{z}) log q_{\phi}(\boldsymbol{z}) d\boldsymbol{z} - \int q_{\phi}(\boldsymbol{z}) log p_{\theta}(\boldsymbol{z}) d\boldsymbol{z} \\<br>\end{split}\end{equation}<br>第二项如下所示(因为先写的第二项，小声bb.jpg)：<br>\begin{equation}\begin{split}<br>\int q_{\phi}(\boldsymbol{z}) log p_{\theta}(\boldsymbol{z}) d\boldsymbol{z} &amp;= \int \mathcal{N}(\boldsymbol{z;\mu, \sigma^2}) log \mathcal{N}(\boldsymbol{z; 0, I})d \boldsymbol{z} \\<br>&amp;= \int -\frac{1}{2} log{2\pi}\ q_{\phi}(\boldsymbol{z}) -\frac{z^2}{2} q_{\phi}(\boldsymbol{z}) d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \int q_{\phi}(\boldsymbol{z}) \boldsymbol{z}^2 d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \int q_{\phi}(\boldsymbol{z}) (\boldsymbol{z- \mu + \mu})^2 d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \int q_{\phi}(\boldsymbol{z}) [(\boldsymbol{z- \mu})^2 + \boldsymbol{\mu}^2 +2(\boldsymbol{z - \mu})\boldsymbol{\mu}] d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \int q_{\phi}(\boldsymbol{z}) [(\boldsymbol{z- \mu})^2 + \boldsymbol{\mu}^2)] d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \int q_{\phi}(\boldsymbol{z}) (\boldsymbol{\sigma}^2 + \boldsymbol{\mu}^2) d\boldsymbol{z} \\<br>&amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \sum_{j=1}^{J} (\mu_j^2 + \sigma_j^2)<br>\end{split}\end{equation}</p>
<p>同样，第一项可以写成如下的形式：<br>\begin{equation}\begin{split}<br>\int q_{\phi}(\boldsymbol{z}) log q_{\phi}(\boldsymbol{z}) d\boldsymbol{z} &amp;= -\frac{J}{2}log(2\pi) -\frac{1}{2} \sum_{j=1}^{J} (1 + log\ \sigma_j^2)<br>\end{split}\end{equation}<br>将上面两项合并一起：<br>\begin{equation}\begin{split}<br>D_{KL}(q_{\phi}(\boldsymbol{z}) || p_{\theta}(\boldsymbol{z})) &amp;= \int q_{\phi}(\boldsymbol{z}) log (q_{\phi}(\boldsymbol{z}) - p_{\theta}(\boldsymbol{z})) d\boldsymbol{z}\\<br>&amp;= -\frac{1}{2} \sum_{j=1}^{J} (1 + log\ \sigma_j^2) + \frac{1}{2} \sum_{j=1}^{J} (\mu_j^2 + \sigma_j^2) \\<br>&amp;= \frac{1}{2} \sum_{j=1}^{J} (-1 - log\ \sigma_j^2 + \mu_j^2 + \sigma_j^2)<br>\end{split}\end{equation}</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>Kingma D P. Variational inference &amp; deep learning: A new synthesis[D]. 2017.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/18/MRI读取与可视化I/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/18/MRI读取与可视化I/" itemprop="url">MRI读取与可视化I</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-18T19:00:40+08:00">
                2018-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天在网上看了一些读取MRI文件的方法，中文的博客并不是很多，另外很多并不适合我的文件格式，本文主要是针对MRI中采用NIFTI(.nii.g其中gz是压缩文件)格式的文件，并进行可视化分析。</p>
<h1 id="NIBabel"><a href="#NIBabel" class="headerlink" title="NIBabel"></a>NIBabel</h1><p>NIBabel是一个常见的读写神经医学文件的python库，包括ANALYZE, GIFTI, NIfTI2, MINC1, MINC2, MGH和ECAT，还有Philips PAR/REC。<br>下面我们用一张大脑的<a href="http://nipy.org/nibabel/_downloads/someones_epi.nii.gz" target="_blank" rel="noopener">MRI图片</a>，来说这个库的使用，以及MRI文件的格式。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line">img = nib.load(<span class="string">'downloads/someones_epi.nii.gz'</span>)</span><br><span class="line">img_header = img.get_header()</span><br><span class="line">print(<span class="string">'Header: '</span>, img_header)</span><br><span class="line">img_data = img.get_fdata()</span><br><span class="line">print(<span class="string">'img_data shape: '</span>, img_data.shape)</span><br></pre></td></tr></table></figure></p>
<p>一个格式为NIFTI的格式文件，通常包括头文件和相应的图像文件。图像文件时三维的，上面的MRI图片的shape为(53, 61, 33)。下面我们将三个维度的中间slice进行可视化(因为不会直接将三维的图像可视化)。</p>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p>下面我们显示中间的slice：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(img_data[<span class="number">26</span>, :, :])</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">plt.imshow(img_data[:, <span class="number">30</span>, :])</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">plt.imshow(img_data[:, :, <span class="number">15</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<h1 id="下面的工作"><a href="#下面的工作" class="headerlink" title="下面的工作"></a>下面的工作</h1><p>利用pytorch读取文件，训练神机网络。(可能不会上传到本博客中)</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] <a href="http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array" target="_blank" rel="noopener">http://nipy.org/nibabel/coordinate_systems.html#voxel-coordinates-are-coordinates-in-the-image-data-array</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="HJY" />
            
              <p class="site-author-name" itemprop="name">HJY</p>
              <p class="site-description motion-element" itemprop="description">HJY的装逼小站</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">45</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hjyai94" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HJY</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.3"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
