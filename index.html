<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="HJY的装逼小站">
<meta property="og:type" content="website">
<meta property="og:title" content="HJY">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="HJY">
<meta property="og:description" content="HJY的装逼小站">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HJY">
<meta name="twitter:description" content="HJY的装逼小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'HR62QHMRVP',
      apiKey: '5003cc57039452aa0e152bdb9198ed17',
      indexName: 'dev_NAME',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>HJY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HJY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">昨夜西风凋碧树，独上高楼望尽天涯路。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/17/可观无向图模型中的学习问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/17/可观无向图模型中的学习问题/" itemprop="url">可观无向图模型中的学习问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-17T10:58:53+08:00">
                2018-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="最大似然结构学习"><a class="markdownIt-Anchor" href="#最大似然结构学习"></a> 最大似然结构学习</h1>
<h1 id="连续型马尔科夫随机场"><a class="markdownIt-Anchor" href="#连续型马尔科夫随机场"></a> 连续型马尔科夫随机场</h1>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/可观贝叶斯网络中的学习问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/可观贝叶斯网络中的学习问题/" itemprop="url">可观贝叶斯网络中的学习问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T15:37:27+08:00">
                2018-05-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="完全可观的图模型学习"><a href="#完全可观的图模型学习" class="headerlink" title="完全可观的图模型学习"></a>完全可观的图模型学习</h1><p>图模型学习的目的是在给定独立的样本集的情况下找到合适的的贝叶斯网络，这里的学习（learning）表示对参数的估计或者是从数据学习网络的拓扑结构。</p>
<h2 id="最大似然在信息论上的解释"><a href="#最大似然在信息论上的解释" class="headerlink" title="最大似然在信息论上的解释"></a>最大似然在信息论上的解释</h2><p>可以这样理解，将对数似然函数在数据上的和，转变为在变量状态上的和。<br>\begin{equation}\begin{split} l(\theta_G,G;D)&amp;=log\ p(D\mid \theta_G,G) (Joint Likelilood)\\<br>&amp; = log\ p\prod_n(\prod_i p(x_{n,i}\mid x_{n,\pi_{i(G)}}, \theta_{i\mid \pi_{i(G)}})  (BN Factorization  Rule)\\<br>&amp; = \Sigma_i(\Sigma_n log\ p(x_{n,i}\mid x_{n,\pi_{i(G)}}, \theta_{i\mid \pi_{i(G)}}))\\<br>&amp; = M\ \Sigma_i(\Sigma_{x_i,x_{\pi_{i(G)}}} \frac{count(x_i,x_{\pi_{i(G)}})}{M} log\ p(x_i\mid x_{\pi_{i(G)}}, \theta_{i\mid \pi(G)}))  \\<br>&amp; = M\ \Sigma_i(\Sigma_{x_i,x_{\pi_{i(G)}}} \hat{p}(x_i, x_{\pi_{i(G)}}) log\ p(x_i\mid x_{\pi_{i(G)}}, \theta_{i\mid \pi(G)}))  \\<br>\end{split}\end{equation}</p>
<p>这里的H表示变量状态，概率分布$p(x_i)$用计数函数取代（count function）。$(x_i,x_{\pi{i(G)}}$包括了所随机变量的值。<br>继续对上面的式子进行推导：<br>\begin{equation}\begin{split} l(\theta_G,G;D)&amp;=M\ \Sigma_i(\Sigma_{x_i,x_{\pi_{i(G)}}} \hat{p}(x_i, x_{\pi_{i(G)}}) log\ p(x_i\mid x_{\pi_{i(G)}}, \theta_{i\mid \pi(G)}))  \\<br>&amp; = M\ \Sigma_i(\Sigma_{x_i,x_{\pi_{i(G)}}} \hat{p}(x_i, x_{\pi_{i(G)}}) log\ \frac{p(x_i, x_{\pi_{i(G)}}\mid \theta_{i\mid \pi_{(G)}})}  {\hat{p}(x_i, x_{\pi_{i(G)}})}\frac{\hat{p}(x_i)}{\hat{p}(x_i)})\\<br>&amp; = M\ \Sigma_i(\Sigma_{x_i,x_{\pi_{i(G)}}} \hat{p}(x_i, x_{\pi_{i(G)}}) log\ \frac{p(x_i, x_{\pi_{i(G)}}, \theta_{i\mid \pi_{(G)}})} {\hat{p}(x_i, x_{\pi_{i(G)}})\hat{p}(x_i)}) - M\ \Sigma_i\Sigma_{x_i} - \hat{p}(x_i)log\ \hat{p}(x_i)\\<br>&amp; = M\ \Sigma_i\hat{I}(x_i,x_{\pi_{i(G)}}) - M\ \Sigma_i\hat{H}(x_i) \\<br>\end{split}\end{equation}<br>这样可以将最大似然估计分成两个部分，第一个部分是所有节点的互信息，第二部分是每个节点的熵。可以得出这样的结论，如果我们确定结构式树结构（每个节点只有一个父节点），那么基于最大似然估计下，我们可以获得一个最优的树。</p>
<h1 id="Chow-Liu-算法"><a href="#Chow-Liu-算法" class="headerlink" title="Chow-Liu 算法"></a>Chow-Liu 算法</h1><p>目标函数可以写成：<br>$$ l(\theta_G,G;D) = M\ \Sigma_i\hat{I}(x_i,x_{\pi_{i(G)}}) - M\ \Sigma_i\hat{H}(x_i)  $$<br>将上式后面各个变量的熵去掉，因为变量的熵与树的结构无关，上式化简为：<br>\begin{equation}\begin{split} C(G) &amp;= M\ \Sigma_i\hat{I}(x_i,x_{\pi_{i(G)}}) \\<br>&amp;= M\ \Sigma_i\hat{I}(x_i,x_j) \\<br>\end{split}\end{equation}<br>我们只需要计算经验分布（empirical distribution）和每对节点的互信息（mutual information）就可以了。经验分布可以通过数据直接数出来，下面是计算每对节点$x_i$和$x_j$之间的经验分布和互信息。<br>$$ \hat{p}(X_i, X_j) = \frac{count(x_i, x_j)}{M} $$<br>$$ \hat{I}(X_i, X_j) = \Sigma_{x_i, x_j}\hat{p}(x_i, x_j)log\ \frac{\hat{p}(x_i, x_j)}{\hat{p}(x_i)\hat{p}(x_j)} $$<br>我们定义一个有节点$x_1, x_2, x_3, …,x_n$的图，指定图的边$(i, j)$的权值为$\hat{I}(X_i, X_j)$。Chow-Liu算法可以计算最大权重生成树。挑选任意节点作为根节点，然后使用宽度优先算法（breadth-first-search）来决定方向。</p>
<h1 id="对于完全可观的给定结构的参数学习"><a href="#对于完全可观的给定结构的参数学习" class="headerlink" title="对于完全可观的给定结构的参数学习"></a>对于完全可观的给定结构的参数学习</h1><p>假定图结构固定，从N个独立同分布的样本集中进行参数估计$D = \lbrace x_1, x_2, x_3, …, x_N\rbrace$。一般来说，每个训练样本$x_n = x_{n, 1}, x_{n,2}, …, x_{n,M}$是M维的向量，对应于每个节点。下面介绍几个常见用于参数估计的分布。</p>
<h2 id="多项式模型"><a href="#多项式模型" class="headerlink" title="多项式模型"></a>多项式模型</h2><p>对于N个独立同分布的样本，采用unit basis vectors表示，$x_n = (x_{n,1}, x_{n,2}, …, x_{n,K})$，其中$x_{n,k}=\lbrace 0, 1 \rbrace $， $\Sigma_{k=1}^K x_{n, k} $。这种表示方法将事件抽离出来，不考虑事件本身的意义，关注事件发生与否。数据集$D = \lbrace x_1, x_2, x_3, …, x_N\rbrace$的似然函数为：<br>$$ L(\theta\mid D) = P(x_1, x_2, …, x_N\mid \theta) = \prod_{n=1}^N P(x_n\mid \theta) = \prod_k \theta_k^{n_k} $$<br>$$ l(\theta\mid D) = log\ \prod_k \theta_k^{n_k}  = \Sigma_k n_k log\ \theta_k $$<br>因为存在着等式约束$\Sigma_{k=1}^K x_{n,k} = 1$，所以需要在$l(\theta\mid D)$中加入Lagarange乘子。<br>$$ \hat{l}(\theta\mid D) = \Sigma_k n_k log\ \theta_k + \lambda(1 - \Sigma_{k=1}^K x_{n,k}) $$<br>对$\theta_k$求偏导并令其为零：<br>$$ \hat{\theta}_{k,MLE} = \frac{n_k}{N} $$<br>或者$$ \hat{\theta}_{k,MLE} = \frac{1}{N}\Sigma_n x_{n,k}$$<br>此外，$\bar{n} = {n_1, n_2, …, n_K}$和$n_k = \Sigma_n x_{n,k}$是数据集D的充分统计量。</p>
<h2 id="贝叶斯参数估计"><a href="#贝叶斯参数估计" class="headerlink" title="贝叶斯参数估计"></a>贝叶斯参数估计</h2><p>贝叶斯参数估计就是通过贝叶斯定理，利用先验概率分布来推测出后验概率分布，所以先验概率分布对于贝叶斯参数估计方法来说非常的重要，下面介绍两种常见的先验。</p>
<h3 id="狄利克雷先验-Dirichlet-Prior"><a href="#狄利克雷先验-Dirichlet-Prior" class="headerlink" title="狄利克雷先验(Dirichlet Prior)"></a>狄利克雷先验(Dirichlet Prior)</h3><p>Dirichlet Prior由一组超参数$\alpha_1, \alpha_2, …,\alpha_N$来定义。Dirichlet分布如下：<br>$$ P(\theta) = \frac{\Gamma(\Sigma_k \alpha_k)}{\prod_k \Gamma(\Sigma_k \alpha_k)} \prod_k \theta_k^{\alpha_k-1} = C(\alpha)\prod_k \theta_k^{\alpha_k-1} $$<br>其中$C(\alpha)$是正则化参数，后验概率可以写成如下形式：<br>$$ P(\theta\mid x_1, x_2, …, x_N) = \frac{P(x_1, x_2,…, x_N\mid \theta)P(\theta)}{P(x_1, x_2, …, x_N)} \propto \prod_k \theta_k^{\alpha_k + n_k -1} $$<br>因为后验概率与先验概率形式相同，所以被叫做共轭先验。也就是说，只要先验是Dirichlet分布，那么后验就必定是Dirichlet分布。<br>基于这一特性，就有了序列贝叶斯更新算法。由Dirichlet先验分布$P(\vec{\theta}\mid \vec{\alpha}) = Dir(\vec{\theta}\mid \vec{\alpha})$，后验更新为$P(\vec{\theta}\mid \vec{\alpha},\vec{n’}) = Dir(\vec{\theta}\mid \vec{\alpha}, \vec{n’})$，之后通过$N’$个样本，可以获得充分统计量$\vec{n’}$，后验变成：<br>$$ P(\vec{\theta}\mid \vec{\alpha},\vec{n’}, \vec{n’’}) = Dir(\vec{\theta}\mid \vec{\alpha}, \vec{n’}, \vec{n’’}) $$<br>观测另外$N’’$数据有充分统计量$\vec{n’’}$。这样序列化的处理数据方式和批处理是等价的。Dirichlet主要的缺点是一维的分布，不能处理多维的分布，对于多维有对数正态先验。</p>
<h3 id="对数正态先验"><a href="#对数正态先验" class="headerlink" title="对数正态先验"></a>对数正态先验</h3><p>对数正态先验相比于Dirichlet拥有更加丰富的分布性质。下面是对数先验的定义：<br>$$ \theta \sim LN_K(\mu, \Sigma) $$ $$ \gamma \sim N_{K-1}(\mu, \Sigma)\ \ \  \gamma_K = 0 $$  $$\theta_i \sim \lbrace \gamma_i - log(1 + \Sigma_{i=1}^{K-1} e^{\gamma_i}) $$<br>对数配分函数 $ C(\gamma) = log(1 + \Sigma_{i=1}^{K-1} e^{\gamma_i}) $<br>对数正态先验可以获得更好的协方差结构的性质，但是它不是共轭先验。</p>
<h3 id="多元正态分布的参数估计"><a href="#多元正态分布的参数估计" class="headerlink" title="多元正态分布的参数估计"></a>多元正态分布的参数估计</h3><p>高斯分布的概率密度函数为：<br>$$p(X; \mu,\Sigma)=\frac{1}{(2\pi)^{n/2}\Sigma^{\frac{1}{2}}}exp \lbrace  -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \rbrace$$<br>可以对$\mu$和$\Sigma$进行最大似然估计：<br>$$ \mu_{MLE} = \frac{1}{N}\Sigma_n x_n $$<br>$$ \Sigma_{MLE} = \frac{1}{N}\Sigma_n (x_n - \mu_{MLE})(x_n - \mu_{MLE})^T $$<br>我们需要主要到当$\Sigma$不是满秩的时候，其也不是可逆的。贝叶斯估计的优势在于贝叶斯估计具有先验知识，或者是先验是共轭的，这样就可以进行序列化的处理，类似于批处理的方式。<br>特别的，当$\mu$未知，$\sigma$已知时：<br>$$ p(\mu) = (2\pi\tau^2)^{-1/2} exp\lbrace -(\mu - \mu_0)^2 /2\tau^2 \rbrace $$<br>联合概率分布为：<br>$$ P(x,\mu) = (2\pi\tau^2)^{-1/2} exp\lbrace -(\mu - \mu_0)^2 /2\tau^2 \rbrace * (2\pi\sigma^2)^{-N/2} exp\lbrace -\frac{1}{2\sigma^2}\Sigma_{n=1}^N (x_n - \mu)^2 \rbrace $$<br>后验概率即为：<br>$$ P(\mu\mid X) = (2\pi\tilde{\sigma}^2)^{-N/2} exp\lbrace -\frac{1}{2\tilde{\sigma}^2} (\mu - \tilde{\mu})^2 \rbrace $$<br>其中$\mu = \frac{N/\sigma^2}{N/\sigma^2 + 1/\tau} \bar{x} + \frac{1/\tau}{N/\sigma^2 + 1/\tau}\mu_0 $和$ \tilde{\sigma}^2 = (\frac{N}{\sigma^2} + \frac{1}{\tau^2})^{-1} $<br>后验均值是先验和极大似然估计的凸组合，权值与噪声水平成正比。<br>后验$1/\tilde{\sigma}^2$是先验$1/\tau^2$与每个观测数据对于$1/\sigma^2$的影响。</p>
<h2 id="最大似然估计用于一般的贝叶斯网络"><a href="#最大似然估计用于一般的贝叶斯网络" class="headerlink" title="最大似然估计用于一般的贝叶斯网络"></a>最大似然估计用于一般的贝叶斯网络</h2><p>如果我们假定每个条件概率密度参数是全局独立的，所有的节点是可观的，那么对数似然函数可以分解为如下的形式：<br>$$ l(\theta; D) = log\ p(D\mid \theta) = \Sigma_i(\Sigma_n log\ p(x_{n,i} \mid x_{n,\pi_i}, \theta_i)) $$<br>对于独立同分布的数据似然函数为：<br>$$ p(D\mid \theta) = \prod_n p(x_n\mid \theta) $$</p>
<h3 id="最大似然估计用于离散形式的贝叶斯网络"><a href="#最大似然估计用于离散形式的贝叶斯网络" class="headerlink" title="最大似然估计用于离散形式的贝叶斯网络"></a>最大似然估计用于离散形式的贝叶斯网络</h3><p>假定每个条件概率分布都可以用一个表格来表示，其中$\theta_{ijk} = P(X_i = j\mid x_{\pi_i} = k)$，然后充分统计量就是所有可能的状态的和$ n_{ijk} = \Sigma_n x_{n,i}^j x_{n,{\pi_i}}^k $，对数似然函数写成：<br>$$ l(\theta; \mid D) = log\prod_{i,j,k}\theta_{ijk}^{n_{ijk}} = \Sigma_{i,j,k}n_{i,j,k} log\ \theta_{i,j,k} $$<br>其中$\Sigma_j \theta_{ijk} = 1$，使用拉格朗日乘数法可以得出结果：<br>$$ \theta_{ijk}^{ML} = \frac{n_{ijk}}{\Sigma_{j’} n_{ij’k}} $$</p>
<h2 id="贝叶斯参数估计-1"><a href="#贝叶斯参数估计-1" class="headerlink" title="贝叶斯参数估计"></a>贝叶斯参数估计</h2><ul>
<li>全局独立性 $p(\theta_m\mid G) = \prod_{i=1}^M p(\theta_i \mid G)$</li>
<li><p>局部独立性 $p(\theta_i\mid G) = \prod_{j=1}^{q_i} p(\theta_{x_i^k\mid x_{\pi_i^j}} \mid G)$<br>全局参数独立性指的是每个节点间的参数是独立的，局部参数独立性指的是节点的参数在其父节点不同的情况下独立。</p>
</li>
<li><p>离散的有向无环图模型满足$x_i\mid x_{\pi_i}^j \sim Multi(\theta)$，同时Dirichlet先验为$p(\theta) = C(\alpha)\prod_k \theta_k^{\alpha_k - 1}$。</p>
</li>
<li>高斯有向无环图模型满足$x_i\mid x_{\pi_i}^j \sim Normal(\mu,\Sigma)$，正态Wishart先验为：<br>$$ p(\mu\mid v,\alpha_{\mu},W) = Normal(v,(\alpha_{\mu}W)^{-1}) $$<br>$$ p(W\mid \alpha_w,T) = c(n, \alpha_w)|T|^{\alpha_w /2}|W|^{(\alpha_w -n-1)/2} exp \lbrace\frac{1}{2}tr\lbrace TW \rbrace\rbrace $$<br>其中$W = \Sigma^{-1}$。</li>
</ul>
<p>##　马尔科夫链转移矩阵<br>考虑一个时不变的一阶马尔科夫链，初始状态概率向量为$\pi_k = P(X_1^K = 1)$，状态转移矩阵$A_{ij} = P(X_t^j = 1\mid x_{t-1}^i = 1)$。联合概率为：<br>$$ P(X_{1:T\mid \theta}) = P(x_1\mid \pi)\prod_{t=2}^T P(X_t\mid X_{t-1})$$<br>对数似然函数为：<br>$$ l(\theta;D) = \Sigma_n log\ p(x_{n,1}\mid \pi) + \Sigma_n\Sigma_{t=2}^T log\ P(x_{n,t}\mid x_{n,t-1,A}) $$<br>A是随机矩阵并且$\Sigma_j A_{ij}$，所以$A_{ij}$的最大似然估计是从$i$到$j$转移的分式：<br>$$ A_{ij}^{ML} = \frac{\Psi(i\rightarrow j)}{\Psi(i\rightarrow \star)} = \frac{\Sigma_n\Sigma_{t=2}^T x_{n,t-1}^i x_{n,t}^j}{\Sigma_n\Sigma_{t=2}^T x_{n,t-1}^i} $$</p>
<p>上面的方法有一个稀疏的问题，当$i\rightarrow j$没有出现时，$A_{ij}=0$，那么即将出现的单词对$i\rightarrow j$概率为零。可以使用下面的方法进行解决：<br>$$ \tilde{A}_{i\rightarrow \star} = \lambda\eta_t + (1 - \lambda) A_{i\rightarrow \star}^{ML} $$</p>
<h2 id="隐马尔科夫模型"><a href="#隐马尔科夫模型" class="headerlink" title="隐马尔科夫模型"></a>隐马尔科夫模型</h2><ul>
<li>两个状态之间转移的可能性$P(y_t^j = 1\mid y_{t-1}^i = 1) = a_{i,j}$或者$P(y_t\mid y_{t-1} = 1)\sim Multinomial(a_{i,1}, a_{i,2}, …, a_{i,M})$。</li>
<li>开始概率$P(y_1) \sim Multinomial(\pi_1, \pi_2,…, \pi_M)$。</li>
<li>每个y向x的传播概率$P(x_t\mid y_t^i = 1)\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K})$。</li>
</ul>
<p>给定$x=x_1,…,x_N$对实际的状态路径已知，定义如下：<br>$A_{ij} = \Psi$状态转移在y上从$i\rightarrow j$<br>$B_{ik} = \Psi $状态i在y中影响在x中的k<br>$\theta$的最大似然估计：<br>$$a_{ij}^{ML} = \frac{\Psi(i\rightarrow j)} {\Psi(i\rightarrow \star)} = \frac{A_{ij}}{\Sigma_j A_{ij}}$$<br>$$ b_{ik}^{ML} = \frac{\Psi(i\rightarrow \star)}{\Psi(i\rightarrow \star)} = \frac{B_{ij}}{\Sigma_k B_{ik}} $$</p>
<p>对于样本较小的情况下，采用伪计数。<br>$A_{ij} = \Psi$状态转移在$y+R_{ij$}$上从$i\rightarrow j$<br>$B_{ik} = \Psi$状态i在$y$中影响在$x+S_{ik}$中的k<br>$R_{ij}$，$S_{ij}$是伪计数，体现了我们对先验信息的信任。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对于完全可观的贝叶斯网络，可以进行分解，所以学习问题可以进行分解。</p>
<ul>
<li>结构学习<ul>
<li>Chow Liu 算法</li>
<li>近邻选择</li>
</ul>
</li>
<li>在概率图的单个节点上进行学习-密度估计：指数族分布<ul>
<li>一般的离散分布</li>
<li>一般的连续分布</li>
<li>共轭先验</li>
</ul>
</li>
<li>两个节点进行学习：广义线性模型<ul>
<li>条件概率密度估计</li>
<li>分类</li>
</ul>
</li>
<li>更多的节点<ul>
<li>利用局部的性质</li>
</ul>
</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第7讲视频以及笔记。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/09/指数族与广义线性模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/09/指数族与广义线性模型/" itemprop="url">指数族与广义线性模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-09T10:30:15+08:00">
                2018-05-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="指数族"><a href="#指数族" class="headerlink" title="指数族"></a>指数族</h1><p>将随机变量X写成指数族的形式：<br>$$p(X=x;\eta)=h(x)exp(\eta^T T(x)-A(\eta))$$<br>其中：$\eta$是自然参数向量（natural paramater），T(x)是充分统计量（sufficient statistic），$A(\eta)$是对数判分函数（log partition function）。</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>指数族可以包括许多的例子，比如高斯分布，伯努利分布，多项式分布等。</p>
<h3 id="多元正态分布"><a href="#多元正态分布" class="headerlink" title="多元正态分布"></a>多元正态分布</h3><p>令向量$X\in R^k$<br>$$p(x\mid \mu,\Sigma)=\frac{1}{(2\pi)^{k/2}\Sigma^{\frac{1}{2}}}exp \lbrace  -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \rbrace$$<br>$$=\frac{1}{(2\pi)^{k/2}} exp\lbrace -\frac{1}{2} tr(\Sigma^{-1}x x^T) + \mu^T \Sigma^{-1}x^T- \frac{1}{2}\mu^T \Sigma^{-1}\mu - log|\Sigma|\rbrace$$<br>对应的指数族表示：<br>$$\eta = [\Sigma^{-1}\mu; -\frac{1}{2}vec(\Sigma^{-1})]$$  $$ T(x)=[x;vec(xx^T)]$$  $$ A(\eta)=\frac{1}{2} \mu^T \Sigma^{-1} \mu + log|\Sigma| $$  $$ h(x)= \frac{1} { {2\pi}^{k/2} } $$</p>
<h3 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h3><p>$$ p(x;\phi) $$  $$ = \phi^x(1-\phi)^{1-x} $$  $$ = exp(log(\phi^x(1-\phi)^{1-x}) $$  $$ = exp(log(\phi^x)+log((1-\phi)^{1-x})) $$  $$ = exp(xlog(\phi) + (1-x)log(1-\phi)) $$  $$ = exp(xlog(\frac{\phi}{1-\phi})+log(1-\phi))$$<br>对应于指数族：<br>$$ \eta = log(\frac{\phi}{1-\phi}) $$  $$ T(x) = x $$  $$ A(\eta) = -log(1-\phi) $$  $$ h(x) = 1 $$</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>很多的分布可以看做是指数族：单变量高斯分布（the univariate Gaussian)，泊松分布（Poisson）， 多项分布（multinomial），线性回归（linear regression），伊辛模型（Ising model），受限波尔兹曼机机（restricted Boltzmann machines），还有条件随机场（contional random field，CRFs）。</p>
<h4 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h4><p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png" alt=""><br>条件随机场是基于上面图的无向图模型，势函数是定义在成对输出上面的。<br>$$ p_\theta(y\mid x)=\frac{1}{Z(x)}exp(\Sigma_{e\in E,k} \lambda_k f_k(e,y\mid_e, x) + \Sigma_{v\in V,k} \mu_k g_k(v,y\mid_v, x))$$<br>其中$f_k$和$g_k$是固定的，$g_k$是波尔顶点特征，$f_k$是波尔边特征。</p>
<h2 id="指数族特性"><a href="#指数族特性" class="headerlink" title="指数族特性"></a>指数族特性</h2><p>指数族具有如下的特性：</p>
<ol>
<li>对数配分函数的第d阶导数，是充分统计量的第d阶中心距。<br>比如：对数配分函数的一阶导数是T(X)的均值，其二阶导是T(X)的方差。</li>
<li>因为对数配分函数的二阶导是正的，所以对数配分函数是凸的，因此方差总是非负的。</li>
<li>我们可以将对数配分函数的一阶导看成自然参数的函数，然后令其为零，反过来利用距参数就可以解决自然参数，记作：$\eta = \psi(\mu)$ 。</li>
<li>在指数族上进行最大似然估计与矩匹配是一致的。<ul>
<li>写出一般指数族的对数似然函数:<br>$$ const + \eta^T (\Sigma_{i=1}^n T(x_i)) - nA(\eta) $$</li>
<li>求似然函数的梯度：<br>$$ \Sigma_{i=1}^n T(x_i)) - n\Delta_\eta A(\eta) $$</li>
<li>令$\Delta_\eta A$为零：<br>$$ \Delta_\eta A = \frac{1}{n}\Sigma_{i=1}^T T(x_i) \Rightarrow \mu = \frac{1}{n}\Sigma_{i=1}^T T(x_i) \Rightarrow 矩估计=样本距 $$</li>
</ul>
</li>
</ol>
<h3 id="充分统计量"><a href="#充分统计量" class="headerlink" title="充分统计量"></a>充分统计量</h3><p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png" alt=""><br>从贝叶斯的观点出发：如果T具备了我们预测参数$\theta$的所有信息（即T是充分统计量），那么$\theta \perp X \mid T \Rightarrow P(\theta \mid X, T)=P(\theta\mid T)$。<br>从频率学派的角度出发：如果T已知的用来产生数据的参数，那么$ X \perp \theta \mid T \Rightarrow P(X\mid T;\theta) = P(X\mid T) $<br>从马尔科夫随机场的角度进行考虑：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F.png" alt=""></p>
<h2 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h2><p>重新从贝叶斯的角度出发，写出给定自然参数的似然函数，我们选择了一个自然参数先验，然后计算出自然参数的后验概率。<br>比如：<br>$$ p(x\mid \eta) \propto exp(\eta^ T T(x) - A(\eta))$$<br>$$ p(\eta) \propto exp(\xi^T T(\eta) - A(\xi)) $$<br>$$ p(\eta\mid x, \xi) \propto exp(\eta^T T(x) + \xi^T T(\eta) + A(\eta) + A(\xi)) $$<br>如果$\eta = T(\eta)$ ，那么后验概率变为：<br>$$ p(\eta\mid x, \xi) \propto exp(T(\eta)(T(x) + \xi)+ A(\eta) + A(\xi)) $$<br>当$ \eta = T(\eta)$ ，我们指定$\eta ~exponentialFamily$，这是先验就是共轭先验。</p>
<h1 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h1><p>广义线性模型可以将分类和回归问题进行统一，使用相同的统计框架。<br>假定：<br>$$ Y \sim exponentialFamily $$<br>$$ \eta = \psi(\mu=f(\xi = \theta^T x)) $$<br>其中Y是响应，x是固定输入，$\theta$是需要学习的参数，$f$（响应函数，response function），$\psi$增加了一定的灵活性，f经常被设定为$\psi^{-1}$（canonical response function）。</p>
<h1 id="广义线性模型的批学习"><a href="#广义线性模型的批学习" class="headerlink" title="广义线性模型的批学习"></a>广义线性模型的批学习</h1><p>考虑通过求导的方法来解决最小二乘问题，就是使代价函数达到极小：<br>$$ J(\theta) = \frac{1}{2} \Sigma_{i=1}^n (x_i^T\theta - y_i)^2 = \frac{1}{2} (X\theta-y) $$<br>$x_i$表示第i个输入样本，$y_i$表示第i个输出样本。<br>对$J(\theta)$求一阶导并令其为零，可以得到取得极小值时的$\theta$。<br>$$ \triangledown J(\theta) = X^T X\theta - X^T y = 0 \Rightarrow \theta^* = (X^T X)^{-1} X^T y $$<br>使用牛顿法进行迭代寻找最优解，牛顿法更新参数更新准则：<br>$$ \theta^{t+1} = \theta^t - H^{-1}\triangledown J(\theta) $$</p>
<p>对数似然函数$l = \Sigma_n logh(y_n) + \Sigma_n(\theta^T x_n y_n - A(\eta))$<br>下面获得Hessian阵：<br>\begin{equation}\begin{split} H&amp;=\frac{d^2 l}{d\theta d\theta^T}\\<br>&amp; = \frac{d}{d\theta^T}\Sigma_n(y_n-\mu_n)x_n\\<br>&amp; = \Sigma_n x_n \frac{d\mu_n}{d\theta^T}\\<br>&amp; = -\Sigma_n X_n \frac{d\mu_n}{d\eta_n} \frac{d\eta_n}{d\theta^T}\\<br>&amp; = -\Sigma_n X_n \frac{d\mu_n}{d\eta_n} x_n^T \   因为\eta_n = \theta^T x_n\\<br>&amp; = -X^T W X<br>\end{split}\end{equation}<br>其中$X = [x_n^T]$，$W = diag[\frac{d\mu_1}{d\eta_1},…,\frac{d\mu_N}{d\eta_N}]$。W可以同过计算$A(\eta)$的二阶导来计算。<br>代换上式中的$\triangledown J(\theta)$和H，可以得到：<br>$$ \theta^{t+1} = (X^T W^t X)^{-1} X^T W^t z^t $$<br>其中$z^t = X\theta^ t + (W^t)^{-1}(y - \mu^t)$。因为W是对角阵，所有该式子具有解耦的作用。</p>
<h3 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h3><p>条件概率分布如下（伯努利分布）：<br>$$ p(y \mid x) = \mu(x)^y (1-\mu(x))^{1-y} $$<br>其中$\mu$是logistic函数<br>$$ \mu(x) = \frac{1}{1 + e^{-\eta(x)}} $$</p>
<p>由于$p(y\mid x)$是指数族，<br>均值：<br>$$ E[y\mid x] = \mu = \frac{1}{1 + e^{-\eta(x)}} $$<br>canonical response  function:<br>$$ \eta = \xi = \theta^T x $$<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \frac{d\mu}{d\eta} = \mu (1 - \mu) $$<br>$$ W =<br>\begin{pmatrix}<br>\mu_1 (1 - \mu_1)\\<br>&amp;\ddots \\<br>&amp; &amp; \mu_N (1-\mu_N) \\<br>\end{pmatrix}<br>$$<br>其中N是训练样本的数量，d是输入样本的维度。上面的方法每代复杂度为$O(Nd^3)$。可以利用拟牛顿法来近似计算Hessian阵来减小运算成本。<br>共轭梯度每代的复杂度为$O(N d)$，在实际中使用效果更好。dang样本数量较大时，也可以采用随机梯度下降。</p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>条件概率分布为：<br>$$p(y\mid x,\theta,\Sigma)=\frac{1}{(2\pi)^{k/2}\Sigma^{\frac{1}{2}}}exp \lbrace  \frac{1}{2}(y-\mu)^T\Sigma^{-1}(y - \mu) \rbrace$$<br>从上面多元正态分布中，可以写成指数族的形式。<br>利用上面的方法广义线性模型中的方法求W：<br>$$ \frac{d\mu}{d\eta} = 1 $$<br>$$ W = 1 $$<br>更新规则如下：<br>$$ \theta^{t+1} = \theta^t + (X^T X)^{-1} X^T(y - \mu^t) $$</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>对于指数族分布，最大似然估计等价于矩估计。</li>
<li>广义线性模型是图模型的实际应用中的重要组成部分。</li>
<li>要选择合适的独立性以及合适的先验。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第6讲视频以及笔记。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/25/概率论知识点/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/概率论知识点/" itemprop="url">概率论知识点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-25T10:11:46+08:00">
                2018-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="频率学派和贝叶斯学派"><a href="#频率学派和贝叶斯学派" class="headerlink" title="频率学派和贝叶斯学派"></a>频率学派和贝叶斯学派</h1><p>频率学派：观测数据是随机变量，参数是未知但确定的；<br>贝叶斯学派：观测数据是已知的，参数是随机变量。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%A2%91%E7%8E%87%E5%AD%A6%E6%B4%BE%E4%B8%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E6%B4%BE.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/18/神经网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/18/神经网络/" itemprop="url">神经网络</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-18T20:30:14+08:00">
                2018-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>感知机主要是解决了与非问题，输入是二值的0或者1，后来出现了Sigmoid。解决了感知机只能处理与非问题，将输出变为0~1之间，这样就有了神经网络。下面的文章非常的通俗易懂，可以一看。<br><a href="http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/18/massage-passing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/18/massage-passing/" itemprop="url">massage-passing</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-18T10:52:19+08:00">
                2018-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="变量消除的缺点"><a href="#变量消除的缺点" class="headerlink" title="变量消除的缺点"></a>变量消除的缺点</h1><p>elimination algorihthm中会有clique中重复使用的情况，massage passing将重复使用的clique保留下来，这样可以减少运算复杂度。</p>
<h1 id="Elimination-on-a-tree"><a href="#Elimination-on-a-tree" class="headerlink" title="Elimination on a tree"></a>Elimination on a tree</h1><p>将从i开始的变量消除记作$m_{ji}(x_i)$，并且是$x_i$的函数。<br>$$m_{ji}(x_i)=\sum_{x_j}(\psi(x_j) \psi(x_i,x_j)\prod_{k\in N(j)\j} m_{kj}(x_j))$$<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/elimination%20on%20a%20tree.png" alt=""><br>$m_{ji}(x_i)$能够表示从$x_j$到$x_i$的置信。</p>
<h1 id="Two-pass-Algorithm"><a href="#Two-pass-Algorithm" class="headerlink" title="Two-pass Algorithm"></a>Two-pass Algorithm</h1><p>算法的实施的具体步骤，确定一个根节点，从其他节点中收集信息到这个根节点，然后回到分布的信息。直到某一节点中包含了除却继续传播节点的所有信息，这样就计算信息，然后传播到剩下的节点。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] <a href="http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A" target="_blank" rel="noopener">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第5讲视频以及笔记，参考[2]中第4章。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/10/EnglishPod/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/10/EnglishPod/" itemprop="url">EnglishPod</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-10T16:33:23+08:00">
                2018-04-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="englishpod-B0001"><a href="#englishpod-B0001" class="headerlink" title="englishpod_B0001"></a>englishpod_B0001</h1><ul>
<li>I’m still working on it.<br>I still need more time.</li>
<li>complimentray<br>free</li>
<li>I’ll go with.<br>I’ll take. I’ll choose.</li>
<li>grab<br>get quickly</li>
</ul>
<h1 id="englishpod-B0002"><a href="#englishpod-B0002" class="headerlink" title="englishpod_B0002"></a>englishpod_B0002</h1><ul>
<li>headache</li>
<li>sore throat<br>it hurts</li>
<li>runny nose</li>
<li>feverish<br>feeling your body being very hot.</li>
<li>quite ill<br>very sick</li>
<li>come down with flu<br>I’m coming with cold.Begining to feel sick.</li>
<li>calling in  sick<br>You call to your office,and you are sick and won’t go to work.</li>
<li>take the day off</li>
</ul>
<h1 id="englishpod-C0003"><a href="#englishpod-C0003" class="headerlink" title="englishpod_C0003"></a>englishpod_C0003</h1><ul>
<li>I have the reservation under the name</li>
<li>mix up<br>confusion</li>
<li>overbooked<br>full</li>
<li>complimentray upgrade<br>free</li>
</ul>
<h1 id="englishpod-C0004"><a href="#englishpod-C0004" class="headerlink" title="englishpod_C0004"></a>englishpod_C0004</h1><ul>
<li>resources<br>money</li>
<li>understaffed<br>not enough people to do the job</li>
<li>the timing is just not right<br>it is not the right now</li>
<li>weight off my sholders<br>remove pressure or stress</li>
<li>give me a hand<br>help out</li>
<li>keep our cost down<br>to not to spend much money</li>
<li>intern<br>实习生</li>
</ul>
<h1 id="englishpod-C0005"><a href="#englishpod-C0005" class="headerlink" title="englishpod_C0005"></a>englishpod_C0005</h1><ul>
<li>unbelievable<br>something is amazing</li>
<li>a mile long<br>this line is really long</li>
<li>there is no way<br>it is not possible</li>
<li>cut in line<br>somebody get in front of you</li>
</ul>
<h1 id="englishpod-C0006"><a href="#englishpod-C0006" class="headerlink" title="englishpod_C0006"></a>englishpod_C0006</h1><ul>
<li>road trip<br>the car is packed. everything you need is in the car</li>
<li>fill up the tank.</li>
<li>we got all our bases coverd</li>
<li>let’s get going</li>
</ul>
<h1 id="englishpod-C0007"><a href="#englishpod-C0007" class="headerlink" title="englishpod_C0007"></a>englishpod_C0007</h1><ul>
<li>computer virus</li>
<li>froze<br>stopping working</li>
<li>infective file</li>
<li>up to date</li>
<li>I’ll be right there/down/out</li>
<li>It turns out that</li>
</ul>
<h1 id="englishpod-C0008"><a href="#englishpod-C0008" class="headerlink" title="englishpod_C0008"></a>englishpod_C0008</h1><ul>
<li>in a bit of hurry</li>
<li>contact details</li>
<li>slip my mind</li>
<li>around there</li>
<li>I’m terrible with names/faces</li>
</ul>
<h1 id="englishpd-C0009"><a href="#englishpd-C0009" class="headerlink" title="englishpd_C0009"></a>englishpd_C0009</h1><ul>
<li>inconsiderate<br>not thinking about other’s feeling</li>
<li>keep it down</li>
<li>not such a big deal</li>
<li>not a big problem</li>
<li>switch it off</li>
<li>I can’t hear a thing</li>
</ul>
<h1 id="englishpod-C0010"><a href="#englishpod-C0010" class="headerlink" title="englishpod_C0010"></a>englishpod_C0010</h1><ul>
<li>drive sales</li>
<li>promotion</li>
<li>match the competitor</li>
<li>in the market<br>in the insustry</li>
<li>It’ll never fly<br>it won’t work</li>
</ul>
<h1 id="englishpod-C0011"><a href="#englishpod-C0011" class="headerlink" title="englishpod_C0011"></a>englishpod_C0011</h1><ul>
<li>weird<br>strange  odd</li>
<li>housewarming</li>
<li>a bad feeling</li>
<li>kicked me out<br>force me to leave</li>
<li>creep me out<br>make me feel uncomfortable</li>
<li>scared and</li>
<li>I don’t know if you heard<br>gossip</li>
<li>fill me in<br>give me information</li>
<li>you scared the heck out of me</li>
</ul>
<h1 id="englishpod-C0012"><a href="#englishpod-C0012" class="headerlink" title="englishpod_C0012"></a>englishpod_C0012</h1><ul>
<li>such a mess</li>
<li>chore</li>
<li>tidy up</li>
<li>spotless<br>一尘不染</li>
<li>mall<br>many stores in there</li>
<li>grocery<br>grocery list<br>grocery shopping</li>
<li>I’m in the middle of something now.</li>
<li>I’ll be there in a second</li>
</ul>
<h1 id="englishpod-C0013"><a href="#englishpod-C0013" class="headerlink" title="englishpod_C0013"></a>englishpod_C0013</h1><ul>
<li>expenses</li>
<li>through the roof<br>off the charts</li>
<li>expenditure</li>
<li>out of control</li>
<li>go over</li>
<li>profit and loss statement</li>
</ul>
<h1 id="englishpod-B0014"><a href="#englishpod-B0014" class="headerlink" title="englishpod_B0014"></a>englishpod_B0014</h1><ul>
<li>recession</li>
<li>broke</li>
<li>loan</li>
<li>mortgage<br>a loan to help you buy an apartment</li>
<li>hit me pretty hard</li>
<li>tuition</li>
<li>can I help you?<br>what can I do for you?</li>
<li>I’m sorry to trouble you</li>
<li>on top of that</li>
<li>data debt date</li>
</ul>
<h1 id="englishpod-C0015"><a href="#englishpod-C0015" class="headerlink" title="englishpod_C0015"></a>englishpod_C0015</h1><ul>
<li>knock over<br>slip something down</li>
<li>explode</li>
<li>familiar</li>
<li>coincidence</li>
<li>I feel terrible<br>please accept my apologies</li>
<li>I don’t mean knocking over</li>
</ul>
<h1 id="englishpod-B0016"><a href="#englishpod-B0016" class="headerlink" title="englishpod_B0016"></a>englishpod_B0016</h1><ul>
<li>step on it<br>speed up slow down<br>go fast</li>
<li>have a fit<br>get angry</li>
<li>cut through<br>go through</li>
<li>short cut<br>take a short way</li>
<li>make a left/right<br>make a u turn</li>
<li>take a side street<br>take the freeway</li>
</ul>
<h1 id="englishpod-B0017"><a href="#englishpod-B0017" class="headerlink" title="englishpod_B0017"></a>englishpod_B0017</h1><ul>
<li>groom<br>man</li>
<li>bride<br>woman</li>
<li>It’s about time<br>finally at last</li>
<li>aisle</li>
<li>bridemaids</li>
<li>flower girl</li>
<li>ring bearer</li>
<li>niece nephew</li>
<li>gorgeous<br>beautiful</li>
<li>get married</li>
<li>priest</li>
</ul>
<h1 id="englishpod-D0018"><a href="#englishpod-D0018" class="headerlink" title="englishpod_D0018"></a>englishpod_D0018</h1><ul>
<li>bankrupt</li>
<li>bail out</li>
<li>injustice</li>
<li>outrage</li>
<li>break out<br>to begin suddenlly</li>
<li>have the nerve to<br>dare to do</li>
<li>financial</li>
</ul>
<h1 id="englishpod-C0019"><a href="#englishpod-C0019" class="headerlink" title="englishpod_C0019"></a>englishpod_C0019</h1><ul>
<li>eggnog</li>
<li>vehicle<br>car</li>
<li>lawer</li>
<li>appoint<br>choose</li>
<li>sleigh</li>
<li>step out<br>step out the vehicle</li>
<li>get a load of<br>look at</li>
<li>Don’t take the tone with me</li>
<li>invoice<br>发票</li>
</ul>
<h1 id="englishpod-B0020"><a href="#englishpod-B0020" class="headerlink" title="englishpod_B0020"></a>englishpod_B0020</h1><ul>
<li>struggle<br>try real hard</li>
<li>blurry<br>not clear</li>
<li>prescription</li>
<li>20-20 vision<br>Perfect eyesight</li>
<li>far sighted<br>near sighted</li>
<li>make out<br>see clearly</li>
<li>as blind as a bat</li>
<li>what seems to be the problem</li>
<li>head on<br>head on over<br>head on in</li>
</ul>
<h1 id="englishpod-C0021"><a href="#englishpod-C0021" class="headerlink" title="englishpod_C0021"></a>englishpod_C0021</h1><ul>
<li>VP<br>the vice president</li>
<li>fortune 500 company</li>
<li>implement</li>
<li>policy</li>
<li>oversee</li>
<li>go on about him</li>
<li>How’s going?</li>
<li>what do you do for a living?</li>
</ul>
<h1 id="englishpod-C0022"><a href="#englishpod-C0022" class="headerlink" title="englishpod_C0022"></a>englishpod_C0022</h1><ul>
<li>candy canes</li>
<li>booked</li>
<li>speeding<br>go too fast</li>
<li>impounded<br>held by the police<br>take your car to car jail</li>
<li>ruined<br>destoried</li>
<li>backup<br>help</li>
</ul>
<h1 id="englishpod-B0023"><a href="#englishpod-B0023" class="headerlink" title="englishpod_B0023"></a>englishpod_B0023</h1><ul>
<li>financial adviser</li>
<li>available</li>
<li>double check<br>check it again</li>
<li>sheduled<br>book it at that time</li>
<li>booked solid</li>
</ul>
<h1 id="englishpod-B0024"><a href="#englishpod-B0024" class="headerlink" title="englishpod_B0024"></a>englishpod_B0024</h1><ul>
<li>food po<br>not a good thing</li>
<li>allergic<br>It make you sick</li>
<li>check out<br>look at</li>
<li>be</li>
<li>not all that crazy about</li>
<li>tasty<br>delicious</li>
<li>in the mood for<br>have a desire</li>
<li>Do  you have any suggentions/ideas?</li>
<li>I reconmend giving it a try.<br>You’ve got to give a try.</li>
<li>platter</li>
<li>decor<br>decoration</li>
</ul>
<h1 id="englishpod-D0025"><a href="#englishpod-D0025" class="headerlink" title="englishpod_D0025"></a>englishpod_D0025</h1><ul>
<li>converage</li>
<li>pain de<br>scary</li>
<li>critical<br>important</li>
<li>outbreak</li>
<li>forcast<br>predict</li>
<li>Let’s move to the next order of business.<br>come up<br>move on</li>
<li>head up<br>take charge of</li>
<li>I’ll leave it to you.</li>
<li>contingency plan<br>a plan that prepares for a situation where things go wrong</li>
<li>vaccine<br>疫苗</li>
</ul>
<h1 id="englishpod-B0026"><a href="#englishpod-B0026" class="headerlink" title="englishpod_B0026"></a>englishpod_B0026</h1><ul>
<li>eating habits<br>the regular way you eat</li>
<li>junk food</li>
<li>transform</li>
<li>I’m stuffed</li>
<li>stick to it<br>keep doing it</li>
<li>I mean it.<br>I’m serious.</li>
<li>cut out</li>
<li>wait and see</li>
</ul>
<h1 id="englishpod-B0027"><a href="#englishpod-B0027" class="headerlink" title="englishpod_B0027"></a>englishpod_B0027</h1><ul>
<li>vacation day</li>
<li>overseas</li>
<li>unpaid leave</li>
<li>notice</li>
<li>Do you have a second?<br>Do you have a minute/sec?</li>
<li>Would you be OK with that?<br>will it be OK with that?</li>
<li>I was just wondering<br>I was just hoping that</li>
</ul>
<h1 id="englishpod-C0028"><a href="#englishpod-C0028" class="headerlink" title="englishpod_C0028"></a>englishpod_C0028</h1><ul>
<li>relieved</li>
<li>pick me up<br>come and get me</li>
<li>ordinary</li>
<li>make it up to you</li>
<li>my treat</li>
<li>twist of fate</li>
</ul>
<h1 id="englishpod-E0029"><a href="#englishpod-E0029" class="headerlink" title="englishpod_E0029"></a>englishpod_E0029</h1><ul>
<li>merging market<br>developing</li>
<li>turmoil<br>a state of confusion</li>
<li>proposed</li>
<li>hit up<br>ask for money</li>
<li>inevitable</li>
</ul>
<h1 id="englishpod-C0030"><a href="#englishpod-C0030" class="headerlink" title="englishpod_C0030"></a>englishpod_C0030</h1><ul>
<li>thoughtful</li>
<li>give me the creeps<br>make me feel uncomfortable</li>
<li>rope me into something</li>
<li>appetite<br>strong desire for food</li>
<li>get to know someone</li>
<li>why on earth</li>
</ul>
<h1 id="englishpod-B0031"><a href="#englishpod-B0031" class="headerlink" title="englishpod_B0031"></a>englishpod_B0031</h1><ul>
<li>reshedule<br>change for another day or time</li>
<li>inconvenience</li>
<li>postpone<br>delay</li>
<li>can not make it<br>can’t do something</li>
<li>this thing comes up</li>
</ul>
<h1 id="englishpod-C0032"><a href="#englishpod-C0032" class="headerlink" title="englishpod_C0032"></a>englishpod_C0032</h1><ul>
<li>chequing account</li>
<li>savings account</li>
<li>transaction</li>
<li>balance</li>
<li>overdraft</li>
<li>debit card</li>
<li>I’ll get you to</li>
<li>I need your insurace number.</li>
<li>If you could sign here?</li>
</ul>
<h1 id="englishpod-B0033"><a href="#englishpod-B0033" class="headerlink" title="englishpod_B0033"></a>englishpod_B0033</h1><ul>
<li>foul</li>
<li>ref</li>
<li>free throw</li>
<li>make a shot<br>to successful</li>
<li>3 pointer shot</li>
<li>travel<br>take more than two steps with the ball</li>
<li>screw up<br>to make a mistake</li>
<li>beer run<br>to go and get a beer</li>
</ul>
<h1 id="englishpod-D0034"><a href="#englishpod-D0034" class="headerlink" title="englishpod_D0034"></a>englishpod_D0034</h1><ul>
<li>swear in<br>swore in</li>
<li>oath<br>a promise</li>
<li>deliver<br>say a speech</li>
<li>who’s who</li>
<li>palpable</li>
<li>in a word</li>
<li>go down in history</li>
<li>my fellow Americans<br>dear</li>
</ul>
<h1 id="englishpod-C0035"><a href="#englishpod-C0035" class="headerlink" title="englishpod_C0035"></a>englishpod_C0035</h1><ul>
<li>a good fit<br>suitable for the job</li>
<li>performance</li>
<li>unreliable<br>reliable</li>
<li>productive</li>
<li>work ethic</li>
<li>coach<br>train</li>
<li>the bottom of line<br>the most important point</li>
<li>overall</li>
<li>perfectly good</li>
</ul>
<h1 id="englishpod-B0036"><a href="#englishpod-B0036" class="headerlink" title="englishpod_B0036"></a>englishpod_B0036</h1><ul>
<li>get a hold</li>
<li>stand me up<br>fail to keep the appointment to meet someone</li>
<li>priority</li>
<li>heading<br>going</li>
<li>Do you have any idea how</li>
<li>I heard it before</li>
<li>take a break<br>stop their relationship</li>
<li>decency<br>polite or moral bahavior</li>
<li>get your priorities straight<br>realize what is more important</li>
</ul>
<h1 id="englishpod-C0037"><a href="#englishpod-C0037" class="headerlink" title="englishpod_C0037"></a>englishpod_C0037</h1><ul>
<li>dumping<br>水饺</li>
<li>firecracker</li>
<li>set off</li>
<li>I can’t wait to</li>
<li>I bet</li>
<li>red envelope</li>
<li>mahjong</li>
</ul>
<h1 id="englishpod-C0038"><a href="#englishpod-C0038" class="headerlink" title="englishpod_C0038"></a>englishpod_C0038</h1><ul>
<li>vehicle</li>
<li>sedan<br>a car with four doors</li>
<li>gas mileage<br>the amount of gas used per mile</li>
<li>airbags</li>
<li>brake</li>
<li>reinforce<br>make stronger</li>
<li>I’m just browsing</li>
<li>sleep on it<br>to think about it</li>
</ul>
<h1 id="englishpod-B0039"><a href="#englishpod-B0039" class="headerlink" title="englishpod_B0039"></a>englishpod_B0039</h1><ul>
<li>heard</li>
<li>fill me in<br>tell me about something</li>
<li>career path</li>
<li>In  his early 30s</li>
</ul>
<h1 id="englishpod-B0040"><a href="#englishpod-B0040" class="headerlink" title="englishpod_B0040"></a>englishpod_B0040</h1><ul>
<li>on board<br>welcome to the company</li>
<li>about to</li>
<li>instead<br>in the  place of</li>
<li>intrepret</li>
</ul>
<h1 id="englishpod-C0041"><a href="#englishpod-C0041" class="headerlink" title="englishpod_C0041"></a>englishpod_C0041</h1><ul>
<li>posses</li>
<li>survival</li>
<li>defend<br>protect</li>
<li>rough<br>hard</li>
<li>at all costs<br>no matter what</li>
<li>stand in one’s way</li>
</ul>
<h1 id="englishpod-B0042"><a href="#englishpod-B0042" class="headerlink" title="englishpod_B0042"></a>englishpod_B0042</h1><ul>
<li>deadline</li>
<li>extension</li>
<li>run into<br>run into some problem</li>
<li>delay</li>
<li>be under control</li>
<li>put this off</li>
<li>press kit<br>groups of photos, documents, articals, and information about company given to reporters, newspapers,magazines,etc.</li>
<li>finalize<br>finish</li>
</ul>
<h1 id="englishpod-C0043"><a href="#englishpod-C0043" class="headerlink" title="englishpod_C0043"></a>englishpod_C0043</h1><ul>
<li>visa<br>签证</li>
<li>sponsor</li>
<li>invitation letter</li>
<li>ties</li>
<li>financially independent</li>
</ul>
<h1 id="englishpod-B0044"><a href="#englishpod-B0044" class="headerlink" title="englishpod_B0044"></a>englishpod_B0044</h1><ul>
<li>barely even</li>
<li>catch the news<br>hear the news</li>
<li>by the way</li>
<li>take the stairs</li>
<li>do you happen to<br>by chance</li>
</ul>
<h1 id="englishpod-C0045"><a href="#englishpod-C0045" class="headerlink" title="englishpod_C0045"></a>englishpod_C0045</h1><ul>
<li>on a break</li>
<li>seeing someone<br>dating or going out with someone</li>
<li>cheat on</li>
<li>mess this up</li>
<li>immature  </li>
<li>selfish</li>
<li>everything is going to work out just fine.</li>
<li>pull yourself together<br>calm down</li>
<li>It’s going to be alright.</li>
</ul>
<h1 id="englishpod-D0046"><a href="#englishpod-D0046" class="headerlink" title="englishpod_D0046"></a>englishpod_D0046</h1><ul>
<li>CPR</li>
<li>BP<br>blood pressure</li>
<li>hook up</li>
<li>out of woods<br>free from danger</li>
<li>defibrillator</li>
</ul>
<h1 id="englishpod-C0048"><a href="#englishpod-C0048" class="headerlink" title="englishpod_C0048"></a>englishpod_C0048</h1><ul>
<li>ticket scalper<br>黄牛</li>
<li>prestigious<br>being respected and admired for being successful or important</li>
<li>float</li>
<li>once in the lifetime</li>
<li>good thing</li>
<li>no kidding<br>I totally agree with you</li>
</ul>
<h1 id="englishpod-C0049"><a href="#englishpod-C0049" class="headerlink" title="englishpod_C0049"></a>englishpod_C0049</h1><ul>
<li>concert</li>
<li>hottest</li>
<li>fine then</li>
<li>I was wondering can I<br>Do you think<br>would you mind</li>
</ul>
<h1 id="englishpod-C0050"><a href="#englishpod-C0050" class="headerlink" title="englishpod_C0050"></a>englishpod_C0050</h1><ul>
<li>appetite</li>
<li>poison</li>
<li>points<br>suggestions</li>
<li>aroma<br>special smell</li>
<li>bitter</li>
<li>pass out<br>become unconscious</li>
<li>make yourself at home</li>
</ul>
<h1 id="englishpod-C0051"><a href="#englishpod-C0051" class="headerlink" title="englishpod_C0051"></a>englishpod_C0051</h1><ul>
<li>price range</li>
<li>shop around</li>
<li>pricey</li>
<li>a better deal</li>
<li>That’s my best offer.<br>That’s my last offer.</li>
<li>exclusive<br>not common, unique</li>
</ul>
<h1 id="englishpod-C0052"><a href="#englishpod-C0052" class="headerlink" title="englishpod_C0052"></a>englishpod_C0052</h1><ul>
<li>medium<br>12 inch<br>larger</li>
<li>pepperoni<br>a spicy sausage usually on pizza</li>
<li>olives</li>
<li>extra cheese</li>
<li>ham</li>
<li>pineapple</li>
<li>thin crust</li>
<li>would you like</li>
</ul>
<h1 id="englishpod-C0053"><a href="#englishpod-C0053" class="headerlink" title="englishpod_C0053"></a>englishpod_C0053</h1><ul>
<li>head chef<br>the main cook</li>
<li>cuisine</li>
<li>peel<br>remove the outside</li>
<li>chop</li>
<li>stir<br>mix</li>
<li>butcher</li>
<li>butter</li>
<li>in the weeds<br>you are really busy</li>
<li>run low on<br>not something left</li>
<li>do really well</li>
</ul>
<h1 id="englishpod-C0054"><a href="#englishpod-C0054" class="headerlink" title="englishpod_C0054"></a>englishpod_C0054</h1><ul>
<li>blaze<br>fire</li>
<li>in the middle of nowhere</li>
<li>first thing in the morning</li>
<li>everything seems to be order</li>
</ul>
<h1 id="englishpod-C0055"><a href="#englishpod-C0055" class="headerlink" title="englishpod_C0055"></a>englishpod_C0055</h1><ul>
<li>puck</li>
<li>key game</li>
<li>finals</li>
<li>face-off</li>
<li>goalie<br>saver</li>
<li>breakaway</li>
</ul>
<h1 id="englishpod-C0056"><a href="#englishpod-C0056" class="headerlink" title="englishpod_C0056"></a>englishpod_C0056</h1><ul>
<li>fill in</li>
<li>replicas</li>
<li>tap</li>
<li>map out</li>
<li>screw it up</li>
<li>lose your cool</li>
</ul>
<h1 id="englishpod-C0057"><a href="#englishpod-C0057" class="headerlink" title="englishpod_C0057"></a>englishpod_C0057</h1><ul>
<li>malfunction</li>
<li>ASAP<br>as soon as possible</li>
<li>practical joke</li>
<li>never mind</li>
<li>out of to</li>
<li>on your way up</li>
<li>break down<br>break in<br>break out</li>
<li>toner<br>ink used in a printer or photocopier</li>
</ul>
<h1 id="englishpod-C0058"><a href="#englishpod-C0058" class="headerlink" title="englishpod_C0058"></a>englishpod_C0058</h1><ul>
<li>turbulence</li>
<li>flight crew</li>
<li>bumpy ride</li>
<li>fasten<br>fasten your seat belt</li>
<li>lavatory</li>
<li>stow</li>
<li>refrain</li>
<li>remain seated</li>
<li>patch</li>
<li>suspend<br>stop for a short time</li>
</ul>
<h1 id="englishpod-E0059"><a href="#englishpod-E0059" class="headerlink" title="englishpod_E0059"></a>englishpod_E0059</h1><ul>
<li>CRM<br>custom relationship manager</li>
<li>custom designed<br>custom built house</li>
<li>core values</li>
<li>undisputed<br>the is no doubt</li>
<li>growth oppotunity</li>
<li>read up</li>
<li>unleash potential</li>
<li>resonate</li>
</ul>
<h1 id="englishpod-C0060"><a href="#englishpod-C0060" class="headerlink" title="englishpod_C0060"></a>englishpod_C0060</h1><ul>
<li>drag</li>
<li>tie somebody up</li>
<li>fools</li>
<li>fell for it</li>
<li>the cat is out of the bag<br>the truth is out</li>
<li>pretend</li>
<li>gullible<br>easily beliving something that is not true, eaily fooled</li>
</ul>
<h1 id="englishpod-C0061"><a href="#englishpod-C0061" class="headerlink" title="englishpod_C0061"></a>englishpod_C0061</h1><ul>
<li>sail</li>
<li>anchor</li>
<li>doggy-paddling<br>swim like a dog</li>
<li>breast stroke</li>
<li>backstroke</li>
<li>take a dip</li>
<li>for a little while</li>
</ul>
<h1 id="englishpod-C0062"><a href="#englishpod-C0062" class="headerlink" title="englishpod_C0062"></a>englishpod_C0062</h1><ul>
<li>major<br>main subject</li>
<li>minor</li>
<li>course of study</li>
<li>track<br>path</li>
<li>hence</li>
<li>pursued<br>to chase</li>
<li>strive<br>to try real hard</li>
<li>breadth</li>
<li>implement</li>
<li>postgraduate<br>masters or PH.D;</li>
<li>initiative<br>倡议</li>
<li>churn rate<br>客户流失率</li>
<li>coordinate<br>协调</li>
</ul>
<h1 id="englishpod-C0063"><a href="#englishpod-C0063" class="headerlink" title="englishpod_C0063"></a>englishpod_C0063</h1><ul>
<li>certainly</li>
<li>may I take your name?</li>
<li>monmentarily<br>in a short</li>
<li>ready for</li>
</ul>
<h1 id="englishpod-C0064"><a href="#englishpod-C0064" class="headerlink" title="englishpod_C0064"></a>englishpod_C0064</h1><ul>
<li>sleep with</li>
<li>confess<br>you tell a secret that you are hiding</li>
<li>overwhelm</li>
<li>jelousy</li>
<li>jerk<br>stupid and mean person</li>
<li>bastard</li>
<li>bun in the oven<br>pregnant</li>
<li>I can’t help myself</li>
<li>come into the picture<br>appear into one’s life</li>
<li>cheerleading squad<br>啦啦队</li>
</ul>
<h1 id="englishpod-C0065"><a href="#englishpod-C0065" class="headerlink" title="englishpod_C0065"></a>englishpod_C0065</h1><ul>
<li>technical acument</li>
<li>excel</li>
<li>head</li>
<li>struggle</li>
<li>punctual<br>punctuality</li>
<li>adress<br>deal with</li>
<li>fit</li>
<li>acumen<br>the ability to think clearly and make good decisions</li>
</ul>
<p>#</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/03/变量消除/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/03/变量消除/" itemprop="url">变量消除</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-03T11:02:58+08:00">
                2018-04-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="精确推断"><a href="#精确推断" class="headerlink" title="精确推断"></a>精确推断</h1><p>精确推断的实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。</p>
<p>精确推断有以下算法：</p>
<ul>
<li>变量消除</li>
<li>消息传递</li>
<li>团树</li>
</ul>
<p>近似推断有一下算法：</p>
<ul>
<li>随机模拟</li>
<li>马尔可夫链的蒙特卡罗方法</li>
<li>变分算法</li>
</ul>
<p>本文主要主要是针对精确推断算法中的变量消除算法，计算变量的边际分布或条件分布是一个NP难问题，会随着极大团的增长呈指数增长。近似推断是在较低的时间复杂度下，或者原问题的近似解，这种方法更有一般的实用性。</p>
<h2 id="变量消除"><a href="#变量消除" class="headerlink" title="变量消除"></a>变量消除</h2><h3 id="有向图"><a href="#有向图" class="headerlink" title="有向图"></a>有向图</h3><p>考虑如下的有向图概率图模型，图中共有五个变量：A,B,C,D,E。如果我们假定每个变量有n个值，那么直接的概率描述就是联合概率密度，那么复杂度为$n^5$。如果我们计算$P(E=e)$，那么我们就要计算：<br>$$P(e)=\sum_{a,b,c,d}P(a,b,c,d,e)$$<br>可是这个计算过程需要对另外四个变量求和(边际化)，那么就需要$n^4$的复杂度。</p>
<p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E7%A4%BA%E4%BE%8B-%E6%97%A0%E5%90%91%E5%9B%BE.png" alt=""></p>
<p>我们可以将上面的联合概率密度$P(a,b,c,d,e)$进行因式分解：<br>$$P(e)=\sum_{a,b,c,d}P(a,b,c,d,e)=\sum_{a,b,c,d}P(a)P(b\mid a)P(c\mid b)P(d\mid c)P(e\mid d)$$<br>假设推断目标是计算边缘概率密度P(e)，那么P(c|b)，P(d|c)，P(e|d)与a无关，将P(a)和P(b|a)的乘积相加。<br>$$P(e)=\sum_{a,b,c,d}P(a)P(b\mid a)P(c\mid b)P(d\mid c)P(e\mid d)$$   $$=\sum_{b,c,d}P(c\mid b)P(d\mid c)P(e\mid d)\sum_a P(a)P(b\mid a)$$    $$=\sum_{b,c,d}P(c\mid b)P(d\mid c)P(e\mid d)P(b)$$<br>下面按照b,c,d的顺序进行求和，最后可以得到$P(e)=\sum_d P(e\mid d)P(d)$。使用该方法可以一次减少一个变量。每次只需要执行$O(n^2)$操作，最终复杂度为$O(kn^2)$。</p>
<h3 id="在HMM上进行变量消除"><a href="#在HMM上进行变量消除" class="headerlink" title="在HMM上进行变量消除"></a>在HMM上进行变量消除</h3><p>参考[4]中笔记对于该例的介绍，主要是利用当前变量相关变量和非相关的变量进行变量消除，每步消除一个变量，最终复杂度为$O(Tn^2)$，其中T表示变量的个数。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<h3 id="无向图"><a href="#无向图" class="headerlink" title="无向图"></a>无向图</h3><p>考虑如下的无向图概率图链模型，总共有五个变量A,B,C，D，E，计算联合概率密度P(e)。<br>$$ P(e)=\sum_{a,b,c,d}\frac{1}{Z}\phi(a,b)\phi(b,c)\phi(c,d)\phi(d,e)$$<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4-%E6%97%A0%E5%90%91%E5%9B%BE.png" alt=""><br>具体计算方法同有向图相似，超级长的公式，不想打，下面用截图来表示。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B.png" alt=""><br>最后通过正则化可以获得最终的概率：<br>$$P(e)=\frac{m_d(e)}{\sum_e m_d(e)}$$</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>[3] 周志华. 机器学习[M]. 清华大学出版社, 2016.<br>[4] <a href="http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A" target="_blank" rel="noopener">http://people.eecs.berkeley.edu/~jordan/prelims/?C=N;O=A</a><br>注：本文主要参考[1]中第4讲视频以及笔记，参考[2]中第9章，参考[3]中第14章，参考[4]中第3章。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/23/概率图模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/23/概率图模型/" itemprop="url">概率图模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-23T16:35:46+08:00">
                2018-03-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="贝叶斯网络-Bayesian-Network"><a href="#贝叶斯网络-Bayesian-Network" class="headerlink" title="贝叶斯网络 Bayesian Network"></a>贝叶斯网络 Bayesian Network</h1><p>贝叶斯网络是概率图模型的一种结构，通过有向无环图来表示模型中的关联性。在特定的图结构中，节点表示随机变量，有向边表示相连的变量之间的因果关系。</p>
<h2 id="贝叶斯网的链式法则"><a href="#贝叶斯网的链式法则" class="headerlink" title="贝叶斯网的链式法则"></a>贝叶斯网的链式法则</h2><p>$$ P(X_1, X_2, …, X_n) = \Pi_{i=1:n}P(X_i \mid Parents(X_i)) $$</p>
<h2 id="I-Map和P-Map"><a href="#I-Map和P-Map" class="headerlink" title="I-Map和P-Map"></a>I-Map和P-Map</h2><p>令P为X上的分布，$I(P)$是满足$(X&perp; Y\mid Z)$的独立性断言的集合。I(G)表示图G上独立性关系的集合，如果$ I(G) \subseteq  I(P) $，则可成G为P的I-Map。<br>显然只要某个图的独立性关机集合是I(P)的子集，其对应的图就是I-Map，所以I-Map有很多个，只有当I(G)=I(P)时，对应的图可以等价的表示这个概率分布，G就叫做P的P-Map(Perfect-Map)。</p>
<h2 id="独立性"><a href="#独立性" class="headerlink" title="独立性"></a>独立性</h2><h3 id="局部马尔科夫独立性"><a href="#局部马尔科夫独立性" class="headerlink" title="局部马尔科夫独立性"></a>局部马尔科夫独立性</h3><p>记$ Pa_{x_i} $是图G中$ X_i $的父节点，将图G中不是$X_i$后代的子节点变量记为$ NonDescendants_{X_i} $。G满足如下的条件独立性论断$I_l(G)$：$ X_i &perp; NonDescendants_{X_i}\mid Pa_{x_i}:\forall i$，也就是说在</p>
<p>给定父节点的情况下，子节点间相互独立。</p>
<h3 id="全局马尔科夫独立性"><a href="#全局马尔科夫独立性" class="headerlink" title="全局马尔科夫独立性"></a>全局马尔科夫独立性</h3><p>全局的马尔科夫独立性与d-分离有关，如果在给定Z的情况下，节点X和Y独立，则X和Y是D-separation。</p>
<p>迹是三个变量相连的路径，比如X，Y，Z。迹有三种形式：</p>
<ul>
<li>Causal Trail $ X \to Z \to Y $: 有效当且仅当Z不可观。</li>
</ul>
<ul>
<li>Evidential Trail $X \leftarrow Z \leftarrow Y$: 有效当且仅当Z不可观。</li>
</ul>
<ul>
<li>Common Cause $X \leftarrow Z \to Y$：有效当且仅当Z不可观。</li>
</ul>
<ul>
<li>Common Effect $ X \to Z \leftarrow Y $：有效当且仅当Z（或者是其他后代）可观。</li>
</ul>
<p>与d-分离想对应的独立性的集合用I(G)表示：<br>$$I(G)=\lbrace(X &perp; Y\mid Z):d-sep_G(X;Y\mid Z)\rbrace $$<br>上面的集合也叫做全局马尔科夫的独立性。</p>
<h2 id="可靠性与完备性"><a href="#可靠性与完备性" class="headerlink" title="可靠性与完备性"></a>可靠性与完备性</h2><ul>
<li>d-分离的可靠性与贝叶斯网络因子分离定理有关,如果分布P根据G因子分解，那么，$I(G)\subseteq I(P)$。</li>
<li>对于任意的分布P根据G因子分解，如果$ (X &perp; Y|Z) \in I(P)$，那么就有$dsep_G(X; Y\mid Z)\in I(P)$</li>
<li>G是一个贝叶斯网络结构的图，如果给定Z时X和Y不是在图G中d-分离的，那么X和Y在某些图G上的因子分解分布P中相互依赖。</li>
<li>对于几乎所有的在G上的因子分解的分布P，$I(P)=I(G)$。几乎所有指的是对于参数化条件概率空间中除了测度为0的分布。</li>
</ul>
<h1 id="马尔科夫网络-Markov-Network"><a href="#马尔科夫网络-Markov-Network" class="headerlink" title="马尔科夫网络 Markov Network"></a>马尔科夫网络 Markov Network</h1><p>上面是有向图模型，又叫做贝叶斯网络，下面我们来看一下无向图模型，也被叫做马尔科夫网。<br>如下的式子必须使用马尔科夫网：<br>$$A \perp C\mid \lbrace B, D \rbrace, B \perp D\mid \lbrace A, B\rbrace$$<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%97%A0%E5%90%91%E5%9B%BE.jpg" alt=""><br>clique就是指的强连通的团，通常翻译为团，每个团会定义一个势函数(potential function)。<br>无向图模型可以通过一个给定的无向图来表示概率分布$P(X_1,…X_n)$，每一个在图H中的团$c\in C$代表一组正势函数$\psi_c$，比如：<br>$$P(X_1, …, X_n)=\frac{1}{Z}\prod_{c\in C}\psi_c(X_c)$$</p>
<p>其中Z是配分函数(partition function)，是一个归一化的常数：<br>$$Z=\sum_{X_1, …, X_n}\prod_{c\in C}\psi_c(X_c)$$</p>
<h2 id="全局马尔科夫独立性-1"><a href="#全局马尔科夫独立性-1" class="headerlink" title="全局马尔科夫独立性"></a>全局马尔科夫独立性</h2><p>如果在给定节点集B时，任意两个节点A和C中的节点之间没有路径，那么则称B在图H中分离A和B。<br>如果对于任意不连接的A，B，C，比如B分离A和C，也就说在给定C的情况下，A和C独立，那么该概率分布满足全局马尔科夫独立性。<br>$$I(H)=\lbrace A \perp C\mid B:sep_H(A;C\mid B)\rbrace$$</p>
<h3 id="完备性"><a href="#完备性" class="headerlink" title="完备性"></a>完备性</h3><p>H是一个马尔科夫网结构，如果在给定Z时，X与Y在图H中不可分离，则在给定Z时，X与Y在因子分解的分布中存在依赖关系。</p>
<h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><ul>
<li>P为X上的正分布，而H为X上的一个马尔科夫网结构。如果P是在图H上的吉布斯分布，那么H是P的I-Map。</li>
<li>P为X上的分布，而H为X上的一个马尔科夫网结构。如果H是P的一个I-Map，则P是可以再H上分解的一个吉布斯分布。</li>
</ul>
<h2 id="局部马尔科夫独立性-1"><a href="#局部马尔科夫独立性-1" class="headerlink" title="局部马尔科夫独立性"></a>局部马尔科夫独立性</h2><p>H=(V,E)是一个马尔科夫网，与H相关的成对独立性定义如下：<br>$$I_P(H)=\lbrace (X \perp Y \mid V-\lbrace X, Y\rbrace):X-Y\notin H\rbrace$$<br>对于给定的图H=(V,E),X在H中的马尔科夫毯$$MB_H(X)$$定义为X在H中的近邻。与H相关的局部独立性定义如下：<br>$$I_l(H)=\lbrace(X \perp V-\lbrace X\rbrace -MB_{H}(X)\mid MB_{H}(X)):X\in V\rbrace$$</p>
<h2 id="局部马尔科夫性与全局马尔科夫性的联系"><a href="#局部马尔科夫性与全局马尔科夫性的联系" class="headerlink" title="局部马尔科夫性与全局马尔科夫性的联系"></a>局部马尔科夫性与全局马尔科夫性的联系</h2><p>$$P\models I_l(H)\Rightarrow P\models I_P(H)$$  $$P=I(H)\Rightarrow P\models I_l(H)$$  $$P&gt;0\  and\  P\models I_p(H) \Rightarrow P\models I(H)$$<br>推论：对于一个正分布P，全局、局部和成对独立性是等价的。</p>
<h2 id="团-cliques"><a href="#团-cliques" class="headerlink" title="团(cliques)"></a>团(cliques)</h2><p>团是一个完全子图(complete graph)，最大团是最大可能的完全子图。最大的团记作max-clique，不是最大的团记作sub-cliques。</p>
<h2 id="对数线性模型"><a href="#对数线性模型" class="headerlink" title="对数线性模型"></a>对数线性模型</h2><p>$$P(X_1,…,X_n)=\frac{1}{Z} exp[-\sum_{i=1}^k \omega_c(X_c)]$$</p>
<h2 id="Perfect-Maps"><a href="#Perfect-Maps" class="headerlink" title="Perfect Maps"></a>Perfect Maps</h2><p>只要分布的分离特性与独立特性一致，马尔科夫网就可以是分布的一个P-Map。然而，就像是贝叶斯网，不是所有的分布都能用无向图来表示。实际上，无向图和有向图不恩能够完全的表达分布的空间。</p>
<h2 id="模型实例"><a href="#模型实例" class="headerlink" title="模型实例　"></a>模型实例　</h2><h3 id="波尔兹曼机"><a href="#波尔兹曼机" class="headerlink" title="波尔兹曼机"></a>波尔兹曼机</h3><p>波尔兹曼机的连接方式如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/波尔兹曼机示意图.png" alt=""><br>波尔兹曼机是一个全连接的图，每条无向边表示一对依赖关系，节点是二值变量。<br>上图的联合概率分布如下：<br>$$<br>P(x_1, x_2, x_3, x_4)=\frac{1}{Z}exp\lbrace \sum_{i,j}\phi_{ij}(x_i, x_j)\rbrace<br>=\frac{1}{Z}exp\lbrace\sum_{i,j}\theta_{ij}x_ix_j+\sum_i\alpha_i x_i + C \rbrace<br>=\frac{1}{Z}exp\lbrace(x-\mu)^T\Theta(x-\mu)\rbrace<br>$$</p>
<h3 id="受限波尔兹曼机"><a href="#受限波尔兹曼机" class="headerlink" title="受限波尔兹曼机"></a>受限波尔兹曼机</h3><p>受限波尔兹曼机通常有很多层构成，每个层中有两个子层，一个隐藏层，另一个是可见层。RBM的概率分布函数：<br>$$P(x,h\mid \theta)=exp\lbrace\sum_i\theta_i\phi_i(x_i)+\sum_j\theta_j\phi_j(h_j)+\sum_{i,j}\theta_{i,j}\phi_{i,j}(x_i,h_j)-A(\theta)\rbrace$$<br>RBM的因子是边际相关的，在给定可观的节点的情况下因子是条件独立的。可以进行迭代吉布斯采样。</p>
<h3 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h3><p>条件随机场是一种判别式的无向图模型，通过观测序列得到标记序列。CRF并没有假定各个特征值之间的独立性，概率分布如下：<br>$$P_\theta(y\mid x)=\frac{1}{Z}exp\lbrace \sum_{e\in E,k}\lambda_k f_k(e,y\mid_e,s)+\sum_{v\in V,k}\mu_k g_k(v,y\mid_v,x)\rbrace$$<br>其中，x是观测序列(数据序列)，y是标记序列，v是标记随机变量集V的顶点，e是来自边集E的边。k是特证序号，$f_k$是固定的二值特征函数，$g_k$是给定的二值顶点特征。$\theta=(\lambda_1, …, \lambda_n;\mu_1, …, \mu_n)$是需要估计的参数$y\mid_e$是由e定义的y的集合，$y\mid_v$是由v定义的y的集合。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%9C%BA.png" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>无向图模型表明了变量间的相互关系（relatedness），而不是因果关系（causality）。</li>
<li>无向图可以定义联合或者独立分布。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>Koller D, Friedman N. Probabilistic graphical models: principles and techniques[M]. MIT press, 2009.<br>周志华. 机器学习[M]. 清华大学出版社, 2016.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/01/git使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/01/git使用/" itemprop="url">git使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-01T09:20:45+08:00">
                2018-02-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技术/" itemprop="url" rel="index">
                    <span itemprop="name">技术</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>创建新的仓库 <code>git init</code><br>从服务器上克隆库 <code>git clone 路径</code><br>添加和提交<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git pull origin <span class="literal">master</span></span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">"first commit"</span></span><br><span class="line">git push origin <span class="literal">master</span></span><br></pre></td></tr></table></figure></p>
<p>基本可以用来保存文件和从服务器上面下载代码，后面的还没有用到，用到再往这篇博客上面加。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="HJY" />
            
              <p class="site-author-name" itemprop="name">HJY</p>
              <p class="site-description motion-element" itemprop="description">HJY的装逼小站</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hjyai94" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HJY</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.3"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
