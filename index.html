<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="HJY的装逼小站">
<meta property="og:type" content="website">
<meta property="og:title" content="HJY">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="HJY">
<meta property="og:description" content="HJY的装逼小站">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HJY">
<meta name="twitter:description" content="HJY的装逼小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'HR62QHMRVP',
      apiKey: '5003cc57039452aa0e152bdb9198ed17',
      indexName: 'dev_NAME',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>HJY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HJY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">昨夜西风凋碧树，独上高楼望尽天涯路。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/31/VGG16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/31/VGG16/" itemprop="url">VGG16</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-31T17:43:18+08:00">
                2018-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VGG16模型结构"><a href="#VGG16模型结构" class="headerlink" title="VGG16模型结构"></a>VGG16模型结构</h1><p>VGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经<br>网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的<br>卷积核而言，减少了参数。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg" alt=""></p>
<h2 id="VGG16模型处理过程"><a href="#VGG16模型处理过程" class="headerlink" title="VGG16模型处理过程"></a>VGG16模型处理过程</h2><p>以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。</p>
<ol>
<li>输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。</li>
<li>做MaxPool，池化尺寸为2x2，步长(stride)为2。</li>
<li>经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。</li>
<li>MaxPool，尺寸变为56x56x128。</li>
<li>256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。</li>
<li>MaxPool，尺寸变为28x28x256。</li>
<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。</li>
<li>MaxPool，尺寸变为14x14x512。</li>
<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。</li>
<li>MaxPool，尺寸变为7x7x512。</li>
<li>与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。</li>
<li>通过softmax输出1000个预测结果。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png" alt=""><br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png" alt=""></li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cnblogs.com/vipyoumay/p/7884472.html" target="_blank" rel="noopener">http://www.cnblogs.com/vipyoumay/p/7884472.html</a><br>[2] <a href="https://my.oschina.net/u/876354/blog/1634322" target="_blank" rel="noopener">https://my.oschina.net/u/876354/blog/1634322</a><br>[3]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/19/MC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/MC/" itemprop="url">MC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T15:00:18+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Point-estimator"><a href="#Point-estimator" class="headerlink" title="Point estimator"></a>Point estimator</h1><p>当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。<br>共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。</p>
<h1 id="MC方法"><a href="#MC方法" class="headerlink" title="MC方法"></a>MC方法</h1><p>为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/19/variational-inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/variational-inference/" itemprop="url">variational inference</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T11:15:17+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p># </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/11/cs131笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/11/cs131笔记/" itemprop="url">cs131笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-11T14:31:40+08:00">
                2018-07-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>filtering<br>Forming a new image whose pixel values are transformed from original pixel values.</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/14/Ubuntu中出现的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/14/Ubuntu中出现的问题/" itemprop="url">记录Ubuntu中出现的问题及解决方案</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-14T00:00:00+08:00">
                2018-06-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技术/" itemprop="url" rel="index">
                    <span itemprop="name">技术</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="执行sudo-apt-get-update-出错"><a href="#执行sudo-apt-get-update-出错" class="headerlink" title="执行sudo apt-get update 出错"></a>执行sudo apt-get update 出错</h1><p>出现错误如下：<br><code>E: Some index files failed to download, they have been ignored, or old ones used instead&#39;
出现无法更新的情况，可以在</code>/etc/apt/sources.list.d`中删除对应错误名字的文件。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/10/高斯图模型图和伊辛图模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/10/高斯图模型图和伊辛图模型/" itemprop="url">高斯图模型图和伊辛图模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-10T11:01:03+08:00">
                2018-06-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。</p>
<h1 id="高斯图模型"><a href="#高斯图模型" class="headerlink" title="高斯图模型"></a>高斯图模型</h1><p>高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：<br>$$ p(x\mid \mu, \Sigma) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp[-\frac{1}{2}(x-\mu)^T \Sigma^{-T}(x-\mu)] $$<br>其中$\mu$是均值，$\Sigma$是协方差矩阵。令$\mu=0$和精度矩阵为$Q=\Sigma^{-1}$，有：<br>$$ p(x_1, x_2, …, x_p\mid \mu=0, Q) = \frac{|Q|^{1/2}}{(2\pi)^{n/2}}exp[-\frac{1}{2}\sum_i q_{ii}(x_i)^2 - \sum_{i&lt;j}q_{ij}x_ix_j] $$<br>这就是条件随机场，定义于成对边和节点上。</p>
<h1 id="协方差矩阵与精度矩阵"><a href="#协方差矩阵与精度矩阵" class="headerlink" title="协方差矩阵与精度矩阵"></a>协方差矩阵与精度矩阵</h1><p>协方差矩阵有一个重要的性质是：当$\Sigma_{i,j}=0$有$x_i\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\Sigma_{i,j}^{-1}=0$时$x_i\perp x_j\mid x_{-ij}$。</p>
<h1 id="利用LASSO进行网络学习"><a href="#利用LASSO进行网络学习" class="headerlink" title="利用LASSO进行网络学习"></a>利用LASSO进行网络学习</h1><h2 id="LASSO回归"><a href="#LASSO回归" class="headerlink" title="LASSO回归"></a>LASSO回归</h2><p>对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。<br>$$\hat{\beta_1} = argmin_{\beta_1}\parallel Y - X\beta_1\parallel^2 + \lambda\parallel\beta_1\parallel_1$$<br>其中，$\beta_1$是节点1的参数，Y是是对节点1的独立观测值。<br>具体过程如图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png" alt=""></p>
<h2 id="理论条件"><a href="#理论条件" class="headerlink" title="理论条件"></a>理论条件</h2><ul>
<li>Dependency Condition: Relevant Covariates are not overly dependent</li>
<li>Incoherence Condition: Large number of irrelevant covariates can’t be too correlated with relevant covariates</li>
<li>Strong concentration bounds: Sample quantities coverge to expected values quickly</li>
</ul>
<h1 id="时变网络"><a href="#时变网络" class="headerlink" title="时变网络"></a>时变网络</h1><h2 id="KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression"><a href="#KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression" class="headerlink" title="KELLER: Kernel Weightd $L_1$-regularized logistic Regression"></a>KELLER: Kernel Weightd $L_1$-regularized logistic Regression</h2><p>对时变网络的结构进行估计，可以采用KELLER的方法解决：<br>$$ \hat{\theta_i^t} = argmain_{\theta_i^t}l_w(\theta_i^t) + \lambda_1\parallel\theta_t^t \parallel_1 $$<br>其中$l_w(\theta_i^t) = \sum_{t’=1}^T w(x^{t’}; x^t)log\ P(x_i^{t’}\mid x_{-i}^x^{t’}, \theta_i^t)$。权值$w(x^{t’}; x^t)$决定了在时间$t’$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。<br><img src="" alt=""><br>给定时间$t^{\ast}$，权值可以写成：<br>$$ w_t(t^{\ast}) = \frac{K_{h_n}(t-t^{\ast})}{\sigma_{t’\in T^n} K_{h_n}(t’-t^{\ast})} $$<br>对于一些平滑的核$K_{h_n}$。</p>
<h2 id="TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression"><a href="#TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression" class="headerlink" title="TESLA: Temporally Smoothed $L_1$-regularized logistic regression"></a>TESLA: Temporally Smoothed $L_1$-regularized logistic regression</h2><p>TESLA对于一个节点的参数优化是基于所有的时间步的：<br>$$ \hat{\theta_i^T}, …, \hat{\theta_i^T} = argmin\sum_{i=1}^T l_{avg}(\theta_i^t) + \lambda_1 \sum_{t=1}^T \parallel\theta_{-1}^t \parallel_1 + \lambda_2\sum_{t=1}^T \parallel \theta_i^t - \theta_i^{t-1} \parallel $$<br>其中，$l_{avg}(\theta_i^t) = \frac{1}{N^t}\sum_{d=1}^{N^t} log\ P(x_{d,i}^t\mid x_{d, -i}^t, \theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/31/HMM和CRF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/31/HMM和CRF/" itemprop="url">HMM和CRF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-31T09:49:19+08:00">
                2018-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h1><p>隐马尔可夫模型如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<h2 id="公式表达"><a href="#公式表达" class="headerlink" title="公式表达"></a>公式表达</h2><p>对于隐马尔可夫模型，通常有三组参数：<br>$$ trasition\ probability\ matrix\ A: p(y_t^j = 1\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\ probability: p(y_1)\sim Multinomial(\pi_1, \pi_2, …, \pi_M) $$    $$ emission\ probabilies: p(x_t\mid y_t^i)\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K}) $$</p>
<h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><ul>
<li><p>前向算法<br>$$ \alpha_t^k \equiv\mu_{t-1\rightarrow}(k)=P(x_1, x_2, …, x_t, y_t^k=1) $$<br>$$ \alpha_t^k = p(x_t\mid y_t^k=1)\sum_i \alpha_{t-1}^ia_{i,k} $$</p>
</li>
<li><p>后向算法<br>$$ \beta_t^k \equiv \mu_{t\leftarrow t+1}(k)=P(x_{t+1}, …, x_T\mid y_t^k=1) $$<br>$$ \beta_t^k = \sum_i a_{k,i}p(x_{t+1}\mid y_{t+1}^i = 1)\beta_{t+1}^i $$</p>
</li>
</ul>
<p>对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。<br>$$ \gamma_t^i = p(y_t^i = 1\mid x_{1:T})\propto \alpha_t^i\beta_t^i =\sum_j \xi_t^{i,j} $$<br>其中有定义：<br>\begin{equation}\begin{split} \xi_t^{i,j} &amp;= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\<br>&amp;\propto \mu_{t-1\rightarrow t}(y_t^i=1)\mu_{t\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\mid y_{t+1})p(y_{t+1}\mid y_t) \\<br>&amp;= \alpha_t^i\beta_{t+1}^j a_{i,j} p(x_{t+1}\mid y_{t+1}^i=1) \\<br>\end{split}\end{equation}<br>具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。<br>在Matlab中可以将公式用向量表示，这样方便处理。<br>\begin{equation}\begin{split} &amp;B_t(i)=p(x_t\mid y_t^i=1)\\<br>&amp; A(i,j)=p(y_{t+1}^j=1\mid y_t^i=1) \\<br>&amp; \alpha_t = (A^T\alpha_{t-1}).\ast B_t \\<br>&amp; \beta_t = A(\beta_{t+1}.\ast B_{t+1}) \\<br>&amp; \xi_t = (\alpha_t(\beta_{t+1}.\ast B_{t+1})^T).\ast A  \\<br>&amp; \gamma_t = \alpha_t.\ast \beta_t \\<br>\end{split}\end{equation}</p>
<h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。<br>$$ a_{ij}^{ML} = \frac{\sum_n\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\sum_n\sum_{t=2}^T y_{n,t-1}^i} $$<br>$$ b_{ik}^{ML} = \frac{\sum_n\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\sum_n\sum_{t=2}^T y_{n,t}^i} $$<br>使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。</p>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：<br>$$ l_c(\theta;x,y)=lop\ p(x,y)=log\prod_n (p(y_{n,1})\prod_{t=1}^T p(y_{n,t}\mid y_{n,t-1})\prod_{t=1}^T p(x_{n,t}\mid y_{n,t})) $$<br>完全对数似然期望是：<br>$$ \langle l_c(\theta;x,y)\rangle = \sum_n (\langle y_{n,1}^i \rangle_{p(y_{n,1}\mid x_n)}log\ \pi_i) + \sum_n\sum_{t=2}^T (\langle y_{n,t-1}^i y_{n,t}^j\rangle_{p(y_{n,t-1},y_{n,t}\mid x_n)}log\ a_{i,j}) + \sum_n\sum_{t=1}^T (x_{n,t}^k\langle y_{n,t}^i\rangle_{p(y_{n,t}\mid x_n)}log\ b_{i,k}) $$</p>
<ul>
<li>E步：<br>$$ \gamma_{n,t}^i = \langle  y_{n,t}^i\rangle = p(y_{n,t}^i = 1\mid x_n) $$    $$ \xi_{n,t}^{i,j} = \langle y_{n,t-1}^i y_{n,t}^j\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\mid x_n) $$</li>
<li>M步：<br>$$ \pi_i=\frac{\sum_n \gamma_{n,1}^i}{N}, a_{i,j}=\frac{\sum_n\xi_{n,t}^{i,j}} {\sum_n\sum_{t=1}^{i,j} \gamma_{n,t}^i},  b_{ik}=\frac{\sum_N\sum_{t=1}^T \gamma_{n,t}^i x_{n,t}^k} {\sum_n\sum_{t=1}^{T-1}\gamma_{n,t}^i} $$</li>
</ul>
<h3 id="HMM的缺点"><a href="#HMM的缺点" class="headerlink" title="HMM的缺点"></a>HMM的缺点</h3><p>HMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\mid X)$，通过这样的考虑，有了一个新的模型MEMM。</p>
<h1 id="MEMM"><a href="#MEMM" class="headerlink" title="MEMM"></a>MEMM</h1><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>MEMM结构如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png" alt=""><br>MEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。<br>$$ P(y_{1:n}\mid x_{1:n}) = \prod_{i=1}^{n} P(y_i\mid y_{i-1},x_{1:n}) = \prod_{i=1}^n \frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>MEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。</p>
<h1 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h1><p>一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。</p>
<h2 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h2><p>CRF结构如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png" alt=""><br>\begin{equation}\begin{split} P(Y\mid X) &amp;= \frac{1}{Z(X)}\prod_{i=1}^n \phi(y_i,y_{i-1},X) \\<br>&amp;= \frac{1}{Z(X, \lambda, \mu)}exp(\sum_{i=1}^T(\sum_k \lambda_k f_k(y_i, y_{i-1}, X) + \sum_l \mu_l g_l(y_i, X))) \\<br>\end{split}\end{equation}<br>其中，$Z(X,\lambda, \mu)=\sum_y exp(\sum_{i=1}(\sum_k \lambda_k f_k(y_i, y_{i-1}, X) + \sum_l \mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。</p>
<p>##　推断<br>所谓的推断问题就是在CRF给定参数$\lambda$和$\mu$，我们可以找到$y^{\ast}$使得$P(y\mid x)$最大。<br>$$ y^{\ast} = argmax_y exp(\sum_{i=1}^n (\sum_k \lambda_k f_k (y_i, y_{i-1}, X) + \sum_l \mu_l g_l (y_i, X))) $$<br>因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。</p>
<h2 id="学习-1"><a href="#学习-1" class="headerlink" title="学习"></a>学习</h2><p>尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\lbrace x_d, y_d\rbrace_{d=1}^N$，寻找到最优的$\lambda^{\ast}$和$\mu^{\ast}$。<br>\begin{equation}\begin{split} \lambda^{\ast}, \mu^{\ast} &amp;= argmax_{\lambda, \mu}\prod_{d=1}^N P(y_d\mid x_d, \lambda, \mu) \\<br>&amp;= argmax_{\lambda, \mu}\prod_{d=1}^N \frac{1}{Z(x_d, \lambda, \mu)}exp(\sum_{i=1}^n (\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \mu^T g(y_{d,i}, x_d))) \\<br>&amp;= argmax_{\lambda, \mu}\sum_{d=1}^T (\sum_{i=1}^n(\lambda^T f(y_{d,i}, y_{d, i-1}) + \mu^T g(y_{d, i}, x_d)) - log\ Z(x_d, \lambda, \mu)) \\<br>\end{split}\end{equation}<br>对$\lambda$求偏导：<br>$$ \Delta_{\lambda}L(\lambda, \mu) = \sum_{d=1}^N(\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \sum_y (P(y\mid x_d) \sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$<br>从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。<br>解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。<br>\begin{equation}\begin{split} \sum_y (P(y\mid x_d)\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &amp;= \sum_{i=1}^n(\sum_y f(y_i, y_{i-1}, x_d) P(y\mid x_d)) \\<br>&amp;= \sum_{i=1}^n(\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\mid x_d)) \\<br>\end{split}\end{equation}<br>这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。<br>下面使用校准势来计算特征期望：<br>\begin{equation}\begin{split} \Delta_{\lambda}L(\lambda, \mu) &amp;= \sum_{d=1}^N(\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \sum_y (P(y\mid x_d) \sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\<br>&amp;= \sum_{d=1}^N(\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \sum_{y_i, y_{i-1}}\alpha’(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\<br>\end{split}\end{equation}<br>其中$\alpha’(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\mid x_d)$。我们可以使用梯度上升法学习参数。<br>$$ \lambda^{(t+1)} = \lambda^{(t)} + \eta\Delta_{\lambda}L(\lambda^{(t)}, \mu^{(t)}) $$     $$ \mu^{(t+1)} = \mu^{(t)} + \eta\Delta_{\mu}L(\lambda^{(t)}, \mu^{(t)}) $$<br>在实际中，我们会加入正则项来提高参数的泛化能力。<br>$$ \lambda^{\ast}, \mu^{\ast} = argmax_{\lambda, \mu}\sum_{d=1}^N log\ P(y_d\mid x_d, \lambda, \mu) - \frac{1}{2\sigma^2} (\lambda^T \lambda + \mu^T\mu) $$<br>第二项叫做高斯先验，因为我们想让$\lambda^{\ast},\mu^{\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。<br>从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>EM算法适应于处理存在隐变量的最大似然估计问题。</li>
<li>GMM和HMM被用于对静态和动态混合模型建模。</li>
<li>实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。</li>
<li>HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。</li>
<li>CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。</li>
<li>具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.<br>注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\sum，本文之前使用的都是\Sigma，后面也会使用\sum。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/25/EM算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/25/EM算法/" itemprop="url">EM算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-25T19:45:46+08:00">
                2018-05-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="混合高斯模型"><a href="#混合高斯模型" class="headerlink" title="混合高斯模型"></a>混合高斯模型</h1><p>$$ p(x_n\mid , \Sigma) = \Sigma_k \pi_k N(x\mid \mu, \Sigma_k) $$<br>其中$\pi_k$是混合参数，$N(x\mid \mu_k, \Sigma_k)$是其对应的高斯分布。<br>对于完全可观的独立同分布，对数似然可以分解为和的形式。<br>$$ l_c(\theta;D) = log p(x,z\mid \theta) = log p(z\mid \theta_z) + log p(z\mid z, \theta_x) $$<br>因为隐变量的存在，所有的变量会通过边缘概率耦合在一起。<br>因为对数里面有和的形式，解决有一定的困难，这样促使我们想到EM算法。</p>
<h1 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h1><p>给定数据集$(x_1, x_2, …, x_n)$，每个观测量都是d维的向量。k-means的目的是将n个观测量分成k个集合，在给定$z= \lbrace z_1, z_2, …, z_n \rbrace $。为了最小化组内平方和，我们随机的初始化类别向量，然后交替进行两步，知道收敛。</p>
<ul>
<li>E步：将每个观测分配到聚类中，是组内平方和最小。直观上来看就是讲数据点分配到最近的中心。<br>$$ z_i^{(t)} = argmin_k (x_i - \mu_k^{(t)})^T\Sigma_k^{-1^{(t)}}(x_i - u_k^{(t)}) $$</li>
<li>M步：重新计算中心值。<br>$$ \mu_k^{(t+1)} = \frac{\Sigma_i \delta(z_i^{(t)}, k)x_i} {\Sigma_i \delta(z_i^{(t)}, k)} $$<br>可以这么来理解EM，每个聚类可以看做具有相同的分布，比如$p(x_i\mid z_i = k)~N(x_i\mid \mu_k, \Sigma_kl) $我们希望可以学习到每个分布的参数$\mu_k$和$\Sigma$。</li>
</ul>
<h1 id="EM-算法"><a href="#EM-算法" class="headerlink" title="EM 算法"></a>EM 算法</h1><p>EM算法可以有效地迭代计算存在隐变量的最大似然估计。在最大似然估计值中，我们希望能够估计出对于每个观测数据最有可能的参数。<br>期望完全对数似然函数：<br>$$ \langle l_c(\theta;x,z)\rangle = \Sigma_n\langle logp(z_n\mid \pi)\rangle_{p(z\mid x)} + \frac{1}{2}\Sigma_n\Sigma_k\langle z_n^k\rangle((x_n - \mu_k)^T\Sigma_K^{-1}(x_n-\mu_k)+log|\sigma_k|+C) $$</p>
<p>EM算法是利用迭代地方式最大化$\langle l_c(\theta;x,z)\rangle$。在E步中，我们利用当前参数估计量计算隐变量的充分估计量。<br>$$ \tau_n^{k(t)} = \langle z_n^k\rangle_{q(t)} = p(zn^k = 1\mid x,\mu^{(t)},\Sigma^{(t)}) = \frac{\pi_k^{(t)}N(x_n\mid \mu_k^{(t)},\Sigma_k^{(t)})} {\Sigma_i \pi_i^{(t)}N(x_n\mid \mu_k^{(t)},\Sigma_k^{(t)})}$$<br>在M步中，使用期望值来计算参数期望的最大值。<br>\begin{equation}\begin{split} \pi_k &amp;= \Sigma_n \langle z_n^k \rangle_{q^{(t)}}/N = \Sigma_n \tau_n^{k(t)}/N = \langle n_k \rangle /N\\<br>\mu_k^{(t+1)} &amp;= \frac{\Sigma_n \tau_n^{k(t)}x_n}{\Sigma_n \tau_n^{k(t)}}\\<br>\Sigma_k^{(t+1)} &amp;= \frac{\Sigma_n \tau_n^{k(t)}(x_n-\mu_k^{(t+1)})(x_n-\mu_k^{(t+1)})^T}{\Sigma_n \tau_n^{(k(t))}}\\<br>\end{split}\end{equation}</p>
<h1 id="比较K-means和EM"><a href="#比较K-means和EM" class="headerlink" title="比较K-means和EM"></a>比较K-means和EM</h1><p>EM算法类似于K-means处理混合高斯模型，对于K-means，在E步中，我们制定每个聚类点，在M中我们假定每个点属于一个聚类重新计算聚类点。在EM算法中，我们使用概率的方式指定点为聚类点，在M步中，我们假定每个点数一个聚类以概率的重新计算聚类中心。</p>
<h1 id="EM算法理论依据"><a href="#EM算法理论依据" class="headerlink" title="EM算法理论依据"></a>EM算法理论依据</h1><p>X记作观测变量，Z记作隐变量集，分布模型为$p(x,z\mid \theta)$。<br>如果Z是可观的我们定义对数似然函数为：$ l_c(\theta;x,z) = log\ p(x,z\mid \theta) $。对于Z是可观的，我们最大化完全对数似然。<br>然而，当Z不可观时，我们必须最大化边际似然，也就是不完全对数似然函数。<br>$$ l_c(\theta;x) = log\ p(x\mid \theta) = log\Sigma_z p(x,z\theta) $$<br>我们必须将不完全对数似然解耦，因为对数里面具有和的形式。<br>为了解决这个问题，我们引入了平均分布$q(z\mid x)$来取代z的随机性。期望完全对数似然可以定义为：<br>$$ \langle l_c(\theta;x,z)\rangle_q = \Sigma_z q(z\mid x,\theta)log\ p(x,z\mid \theta) $$<br>根据杰西不等式：<br>\begin{equation}\begin{split} l(\theta;x) &amp;= log\ p(x\theta) \\<br>&amp;= log \Sigma_z p(x,z\mid \theta) \\<br>&amp;= log \Sigma_z q(z\mid x)\frac{p(x,z\mid \theta)}{q(z\mid x)} \\<br>&amp;\geqslant \Sigma_z q(z\mid x)log \frac{p(x,z\mid \theta)}{q(z\mid x)} \\<br>\end{split}\end{equation}<br>$$ l(\theta;x) \geqslant \langle l_c(\theta;x,z)\rangle_q + H_q $$<br>固定数据x，定义一个函数叫做自由能：<br>$$ F(q,\theta) = \Sigma_z q(z\mid x) log\frac{p(x,z\mid \theta)}{q(z\mid x)} \leq l(\theta;x)$$<br>这样EM算法等同于在F上进行坐标上升法：</p>
<ul>
<li>E步：$q^{t+1} = argmax_q F(q,\theta^t) $</li>
<li>M步：$\theta^{t+1} = argmax_{\theta} F(q^{t+1},\theta^t)$<br>$q^{t+1}(z\mid x)$是隐变量在给定数据和参数下的后验分布。$q^{t+1}=argmax_q F(q,\theta^t)=p(z\mid x,\theta^t) $<br>证明：这样的设置可以保证$l(\theta;x)\geqslant F(q,\theta)$<br>\begin{equation}\begin{split} F(p(z\mid x,\theta^t), \theta^t) &amp;= \Sigma_z q(z\mid x) log\frac{p(x,z\mid \theta)}{q(z\mid x)}\\<br>&amp;= \Sigma_z q(z\mid x) log\ p(x\mid \theta^t) \\<br>&amp;= log\ p(x\mid \theta^t) \\<br>&amp;= l(\theta^t;x) \\<br>\end{split}\end{equation}<br>同样可以用变分微分来表示：<br>$$ l(\theta;x) - F(q,\theta) = KL(q||p(z\mid x, \theta)) $$<br>在不失一般性的情况下，我们可以将$p(x,z\mid \theta)$定义为广义指数族分布：<br>$$ p(x,z\mid \theta) = \frac{1}{Z(\theta)} h(x,z) exp \lbrace \Sigma_i \theta_i f_i(x,z) \rbrace $$<br>如果$p(X\mid Z)$是广义线性模型，那么$f_i(x,z)=\eta_i^T(z)\xi_i(x) $。<br>在$q^{t+1}=p(z\mid x,\theta^t)$下，期望完全对数似然为：<br>\begin{equation}\begin{split} \langle l_c(\theta;x,z)\rangle_{q^{t+1}} &amp;= \Sigma_z q(z\mid x,\theta^t)log\ p(x,z\mid \theta^t) - A(\theta) \\<br>&amp;= \Sigma_i \theta_i^t \langle f_i(x,z)\rangle_{q(z\mid x, \theta^t)} - A(\theta) \\<br>&amp;= \Sigma_i \theta_i^t \langle \eta_i(z)\rangle_{q(z\mid x, \theta^t)}\eta_i(x) - A(\theta) \\<br>\end{split}\end{equation}<br>下面分析EM算法的M步，M步可以看做是最大化期望对数似然：<br>\begin{equation}\begin{split} F(q,\theta) &amp;= \Sigma_z q(z\mid x) log\frac{p(x,z\mid \theta)}{q(z\mid x)} \\<br>&amp;= \Sigma_z q(z\mid x)log\ p(x,z\mid \theta) - \Sigma_z q(z\mid x)log\ q(z\mid x) \\<br>&amp;= \langle l_c(\theta;x, z) \rangle_q + H_q<br>\end{split}\end{equation}<br>这样将自由能分解成两个部分，第一部分是期望完全对数似然，第二部分是熵，并且与变量$\theta$无关，这样最大自由能就等价于最大化期望完全对数似然。<br>$$ \theta^{t+1} = argmax_{\theta} \langle l_c(\theta;x,z)\rangle_{q^{t+1}} = argmax_{\theta} \Sigma_z q(z\mid x)log\ p(x,z\mid \theta) $$<br>在最优的$q^{t+1}$的情况下，这样就等同于解决标准的完全可观模型$p(x,z\mid \theta)$的最大似然问题，用$p(z\mid x, \theta)$取代包含z的充分统计量。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>EM算法是一种对隐变量模型最大似然函数的一种方法，将比较难以解决的问题分解为两步：</p>
<ol>
<li>基于当前参数和可观数据对隐变量进行估计。</li>
<li>基于观测数据和隐变量对参数做极大似然估计。</li>
</ol>
<ul>
<li>EM算法好的方面<ul>
<li>没有学习率参数</li>
<li>自动限制参数</li>
<li>低维速度快</li>
<li>每代都可以确保调高似然</li>
</ul>
</li>
<li>不好的方面<ul>
<li>会陷入局部极优</li>
<li>比共轭梯度慢，特别是接近收敛时</li>
<li>需要代价高的推测过程</li>
<li>是一种最大似然或者最大后验的方法</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/18/论文总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/18/论文总结/" itemprop="url">论文总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-18T19:21:20+08:00">
                2018-05-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/17/可观无向图模型中的学习问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/17/可观无向图模型中的学习问题/" itemprop="url">可观无向图模型中的学习问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-17T10:58:53+08:00">
                2018-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="最大似然结构学习"><a href="#最大似然结构学习" class="headerlink" title="最大似然结构学习"></a>最大似然结构学习</h1><h2 id="连续型马尔科夫随机场"><a href="#连续型马尔科夫随机场" class="headerlink" title="连续型马尔科夫随机场"></a>连续型马尔科夫随机场</h2><p>给定高斯图模型，我们可以用一个伊辛模型来呈现。<br>$$p(x\mid \mu,\Sigma)=\frac{1}{(2\pi)^{k/2}|\Sigma|^{\frac{1}{2}}}exp \lbrace  -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \rbrace$$<br>下面令$\mu=0$和$Q=\Sigma_{-1}$，高斯模型可以写成：<br>$$p(x\mid \mu,Q)=\frac{|Q|^{1/2}} {(2\pi)^{k/2}}exp \lbrace  -\frac{1}{2}()\Sigma_i q_{ii} (x_i)^2 - \Sigma_{i&lt;j} q_{ij} x_i x_j) \rbrace$$<br>我们将上式指数中的第一部分看做是定义在节点上的势函数，第二部分是定义在比边上的势函数，也就是说等同于一个伊辛模型。<br>$$ P(x\mid \Theta) = exp\ (\Sigma_{i\in V} \theta_{ii}^t x_{d,j} + \Sigma_{(i,j)\in E} x_{d,i}x_{d,j} - A(\Theta)) $$</p>
<h2 id="稀疏图模型"><a href="#稀疏图模型" class="headerlink" title="稀疏图模型"></a>稀疏图模型</h2><p>协方差矩阵有一个重要的性质是：当$\Sigma_{i,j}=0$有$x_i\perp x_j$；逆协方差矩阵（精确矩阵）的对应的性质为：当$\Sigma_{i,j}^{-1}=0$时$x_i\perp x_j\mid x_{-ij}$。<br>如果出现$p \gg n$时，得不到最大似然估计，这是我们使用近邻选择得方法，增加惩罚函数来学习稀疏的图模型。<br>近邻选择可以看做是伊辛模型。<br>$$ P(x\mid \Theta) = exp\ (\Sigma_{i\in V} \theta_{ii}^t x_{d,j} + \Sigma_{(i,j)\in E} x_{d,i}x_{d,j} - A(\Theta)) $$</p>
<h1 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h1><h2 id="似然条件"><a href="#似然条件" class="headerlink" title="似然条件"></a>似然条件</h2><p>有向图中，对数似然可以分解为一组和的形式，每个对应于一个子节点对应其父节点。无向图中，对数似然并不能分解，因为Z是包含了所有的参数的函数。<br>$$ p(x) = \frac{1}{Z} \prod_{c\in C} \psi_c{x_c}, Z = \Sigma_x \prod_{c\in C} \psi_c(x_c) $$<br>我们需要通过推测来学习参数。我们获得了输入数据的充分统计量，计数。<br>$$total\ count:m(x) = \Sigma_n \delta(x, x_n)$$  $$cliqu\ count:m(x_c) = \Sigma_{x_{V\setminus c}} m(x)$$<br>似然函数为：<br>$$p(D\mid \theta) = \prod_n \prod_x p(x\mid \theta)^{\delta(x,x_n)}$$</p>
<p>\begin{equation}\begin{split} log\ p(D\mid \theta)&amp;=\Sigma_n \Sigma_x \delta(x,x_n)log\ p(x\mid \theta\\<br>l &amp; = \Sigma_x m(x)log(\frac{1}{Z}\prod_c \pi_c(x_c))\\<br>&amp; = \Sigma_c \Sigma_{x_c}m(x_c)log\ \psi_c(x_c) - N log\ Z \\<br>\end{split}\end{equation}<br>上式的两个部分对$\psi_c(x_c)$求导：<br>第一项：<br>$$ \frac{\partial l_1}{\partial \psi_c(x_c)} = m(x_c)/\psi_c(x_c) $$<br>第二项：<br>\begin{equation}\begin{split} \frac{\partial log\ Z}{\partial \psi_c(x_c)} &amp; = \frac{1}{Z} \frac{\partial}{\partial\psi_c(x_c)}(\Sigma_{\tilde{x} } \prod_{d} \psi_d(\tilde x_d))\\<br>&amp; = \frac{1}{Z} \Sigma_{\tilde{x}}\delta(\tilde x_c, x_c)\frac{\partial}{\partial \psi_c(x_c)}(\prod_{d} \psi_d(\tilde x_d) \\<br>&amp; =  \Sigma_{\tilde x}\delta(\tilde x_c, x_c) \frac{1}{\psi_c(\tilde x_c)} \frac{1}{Z} \prod_d \psi_d(\tilde x_d)\\<br>&amp; = \frac{1}{\psi_c (x_c)}\Sigma_{\tilde x} \delta(\tilde x_c, x_c) p(\tilde x)  \\<br>&amp; = \frac{x_c}{\psi_c (x_c)}<br>\end{split}\end{equation}</p>
<p>令导数为零，有：$\frac{\partial l}{\partial \psi_c(x_c)} = \frac{m(x_c)}{\psi_c(x_c)} - N\frac{p(x_c)}{\psi_c(x_c)} = 0$，从结果可以看出，模型的边缘概率密度等于观测的边缘概率密度。<br>$$ p_{MLE}^{\star} (x_c) = \frac{m(x_c)}{N} = \tilde p(x_c) $$<br>但是结果并没有给出似然参数的估计方法，只是给出了必须满足的条件。</p>
<h2 id="可分解模型"><a href="#可分解模型" class="headerlink" title="可分解模型"></a>可分解模型</h2><p>对于可分解的模型，势函数可以定义于最大团上，团势函数的最大似然等价于经验边际。因此最大似然可以通过检查得到。基于势函数的表示似然$p(x)=\frac{\prod_c \psi_c(x_c)}{\prod_s \psi_s(x_s)}$，其中c是最大团，s是最大团分离的因子。为了计算团势，将他们等同于经验边际。分离因子必须分解为几个邻居，那么$Z=1$。</p>
<h3 id="例一"><a href="#例一" class="headerlink" title="例一"></a>例一</h3><p>考虑链$X_1-X_2-X_3$，有团$(x_1, x_2),(x_2, x_3)$，分离因子$x_2$。<br>$$ \tilde p_{MLE}(x_1, x_2, x_3) = \frac{\tilde p(x_1, x_2)\tilde p(x_2, x_3)}{\tilde p(x_2)} $$<br>$$ \tilde{\psi}_{12}^{MLE}(x_1, x_2) = \tilde p(x_1, x_2) $$<br>$$ \tilde{\psi}_{23}^{MLE}(x_2, x_3) = \frac{\tilde p(x_2, x_3)}{\tilde p(x_2)}= \tilde p(x_2\mid x_3) $$</p>
<h3 id="例二"><a href="#例二" class="headerlink" title="例二"></a>例二</h3><p><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E6%97%A0%E5%90%91%E5%9B%BE%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png" alt=""><br>团$(x_1, x_2, x_3),(x_2, x_3, x_4)$，分离因子$x_2,x_3$<br>$$ \tilde p_{MLE}(x_1, x_2, x_3, x_4) = \frac{\tilde p(x_1, x_2, x_3)\tilde p(x_2, x_3, x_4)}{\tilde p(x_2, x_3)} $$<br>$$ \tilde{\psi}_{123}^{MLE}(x_1, x_2,x_3) = \frac{\tilde p(x_1, x_2, x_3)}{\tilde p(x_2, x_33)}= \tilde p(x_1\mid x_2, x_3) $$<br>$$ \tilde{\psi}_{234}^{MLE}(x_2, x_3, x_4) =  \tilde p(x_2, x_3, x_4) $$</p>
<h2 id="不可分离模型-IPF和GIS"><a href="#不可分离模型-IPF和GIS" class="headerlink" title="不可分离模型-IPF和GIS"></a>不可分离模型-IPF和GIS</h2><p>如果一个图是不可分离的，也就是说势函数不能以最大团定义，我们不能将经验边际等价于势函数的似然。</p>
<h3 id="Tabular-Cique-Potentials-IPF"><a href="#Tabular-Cique-Potentials-IPF" class="headerlink" title="Tabular Cique Potentials-IPF"></a>Tabular Cique Potentials-IPF</h3><p>如果团势函数是表格形式或者可以使用简介的参数模型表示，那么我们可以使用IPF来求最大似然估计。<br>从上面的似然函数导数：<br>$$\frac{\partial l}{\partial \psi_c(x_c)} = \frac{m(x_c)}{\psi_c(x_c)} - N\frac{p(x_c)}{\psi_c(x_c)} = 0$$<br>我们可以得到：<br>$$ \frac{\tilde p(x_c)}{\psi_c(x_c)} = \frac{p(x_c)}{\psi_c(x_c)} $$<br>因为$\psi_c$隐性的出现了模型边际$p(x_c)$中，所以在点$\psi_c$上存在等式关系，所以直接解出$\psi_c$是非常困难的，因为其出现在了等式两边。<br>我们将$\psi_c$在右边固定，然后在左边解出，循环所有的团，进行下面的迭代：<br>$$ \psi_c^{(t+1)}(x_c) = \psi_c^{(t)}(x_c)\frac{\tilde p(x_c)}{p^{(t)}(x_c)} $$<br>上面的算法可以看做是坐标上升算法，其中的坐标就是势团的参数。因此在每一步中，似然函数的值会增加，这样就可以收敛到全局极大值。这个算法童谣可以被看做是最小化观测数据的分布与模型分布的KL散度(交叉熵),只有当模型是可分解的。<br>$$ max\ l \Leftrightarrow KL(\tilde p(x)\mid \mid p(x\mid\theta))=\Sigma_x \tilde p(x)log\frac{\tilde p(x)}{p(x\mid \theta)} $$</p>
<p>\begin{equation}\begin{split} KL(q(x_a, x_b)\mid \mid p(x_a, x_b)) &amp;= \Sigma_{x_a, x_b}q(x_a)q(x_b\mid x_a)log\frac{q(x_a)q(x_b\mid x_a)}{p(x_a)p(x_b\mid x_a)}\\<br>&amp;= \Sigma_{x_a, x_b}q(x_a)q(x_b\mid x_a)log\frac{q(x_a)}{p(x_a)} + \Sigma_{x_a, x_b}q(x_a)q(x_b\mid x_a)log\frac{q(x_b\mid x_a)}{p(x_b\mid x_a)}\\<br>&amp;= KL(1(x_aq)\mid\mid p(x_a)) + \Sigma_x q(x_a)KL(q(x_b\mid x_a)\mid\mid p(x_b\mid x_a))\\<br>\end{split}\end{equation}<br>将上面两个式子合并：<br>$$ KL(\tilde p(x)\mid\mid p(x\theta)) = KL(\tilde p(x_c)\mid \mid p(x_c\theta)) + \Sigma_{x_a}\tilde p(x_c)KL(\tilde p(x_{-c})\mid\mid p(x_{-c}\mid x_c)) $$<br>从上面的式子可以看出，改变团势$\psi$并不会改变条件分布，所以对上式中第二项不会产生影响。<br>为了最小化第一项，和IPF的方法一样，我们将边际分布逼近观测分布。<br>可以将IPF解释为：保存原有的条件分布$p^{(t)}(x_{-c}\mid x_c)$，用观测数据分布取代原有的边际分布。</p>
<h3 id="Feature-based-Clique-Potentials"><a href="#Feature-based-Clique-Potentials" class="headerlink" title="Feature-based Clique Potentials"></a>Feature-based Clique Potentials</h3><p>当团势不能用表格表达时，或者更加一般的来说，获得团势是指数级的推测难度，必须要从有限的数据中学习指数个参数。我们可以将团变小，但是这样需要更多的独立性假设，并且改变了图模型结构。另外一种方法是不改变模型结构，使用更加一般的团势的参数。这被叫做基于特征的方法。<br>特征是对于一般的设定为空，对于少数特别的设定会有高低之分。每个特征函数都能变成小团势，然后将小团势乘起来就可以得到团势了。<br>例如，一个团势$\psi(x_1, x_2, x_3)$：<br>$$ \psi_c(x_a, x_2, x_3) = e^{\theta_{ing}f_{ing}}\times e^{\theta_{?ed}f_{?ed}} \times … = exp\lbrace \Sigma_{k=1}^T \theta_k f_k(c_1, c_2, c_3)\rbrace $$<br>每个特征都有一个权重$\theta_k$，它可以用增加或者减少团势的概率。<br>团上的边际分布就是一个广义指数族：<br>$$ p(c_1, c_2, c_3) \propto exp(\theta_{ing}f_{ing}(x_1, x_2, x_3) + \theta_{?ed}f_{?ed}(x_1, x_2, x_3) + …) $$<br>一般来说，特征可能是重叠的，没有限制的显示因子或者任意团变量的子集：<br>$$ \psi_c(x_c) = exp\lbrace \Sigma_{i\in I_c} \theta_k f_k(x_{c_i})\rbrace $$<br>我们可以将团势向前面一样乘起来：<br>$$ p(x) = \frac{1}{Z(\theta)}\psi_c (x_c) = \frac{1}{Z(\theta)}exp\lbrace \Sigma_c\Sigma_{i\in I_c} \theta_k f_k(x_{c_i})\rbrace $$<br>可以简化为：<br>$$ p(x) = \frac{1}{Z(\theta)}exp(\Sigma_i \theta_i f_i(x_{c_i})) $$<br>这就是指数族模型，特征值就是充分统计量。</p>
<h2 id="Gerneralized-Iterative-Scaling-GIS"><a href="#Gerneralized-Iterative-Scaling-GIS" class="headerlink" title="Gerneralized Iterative Scaling - GIS"></a>Gerneralized Iterative Scaling - GIS</h2><p>基于之前的概率函数，我们想通过一个算法求最大概率，然后有了GIS。<br>我们首先不是考虑直接优化目标，而是处理目标函数的下界。<br>\begin{equation}\begin{split} \tilde l(\theta;D) &amp;= l(\theta;D)/N \\<br>&amp;= \frac{1}{N}\Sigma_n log\ p(x_n\mid \theta) \\<br>&amp;= \Sigma_x \tilde p(x)log\ p(x\mid \theta) \\<br>&amp;= \Sigma_x \tilde p(x)\Sigma_i \theta_i f_i(x) - log\ Z(\theta) \\<br>&amp;\geqslant \Sigma_x \tilde p(x)\Sigma_i \theta_i f_i(x) - \frac{Z(\theta)}{Z(\theta^{(t)})} - log Z(\theta^{(t)}) + 1 \\<br>\end{split}\end{equation}</p>
<p>因为对数函数有一个线性上界：$log\ Z(\theta)\leqslant \mu Z(\theta) - log\ \mu - 1$<br>定义：$\Delta\theta_i^{(t)} = \theta_i-\theta_i^{(t)} $<br>\begin{equation}\begin{split}\tilde l(\theta;D) &amp;\geqslant \Sigma_x \tilde p(x)\Sigma_i \theta_i f_i(x) - \frac{Z(\theta)}{Z(\theta^{(t)})} - log Z(\theta^{(t)}) + 1 \\<br>&amp;= \Sigma_i \theta_i \Sigma_x \tilde p(x)f_i(x) - \frac{1}{Z(\theta^{(t)})}\Sigma_x exp(\Sigma_i \theta_i^{(t)} f_i(x))exp(\Sigma_i \Delta\theta_i^{(t)}f_i(x)) - log\ Z(\theta^{(t)}) + 1\\<br>&amp;= \Sigma_i \theta_i \Sigma_x \tilde p(x)f_i(x) - \Sigma_x p(x\mid \theta^{(x)})exp(\Sigma_i \Delta\theta_i^{(t)} f_i(x)) - log\ Z(\theta^{(t)}) + 1\\<br>\end{split}\end{equation}</p>
<p>假定$f_i(x) \geqslant,\Sigma_i f_i(x) = 1$，使用杰西不等式，$exp(\Sigma_i \pi_i x_i)\leqslant \Sigma_i \pi_i exp(x_i)$有：<br>$$ \tilde l(\theta;D) \geqslant \Sigma_i \theta_i \Sigma_x \tilde p(x)f_i(x) - \Sigma_x p(x\mid \theta^{(x)})\Sigma_i f_i(x)exp(\Delta\theta_i^{(t)}) - log\ Z(\theta^{(t)}) + 1 $$<br>令上面式子的右边等于$\Delta(\theta)$。<br>求偏导令其为零：<br>$$ \frac{\partial \Lambda}{\partial \theta_i} = \Sigma_x \tilde p(x)f_i(x) - exp(\Delta\theta_i^{(t)})\Sigma_x p(x\mid \theta^{(t)})f_i(x) = 0$$<br>$$ e^{\Delta\theta_i^{(t)}} = \frac{\Sigma_x \tilde p(x)f_i)(x)}{\Sigma_x p(x\mid \theta^{(t)})f_i(x)}= \frac{\Sigma_x \tilde p(x)f_i)(x)}{\Sigma_x p^{(t)}(x)f_i(x)}Z(\theta^{(t)}) $$<br>更新准则：<br>$$ \theta_i^{(t+1)} = \theta_i^{(t)} + \Delta\theta_i^{(t)} \Rightarrow p^{(t+1)}(x)=p^{(t)}(x)\prod_i e^{\Delta\theta_i^{(t)}} $$<br>\begin{equation}\begin{split} p^{(t+1)}(x) &amp;= \frac{p^{(t)}(x)}{Z(\theta^{(t)})}\prod_i (\frac{\Sigma_x \tilde p(x)f_i)(x)}{\Sigma_x p^{(t)}(x)f_i(x)}Z(\theta^{(t)}))^{f_i(x)} \\<br>&amp;= \frac{p^{(t)}(x)}{Z(\theta^{(t)})}\prod_i (\frac{\Sigma_x \tilde p(x)f_i)(x)}{\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)}(Z(\theta^{(t)}))^{\Sigma_i f_i(x)} \\<br>&amp;= p^{(t)}(x)\prod_i (\frac{\Sigma_x \tilde p(x)f_i)(x)}{\Sigma_x p^{(t)}(x)f_i(x)})^{f_i(x)} \\<br>\end{split}\end{equation}</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="IPF"><a href="#IPF" class="headerlink" title="IPF"></a>IPF</h2><p>IPF是无向图模型求最大似然的一般方法。</p>
<ul>
<li>对$\psi_c$在每个团上一个固定的等式，坐标上升。</li>
<li>在最大团边际空间上进行I-projection</li>
<li>需要势函数完全的参数化</li>
<li>必须要以最大团描述</li>
<li>对于完全可分的模型，变成一次算法</li>
</ul>
<h2 id="GIS"><a href="#GIS" class="headerlink" title="GIS"></a>GIS</h2><ul>
<li>要以基于特征的势函数描述</li>
<li>GIS是IPF的特殊形式，GIS的团势是建立在特征值配置上的。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>注：本文主要参考[1]中第8讲视频以及笔记。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="HJY" />
            
              <p class="site-author-name" itemprop="name">HJY</p>
              <p class="site-description motion-element" itemprop="description">HJY的装逼小站</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">30</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hjyai94" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HJY</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.3"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
