<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="HJY的装逼小站">
<meta property="og:type" content="website">
<meta property="og:title" content="HJY">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="HJY">
<meta property="og:description" content="HJY的装逼小站">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HJY">
<meta name="twitter:description" content="HJY的装逼小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'HR62QHMRVP',
      apiKey: '5003cc57039452aa0e152bdb9198ed17',
      indexName: 'dev_NAME',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>HJY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HJY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">昨夜西风凋碧树，独上高楼望尽天涯路。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/26/汇报list/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/26/汇报list/" itemprop="url">汇报list</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-26T16:43:47+08:00">
                2018-09-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工作/" itemprop="url" rel="index">
                    <span itemprop="name">工作</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="2017-9-10"><a href="#2017-9-10" class="headerlink" title="2017.9.10"></a>2017.9.10</h1><p>暑假期间学习和看的论文：<br>学习内容：</p>
<ol>
<li>计算视觉CS131，完成了所有的homework的代码，然后传到了我的github上了。<a href="https://github.com/hjyai94/CS131_homework" target="_blank" rel="noopener">https://github.com/hjyai94/CS131_homework</a></li>
<li>计算机视觉CS231看了一点，还没有看完。</li>
<li>最近在看的深度学习和贝叶斯方法结合的一门课(<a href="http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。" target="_blank" rel="noopener">http://deepbayes.ru/)，实现了一个EM算法去除噪声的代码。</a></li>
</ol>
<p>看的论文：<br>[1] Deep Learning Markov Random Field for Semantic Segmentation<br>[2] Single Image Haze Removal Method Using Conditional Random Fields<br>[3] DehazeNet: An End-to-End System for Single Image Haze Removal</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/25/典型相关性/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/25/典型相关性/" itemprop="url">典型相关性(Canonical Correlation Analysis)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-25T16:50:32+08:00">
                2018-09-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>给定带有有限距的随机变量的列向量$X = (x_1, …, x_n)^T$和$Y = (y_1, …, y_m)^T$，我们可以定义互协方差矩阵$\Sigma_{XY} = cov(X, Y)$，为$n\times m$的矩阵，其中$(i, j)$是协方差矩阵$cov(x_i, y_j)$。实际上，我们可以基于$X$和$Y$的采样数据来估计协方差矩阵。<br>典型相关性(Canonical Correlation Analysis)是求出向量$a$和$b$使得随机变量$a^T X$和$b^T Y$的相关性$\rho = corr(a^T X, b^T Y)$最大。随机变量$U = a^T X$和$V = b^T Y$是第一对典型变量。然后寻求一个依然最大化相关但与第一对典型不相关的向量；这样就得到了第二对典型变量。这个步骤会进行$min\lbrace m, n\rbrace$。</p>
<h1 id="典型相关性"><a href="#典型相关性" class="headerlink" title="典型相关性"></a>典型相关性</h1><ol>
<li><p>学习两个线性映射，每个线性映射对应于一组数据，使得两组数据最大相关性。<br>\begin{equation}\begin{split} (u^{\star}, v^{\star}) &amp;= argmax_{u, v} corr(u^T X, v^T Y) \\<br>&amp;= argmax_{u, v} \frac{cov(u^T X, v^T Y)}{\sqrt{var(u^T X) var(v^T Y)}} \\<br>&amp;= argmax_{u, v} \frac{u^T E(X Y^T)v}{\sqrt{u^T E(X X^T) u v^T E(Y Y^T) v}} \\<br>&amp;= argmax_{u, v} \frac{u^T \Sigma_{XY} v}{\sqrt{u^T \Sigma_{XX} u v^T \Sigma_{YY} v}} \\<br>\end{split}\end{equation}</p>
</li>
<li><p>我们希望获得多个映射矩阵，同时多个线性映射对是相互正交的。<br>$$ u_{(i)}^T \Sigma_{XY} v_{(j)} = u_{(j)}^T \Sigma_{XY} v_{(i)} = 0\  \text {for}\ i\neq j$$<br>$$ U\Sigma_{XY}V = tr(U\Sigma_{XY} V) $$<br>其中$U = [u_1, u_2, …, u_k]$和$V = [v_1, v_2, …, v_k] $。<br>$$(U^{\star}, V^{\star}) = argmax_{U, V}\frac{tr(U^T\Sigma_{XY} V)}{\sqrt{U^T\Sigma_{XX} U} \sqrt{V^T \Sigma_{YY} V}}$$</p>
</li>
<li><p>因为上式中分子分布增大相同的倍数，优化目标的结果不变，所以我们采用类似$SVM$中类似的优化方法，固定分母，优化分子，具体转化为[2]：<br>\begin{cases}<br>argmax_{U, V} = U^T\Sigma_{XY} V \\<br>\text{s.t.}\ U^T \Sigma_{XX} U = I, V^T \Sigma_{YY} V= I \\<br>\end{cases}<br>这样就变成了有约束的最优化问题，可以使用拉格朗日乘子法，也可以采用$SVD$分解的方法。</p>
</li>
</ol>
<ul>
<li>拉格朗日乘子法<br>$$ L = tr(U^T \Sigma_{XY} V) - \alpha  (U^T \Sigma_{XX} U - I)  - \beta (V^T \Sigma_{YY} V - I) $$<br>对$U$和$V$分别求偏导并令其为0：<br>\begin{cases}<br>\Sigma_{XY} V = 2\alpha \Sigma_{XX} U \\<br>\Sigma_{XY}^T U = 2 \beta \Sigma_{YY} V \\<br>\end{cases}</li>
</ul>
<p>对上式分别左乘$U^T$和$V^T$，可以得出$2\alpha = 2\beta = U^T \Sigma_{XY} V $<br>将前面的式子再分别左乘$\Sigma_{XX}^{-1}$和$\Sigma_{YY}^{-1}$，然后通过分别消除变量可以得出下面的结果：<br>$$ \Sigma_{XX}\Sigma_{XY}\Sigma_{YY}^{-1}\Sigma^T_{XY}U = \lambda U $$<br>$$ \Sigma_{YY}\Sigma_{XY}\Sigma_{XX}^{-1}\Sigma^T_{XY}V = \lambda V $$<br>其中$$\lambda = 4\alpha \beta $$<br>只要求出对应特征值最大的特征向量，这样就解出$U$和$V$。</p>
<ul>
<li>SVD<br>令$ U = \Sigma_{XX}^{-\frac{1}{2}} u$，$V = \Sigma_{YY}^{-\frac{1}{2}} v $。<br>由$U^T \Sigma_{XX} U = I$和$ V^T \Sigma_{YY} V= I$，可以得出：$ u^T u = I $ $v^T v = I $<br>将原本的最优化问题转化为这样的形式：<br>\begin{cases}<br>argmax_{u, v} = u^T\Sigma_{XX}^{-\frac{1}{2}} \Sigma_{XY} \Sigma_{YY}^{-\frac{1}{2}} v \\<br>\text{s.t.}\ u^T u = I, v^T v = I  \\<br>\end{cases}<br>使用$SVD$就是通过最大化对应的奇异值的特征向量，就是对应的$u$和$v$的结果。<br>$$ T = \Sigma_{XX}^{-\frac{1}{2}}\Sigma_{XY} \Sigma_{YY}^{-\frac{1}{2}}  $$<br>$$ (U^{\star}, V^{\star}) = (\Sigma_{XX}^{-\frac{1}{2}}U_{SVD}, \Sigma_{YY}^{-\frac{1}{2}} V_{SVD}) $$</li>
</ul>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] <a href="https://zh.wikipedia.org/wiki/典型相关" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/典型相关</a><br>[2] <a href="https://blog.csdn.net/Mbx8X9u/article/details/78824216" target="_blank" rel="noopener">https://blog.csdn.net/Mbx8X9u/article/details/78824216</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/05/EM算法程序实现/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/05/EM算法程序实现/" itemprop="url">EM算法实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-05T10:42:01+08:00">
                2018-09-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h1><p>之前在看概率图模型的时候，写过关于EM算法的内容，不过已经忘记差不多了，最近在看[1]中的材料，感觉有了新的理解，特将这些内容整理成这篇博客。<br>EM算法适用于存在隐变量的情况，或者说是假设存在因变量对系统进行推导。<br>\begin{equation}\begin{split} log\ p(X\mid \theta) &amp;= \int q(Z)log\ p(X\mid \theta)dZ \\<br>&amp;= \int q(Z)log \frac{p(X, Z\mid \theta)}{p(Z\mid X, \theta)}dZ \\<br>&amp;= \int q(Z)log \frac{p(X, Z\mid \theta)}{q(Z)}dZ + \int q(Z) log \frac{q(Z)}{p(Z\mid X, \theta)}dZ\\<br>&amp;= L(q, \theta) + KL(q\mid\mid p) \geqslant L(q, \theta)\\<br>\end{split}\end{equation}<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95.png" alt=""><br>E步是为了获得隐变量的最优值，M步是对参数求最大似然。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><a href="https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start" target="_blank" rel="noopener">问题描述</a></h1><p>有$K$张受噪声污染的图片，每张图片大小为$H\times W$，每张图片上都有$H\times w$大小的人脸，每张人脸的位置不固定，但是高度相同，都与图片的高度一样。如下图所示，每张图片都是受严重受噪声污染的，可以看成是高斯噪声。可以从这里得到<a href="https://drive.google.com/open?id=1NLOHNhqdDBG6rWk8lOjzm3u3vDyS_9WZ" target="_blank" rel="noopener">数据集</a>，该数据集为.mat格式，其中包含有500张$45\times 60$的图片，其中人脸大小为$45\times 36$<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%99%AA%E5%A3%B0%E5%9B%BE%E7%89%87.png" alt=""><br>下图是图片的结构，其中$d_k$的位置是不固定的，$F$是不含噪声的人脸图片，$B$是不含噪声的背景图片。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%BE%E7%89%87%E7%BB%93%E6%9E%84.png" alt=""><br>下面基于EM算法来思考该问题：<br>可观数据：$K$张受污染的图片，$X = \lbrace X_1, …, X_K \rbrace$<br>隐变量：$F$的位置，$d = \lbrace d_1, …, d_K \rbrace$<br>参数：$\theta = \lbrace B, F, s^2\rbrace$<br>似然函数：<br>$$ p(X_k\mid d_k, \theta) = \prod_{ij}\begin{cases} N(X_k[i, j]\mid F[i,j-d_k], s^2), &amp; \text {if $[i, j]\in faceArea(d_k)$} \\ N(X_k[i, j]\mid B[i, j], s^2), &amp; \text{otherwise} \end{cases} $$<br>因为每张图片中$F$和$B$部分减去对应的$F$和$B$，这样就是纯粹的噪声，我们将噪声看做是高斯分布，所以上式就是上面的形式。<br>以及先验：<br>$p(d_k\mid a) = a[d_k] $， $\sum_j a[j] = 1$,，$a\in R^{W-w+1}$<br>概率模型可以写成：<br>$$ p(X, d\mid \theta, a) = \prod_k p(X_k\mid d_k, \theta)p(d_k\mid a) $$<br>按照第一张图中的EM算法步骤，进行EM算法的推导：<br>E步：确定隐变量的最优值<br>\begin{equation}\begin{split} q(d) = p(d\mid X, \theta, a) &amp;= \prod_k p(d_k\mid x_k, \theta, a)\\<br>&amp;= \prod_k\frac{p(X_k, d_k\mid \theta, a)}{\sum_{d_k’} p(X_k, d_k’\mid \theta, a)} \\<br>&amp;= \prod_k\frac{p(X_k\mid d_k, theta)p(d_k\mid a)}{\sum_{d_k’} p(X_k\mid d_k’, theta)p(d_k’\mid a)} \\<br>\end{split}\end{equation}<br>M步：对参数求最大似然。<br>$$ Q(\theta, a) = E_{q(d)}log\ p(X, d\mid \theta, a) \rightarrow max_{\theta, a} $$<br>具体推导这里就不再详细的描述了，可以参照参考文献[1]中的推导过程，最后的推导结果如下：<br>$$a[j] = \frac{\sum_k q( d_k = j )}{\sum_{j’}  \sum_{k’} q( d_{k’} = j’)}$$<br>$$F[i, m] = \frac 1 K  \sum_k \sum_{d_k} q(d_k)\, X^k[i,\, m+d_k]$$<br>$$B[i, j] = \frac {\sum_k \sum_{ d_k:\, (i, \,j) \,\not\in faceArea(d_k)} q(d_k)\, X^k[i, j]}<br>          {\sum_k \sum_{d_k: \,(i, \,j)\, \not\in faceArea(d_k)} q(d_k)}$$<br>$$s^2 = \frac 1 {HWK}   \sum_k \sum_{d_k} q(d_k)<br>          \sum_{i,\, j}  (X^k[i, \,j] - Model^{d_k}[i, \,j])^2$$<br> 其中$Model^{d_k}[i, j]$表示由$F$和$B$组成的图片，其中$F$处于$d_k$位置。</p>
<h1 id="程序实现"><a href="#程序实现" class="headerlink" title="程序实现"></a>程序实现</h1><p>下面用EM算法来是处理对受噪声污染影响的图片，从而恢复其中的人脸图像。<br>程序思路为</p>
<ol>
<li>实现对数似然；</li>
<li>实现variational lower bound；</li>
<li>实现E步；</li>
<li>实现M步；</li>
<li>将循环执行EM步，知道满足结束条件。<h2 id="具体程序"><a href="#具体程序" class="headerlink" title="具体程序"></a>具体程序</h2></li>
</ol>
<ul>
<li><p>实现对数似然，似然函数为：$$ p(X_k\mid d_k, \theta) = \prod_{ij}\begin{cases} N(X_k[i, j]\mid F[i,j-d_k], s^2), &amp; \text {if $[i, j]\in faceArea(d_k)$} \\ N(X_k[i, j]\mid B[i, j], s^2), &amp; \text{otherwise} \end{cases} $$</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">def calculate_log_probability(X, F, B, s):</span><br><span class="line">    <span class="string">""</span>"</span><br><span class="line">    Calculates <span class="keyword">log</span> p(X_k|d_k, F, B, s) <span class="keyword">for</span> all images X_k <span class="keyword">in</span> X and</span><br><span class="line">    all possible face position d_k.</span><br><span class="line"></span><br><span class="line">    Parameters</span><br><span class="line">    ----------</span><br><span class="line">    X : array, shape (<span class="keyword">H</span>, W, K)</span><br><span class="line">        K images of size <span class="keyword">H</span> x W.</span><br><span class="line">    F : array, shape (<span class="keyword">H</span>, w)</span><br><span class="line">        Estimate of prankster's face.</span><br><span class="line">    B : array, shape (<span class="keyword">H</span>, W)</span><br><span class="line">        Estimate of background.</span><br><span class="line">    s : float</span><br><span class="line">        Estimate of standard deviation of Gaussian noise.</span><br><span class="line"></span><br><span class="line">    Returns</span><br><span class="line">    -------</span><br><span class="line">    ll : array, shape(W-w+1, K)</span><br><span class="line">        ll[dw, k] - <span class="keyword">log</span>-likelihood of observing image X_k given</span><br><span class="line">        that the prankster's face F is located at position dw</span><br><span class="line">    <span class="string">""</span>"</span><br><span class="line">    # your code here</span><br><span class="line">    <span class="keyword">H</span>, W, K = np.shape(X)</span><br><span class="line">    _, w = np.shape(F)</span><br><span class="line">    ll = np.zeros((W-w+1, K), dtype=float)</span><br><span class="line">    <span class="keyword">for</span> dw <span class="keyword">in</span> <span class="keyword">range</span>(W-w+1):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="keyword">range</span>(K):</span><br><span class="line">            ll[dw, k] = <span class="keyword">H</span>*w*np.<span class="built_in">log</span>(1/(s*np.<span class="built_in">sqrt</span>(2*np.pi))) - np.<span class="built_in">sum</span>((X[:, dw:dw+w, k] - F)**2/(2 * s**2)) + \</span><br><span class="line">            <span class="keyword">H</span>*dw*np.<span class="built_in">log</span>(1/(s*np.<span class="built_in">sqrt</span>(2*np.pi))) - np.<span class="built_in">sum</span>((X[:, 0:dw, k] - B[:, 0:dw])**2/(2 * s**2)) + \</span><br><span class="line">            <span class="keyword">H</span>*(W-w-dw)*np.<span class="built_in">log</span>(1/(s*np.<span class="built_in">sqrt</span>(2*np.pi))) - np.<span class="built_in">sum</span>((X[:, dw+w:, k] - B[:, dw+w:])**2/(2 * s**2))</span><br><span class="line">    <span class="keyword">return</span> ll</span><br></pre></td></tr></table></figure>
</li>
<li><p>实现Variational lower bound</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_lower_bound</span><span class="params">(X, F, B, s, a, q)</span>:</span></span><br><span class="line">   <span class="string">"""</span></span><br><span class="line"><span class="string">   Calculates the lower bound L(q, F, B, s, a) for</span></span><br><span class="line"><span class="string">   the marginal log likelihood.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Parameters</span></span><br><span class="line"><span class="string">   ----------</span></span><br><span class="line"><span class="string">   X : array, shape (H, W, K)</span></span><br><span class="line"><span class="string">       K images of size H x W.</span></span><br><span class="line"><span class="string">   F : array, shape (H, w)</span></span><br><span class="line"><span class="string">       Estimate of prankster's face.</span></span><br><span class="line"><span class="string">   B : array, shape (H, W)</span></span><br><span class="line"><span class="string">       Estimate of background.</span></span><br><span class="line"><span class="string">   s : float</span></span><br><span class="line"><span class="string">       Estimate of standard deviation of Gaussian noise.</span></span><br><span class="line"><span class="string">   a : array, shape (W-w+1)</span></span><br><span class="line"><span class="string">       Estimate of prior on position of face in any image.</span></span><br><span class="line"><span class="string">   q : array</span></span><br><span class="line"><span class="string">       q[dw, k] - estimate of posterior</span></span><br><span class="line"><span class="string">                  of position dw</span></span><br><span class="line"><span class="string">                  of prankster's face given image Xk</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Returns</span></span><br><span class="line"><span class="string">   -------</span></span><br><span class="line"><span class="string">   L : float</span></span><br><span class="line"><span class="string">       The lower bound L(q, F, B, s, a)</span></span><br><span class="line"><span class="string">       for the marginal log likelihood.</span></span><br><span class="line"><span class="string">   """</span></span><br><span class="line">   <span class="comment"># your code here</span></span><br><span class="line">   ll = calculate_log_probability(X, F, B, s)</span><br><span class="line">   L = np.sum(q*ll) + np.sum(q.T*np.log(a)) - np.sum(q*np.log(q))</span><br><span class="line">   <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>
</li>
<li><p>E步</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_e_step</span><span class="params">(X, F, B, s, a)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Given the current esitmate of the parameters, for each image Xk</span></span><br><span class="line"><span class="string">    esitmates the probability p(d_k|X_k, F, B, s, a).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    X : array, shape(H, W, K)</span></span><br><span class="line"><span class="string">        K images of size H x W.</span></span><br><span class="line"><span class="string">    F  : array_like, shape(H, w)</span></span><br><span class="line"><span class="string">        Estimate of prankster's face.</span></span><br><span class="line"><span class="string">    B : array shape(H, W)</span></span><br><span class="line"><span class="string">        Estimate of background.</span></span><br><span class="line"><span class="string">    s : float</span></span><br><span class="line"><span class="string">        Eestimate of standard deviation of Gaussian noise.</span></span><br><span class="line"><span class="string">    a : array, shape(W-w+1)</span></span><br><span class="line"><span class="string">        Estimate of prior on face position in any image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    q : array</span></span><br><span class="line"><span class="string">        shape (W-w+1, K)</span></span><br><span class="line"><span class="string">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class="line"><span class="string">        of prankster's face given image Xk</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># your code here</span></span><br><span class="line">    <span class="comment"># 使用logsumexp的方法</span></span><br><span class="line">    <span class="comment"># ad = log p(x_k| d_k, F, B, s) + log p(d_k,|a)</span></span><br><span class="line">    <span class="comment"># d* = argmax_d&#123;ad&#125;</span></span><br><span class="line">    <span class="comment"># log \sum exp(ad)= ad* + log\sum_d exp(ad-ad*)</span></span><br><span class="line">    ll = calculate_log_probability(X, F, B, s)</span><br><span class="line">    ad = ll + np.log(a).T.reshape(a.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">    ad_max = np.max(ad, axis=<span class="number">0</span>)</span><br><span class="line">    q = ad - ad_max - np.log(np.sum(np.exp(ad - ad_max), axis=<span class="number">0</span>))</span><br><span class="line">    q = np.exp(q)</span><br><span class="line">    <span class="keyword">return</span> q</span><br></pre></td></tr></table></figure>
</li>
<li><p>M步</p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">def run_m_step(X, <span class="keyword">q</span>, w):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    Estimates F, B, s, a given esitmate of posteriors defined by q.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    X : array, shape (H, W, K)</span></span><br><span class="line"><span class="string">        K images of size H x W.</span></span><br><span class="line"><span class="string">    q  :</span></span><br><span class="line"><span class="string">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class="line"><span class="string">                   of prankster's face given image Xk</span></span><br><span class="line"><span class="string">    w : int</span></span><br><span class="line"><span class="string">        Face mask width.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    F : array, shape (H, w)</span></span><br><span class="line"><span class="string">        Estimate of prankster's face.</span></span><br><span class="line"><span class="string">    B : array, shape (H, W)</span></span><br><span class="line"><span class="string">        Estimate of background.</span></span><br><span class="line"><span class="string">    s : float</span></span><br><span class="line"><span class="string">        Estimate of standard deviation of Gaussian noise.</span></span><br><span class="line"><span class="string">    a : array, shape (W-w+1)</span></span><br><span class="line"><span class="string">        Estimate of prior on position of face in any image.</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="comment"># your code here</span></span><br><span class="line">    H, W, K = X.shape</span><br><span class="line">    F = np.zeros((H, w))</span><br><span class="line">    B = np.zeros((H, W))</span><br><span class="line">    <span class="keyword">s</span> = <span class="number">0</span>.<span class="number">0</span></span><br><span class="line">    <span class="comment"># a</span></span><br><span class="line">    a = np.sum(<span class="keyword">q</span>, axis=<span class="number">1</span>)/np.sum(<span class="keyword">q</span>)</span><br><span class="line">    <span class="comment"># F</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">m</span> in range(w):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            F[:, <span class="keyword">m</span>] = (<span class="number">1</span>/K*np.sum(<span class="string">q[:, k]</span>*X[:, <span class="keyword">m</span>:W-w+<span class="number">1</span>+<span class="keyword">m</span>, k], axis=<span class="number">1</span>)) + F[:, <span class="keyword">m</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># B</span></span><br><span class="line">    B1 = np.zeros((H, W))</span><br><span class="line">    B2 = np.zeros((H, W))</span><br><span class="line">    <span class="keyword">for</span> dw in range(W-w+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            B1[:, :dw] = <span class="string">q[dw, k]</span> * X[:, :dw, k] + B1[:, :dw]</span><br><span class="line">            B1[:, dw+w:] = <span class="string">q[dw, k]</span> * X[:, dw+w:, k] + B1[:, dw+w:]</span><br><span class="line">            B2[:, :dw] = <span class="string">q[dw, k]</span> + B2[:, :dw]</span><br><span class="line">            B2[:, dw+w:] = <span class="string">q[dw, k]</span> + B2[:, dw+w:]</span><br><span class="line"></span><br><span class="line">    B = B1/B2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># s</span></span><br><span class="line">    s_square = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> dw in range(W-w+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            s_square = <span class="string">q[dw, k]</span> * (np.sum((X[:, :dw, k] - B[:, :dw])**<span class="number">2</span>) + np.sum((X[:, dw:dw+w, k] - F)**<span class="number">2</span>)+ \</span><br><span class="line">            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**<span class="number">2</span>)) + s_square</span><br><span class="line">    <span class="keyword">s</span> = np.sqrt(<span class="number">1</span>/(K*W*H) *  s_square)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> F, B, <span class="keyword">s</span>, a</span><br></pre></td></tr></table></figure>
</li>
<li><p>对&amp;E&amp;步与&amp;M&amp;步交替运行，当$L(q, \,F, \,B, \,s, \,a)$增加值小于提前设定好的阈值时，程序结束。</p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">def run_m_step(X, <span class="keyword">q</span>, w):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    Estimates F, B, s, a given esitmate of posteriors defined by q.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    X : array, shape (H, W, K)</span></span><br><span class="line"><span class="string">        K images of size H x W.</span></span><br><span class="line"><span class="string">    q  :</span></span><br><span class="line"><span class="string">        q[dw, k] - estimate of posterior of position dw</span></span><br><span class="line"><span class="string">                   of prankster's face given image Xk</span></span><br><span class="line"><span class="string">    w : int</span></span><br><span class="line"><span class="string">        Face mask width.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    F : array, shape (H, w)</span></span><br><span class="line"><span class="string">        Estimate of prankster's face.</span></span><br><span class="line"><span class="string">    B : array, shape (H, W)</span></span><br><span class="line"><span class="string">        Estimate of background.</span></span><br><span class="line"><span class="string">    s : float</span></span><br><span class="line"><span class="string">        Estimate of standard deviation of Gaussian noise.</span></span><br><span class="line"><span class="string">    a : array, shape (W-w+1)</span></span><br><span class="line"><span class="string">        Estimate of prior on position of face in any image.</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="comment"># your code here</span></span><br><span class="line">    H, W, K = X.shape</span><br><span class="line">    F = np.zeros((H, w))</span><br><span class="line">    B = np.zeros((H, W))</span><br><span class="line">    <span class="keyword">s</span> = <span class="number">0</span>.<span class="number">0</span></span><br><span class="line">    <span class="comment"># a</span></span><br><span class="line">    a = np.sum(<span class="keyword">q</span>, axis=<span class="number">1</span>)/np.sum(<span class="keyword">q</span>)</span><br><span class="line">    <span class="comment"># F</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">m</span> in range(w):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            F[:, <span class="keyword">m</span>] = (<span class="number">1</span>/K*np.sum(<span class="string">q[:, k]</span>*X[:, <span class="keyword">m</span>:W-w+<span class="number">1</span>+<span class="keyword">m</span>, k], axis=<span class="number">1</span>)) + F[:, <span class="keyword">m</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># B</span></span><br><span class="line">    B1 = np.zeros((H, W))</span><br><span class="line">    B2 = np.zeros((H, W))</span><br><span class="line">    <span class="keyword">for</span> dw in range(W-w+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            B1[:, :dw] = <span class="string">q[dw, k]</span> * X[:, :dw, k] + B1[:, :dw]</span><br><span class="line">            B1[:, dw+w:] = <span class="string">q[dw, k]</span> * X[:, dw+w:, k] + B1[:, dw+w:]</span><br><span class="line">            B2[:, :dw] = <span class="string">q[dw, k]</span> + B2[:, :dw]</span><br><span class="line">            B2[:, dw+w:] = <span class="string">q[dw, k]</span> + B2[:, dw+w:]</span><br><span class="line"></span><br><span class="line">    B = B1/B2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># s</span></span><br><span class="line">    s_square = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> dw in range(W-w+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> k in range(K):</span><br><span class="line">            s_square = <span class="string">q[dw, k]</span> * (np.sum((X[:, :dw, k] - B[:, :dw])**<span class="number">2</span>) + np.sum((X[:, dw:dw+w, k] - F)**<span class="number">2</span>)+ \</span><br><span class="line">            np.sum((X[:, dw+w:, k] - B[:, dw+w:])**<span class="number">2</span>)) + s_square</span><br><span class="line">    <span class="keyword">s</span> = np.sqrt(<span class="number">1</span>/(K*W*H) *  s_square)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> F, B, <span class="keyword">s</span>, a</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>最终实验结果，人脸图片和背景图如下所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E4%BA%BA%E8%84%B81.png" alt="">  <img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/EM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E8%83%8C%E6%99%AF1.png" alt=""></p>
<h1 id="问题与总结"><a href="#问题与总结" class="headerlink" title="问题与总结"></a>问题与总结</h1><p>变成中遇到了一个问题，就是求解q时会出现0的情况，这样就会导致$log\ 0$的情况出现，出现错误，不知道怎么结果，但是结果却可以跑出了，不过图片并不是特别清晰，我想如果用deep learning的方法训练估计可以达到一个比较好的结果。EM算法可以看成特殊的坐标下降发，对lower bound按照隐变量和参数进行坐标寻优。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] <a href="http://deepbayes.ru/" target="_blank" rel="noopener">http://deepbayes.ru/</a> 主要来自其中的slide<br>[2] <a href="https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start" target="_blank" rel="noopener">https://cw.fel.cvut.cz/old/courses/ae4b33rpz/labs/12_em/start</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/31/VGG16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/31/VGG16/" itemprop="url">VGGNet</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-31T17:43:18+08:00">
                2018-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VGGNet模型结构"><a href="#VGGNet模型结构" class="headerlink" title="VGGNet模型结构"></a>VGGNet模型结构</h1><p>VGGNet是牛津大学视觉组(Visual Geometry Group)和Google DeepMind公司研究员共同研究出的深度卷积神经网络。VGGNet使用的比较小的卷积核(3x3)以及2x2的最大池化层，通过增加层数增强非线性性能，同时相较于7x7的卷积核而言，减少了参数。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/vgg16.jpg" alt=""></p>
<h2 id="VGG16模型处理过程"><a href="#VGG16模型处理过程" class="headerlink" title="VGG16模型处理过程"></a>VGG16模型处理过程</h2><p>以上面图的D为例，下面简要的阐述VGGNet模型的处理过程。</p>
<ol>
<li>输入224x224x3的图片，经过64个3x3的卷积核做两次卷积+ReLU，变成224x224x64。</li>
<li>做MaxPool，池化尺寸为2x2，步长(stride)为2。</li>
<li>经过128个3x3的卷积核做两次卷积+ReLU，尺寸变为112x112x128。</li>
<li>MaxPool，尺寸变为56x56x128。</li>
<li>256个3x3的卷积核做三次卷积+ReLU，尺寸变为56x56x256。</li>
<li>MaxPool，尺寸变为28x28x256。</li>
<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为28x28x512。</li>
<li>MaxPool，尺寸变为14x14x512。</li>
<li>经512个3x3的卷积核做三次卷积+ReLU，尺寸变为14x14x512。</li>
<li>MaxPool，尺寸变为7x7x512。</li>
<li>与两层1x1x4096，一层1x1x1000进行全连接+ReLU(共三层)。</li>
<li>通过softmax输出1000个预测结果。<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG16%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B.png" alt=""><br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/VGG%E5%8F%82%E6%95%B0.png" alt=""></li>
</ol>
<h1 id="利用VGG19实现火灾分类"><a href="#利用VGG19实现火灾分类" class="headerlink" title="利用VGG19实现火灾分类"></a>利用VGG19实现火灾分类</h1><p>主要参考[1]中的代码，另外我将自己跑出的结果贴在了我的github上，具体地址为<a href="https://github.com/hjyai94/VGG" target="_blank" rel="noopener">[4]</a>。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cnblogs.com/vipyoumay/p/7884472.html" target="_blank" rel="noopener">http://www.cnblogs.com/vipyoumay/p/7884472.html</a><br>[2] <a href="https://my.oschina.net/u/876354/blog/1634322" target="_blank" rel="noopener">https://my.oschina.net/u/876354/blog/1634322</a><br>[3] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.<br>[4] <a href="https://github.com/hjyai94/VGG" target="_blank" rel="noopener">https://github.com/hjyai94/VGG</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/19/MC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/MC/" itemprop="url">MC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T15:00:18+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Point-estimator"><a href="#Point-estimator" class="headerlink" title="Point estimator"></a>Point estimator</h1><p>当我们已经获得模型时，我们希望能够估计出模型的参数，这是可以使用点估计的方法。<br>共轭先验：在给定似然函数的情况下，先验分布与后验分布时同种分布。</p>
<h1 id="MC方法"><a href="#MC方法" class="headerlink" title="MC方法"></a>MC方法</h1><p>为了进行估计复杂后验分布，通过采样的方法对后验概率进行估计。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/19/variational-inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/variational-inference/" itemprop="url">variational inference</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T11:15:17+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p># </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/11/cs131笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/11/cs131笔记/" itemprop="url">cs131笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-11T14:31:40+08:00">
                2018-07-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>filtering<br>Forming a new image whose pixel values are transformed from original pixel values.</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/14/Ubuntu中出现的问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/14/Ubuntu中出现的问题/" itemprop="url">记录Ubuntu中出现的问题及解决方案</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-14T00:00:00+08:00">
                2018-06-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/技术/" itemprop="url" rel="index">
                    <span itemprop="name">技术</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="执行sudo-apt-get-update-出错"><a href="#执行sudo-apt-get-update-出错" class="headerlink" title="执行sudo apt-get update 出错"></a>执行sudo apt-get update 出错</h1><p>出现错误如下：<br><code>E: Some index files failed to download, they have been ignored, or old ones used instead&#39;
出现无法更新的情况，可以在</code>/etc/apt/sources.list.d`中删除对应错误名字的文件。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/10/高斯图模型图和伊辛图模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/10/高斯图模型图和伊辛图模型/" itemprop="url">高斯图模型图和伊辛图模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-10T11:01:03+08:00">
                2018-06-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>不同于最大似然估计对于贝叶斯网的估计，有向图中，网络结构通常是已知的，我们需要做的是将参数学习出来或者是对于变量进行推断。无向图中则并不是这样，无向图中，很多模型的结构并不是完全清楚的，需要我们队模型结构进行推断。</p>
<h1 id="高斯图模型"><a href="#高斯图模型" class="headerlink" title="高斯图模型"></a>高斯图模型</h1><p>高斯图模型是马尔科夫随机场的成对形式，同样也是满足高斯正态分布：<br>$$ p(x\mid \mu, \Sigma) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp[-\frac{1}{2}(x-\mu)^T \Sigma^{-T}(x-\mu)] $$<br>其中$\mu$是均值，$\Sigma$是协方差矩阵。令$\mu=0$和精度矩阵为$Q=\Sigma^{-1}$，有：<br>$$ p(x_1, x_2, …, x_p\mid \mu=0, Q) = \frac{|Q|^{1/2}}{(2\pi)^{n/2}}exp[-\frac{1}{2}\sum_i q_{ii}(x_i)^2 - \sum_{i&lt;j}q_{ij}x_ix_j] $$<br>这就是条件随机场，定义于成对边和节点上。</p>
<h1 id="协方差矩阵与精度矩阵"><a href="#协方差矩阵与精度矩阵" class="headerlink" title="协方差矩阵与精度矩阵"></a>协方差矩阵与精度矩阵</h1><p>协方差矩阵有一个重要的性质是：当$\Sigma_{i,j}=0$有$x_i\perp x_j$；逆协方差矩阵（精度矩阵）的对应的性质为：当$\Sigma_{i,j}^{-1}=0$时$x_i\perp x_j\mid x_{-ij}$。</p>
<h1 id="利用LASSO进行网络学习"><a href="#利用LASSO进行网络学习" class="headerlink" title="利用LASSO进行网络学习"></a>利用LASSO进行网络学习</h1><h2 id="LASSO回归"><a href="#LASSO回归" class="headerlink" title="LASSO回归"></a>LASSO回归</h2><p>对于网络结构的学习，我们通常是假设网络是稀疏的。LASSO回归可以用于网络的近邻选择，去除不必要的节点之间的连接。<br>$$\hat{\beta_1} = argmin_{\beta_1}\parallel Y - X\beta_1\parallel^2 + \lambda\parallel\beta_1\parallel_1$$<br>其中，$\beta_1$是节点1的参数，Y是是对节点1的独立观测值。<br>具体过程如图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/LASSO%E5%9B%9E%E5%BD%92.png" alt=""></p>
<h2 id="理论条件"><a href="#理论条件" class="headerlink" title="理论条件"></a>理论条件</h2><ul>
<li>Dependency Condition: Relevant Covariates are not overly dependent</li>
<li>Incoherence Condition: Large number of irrelevant covariates can’t be too correlated with relevant covariates</li>
<li>Strong concentration bounds: Sample quantities coverge to expected values quickly</li>
</ul>
<h1 id="时变网络"><a href="#时变网络" class="headerlink" title="时变网络"></a>时变网络</h1><h2 id="KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression"><a href="#KELLER-Kernel-Weightd-L-1-regularized-logistic-Regression" class="headerlink" title="KELLER: Kernel Weightd $L_1$-regularized logistic Regression"></a>KELLER: Kernel Weightd $L_1$-regularized logistic Regression</h2><p>对时变网络的结构进行估计，可以采用KELLER的方法解决：<br>$$ \hat{\theta_i^t} = argmain_{\theta_i^t}l_w(\theta_i^t) + \lambda_1\parallel\theta_t^t \parallel_1 $$<br>其中$l_w(\theta_i^t) = \sum_{t’=1}^T w(x^{t’}; x^t)log\ P(x_i^{t’}\mid x_{-i} x^{t’}, \theta_i^t)$。权值$w(x^{t’}; x^t)$决定了在时间$t’$和$t$之间的关系，我们可以将其建模为一个分布(如下图)。<br><img src="" alt=""><br>给定时间$t^{\ast}$，权值可以写成：<br>$$ w_t(t^{\ast}) = \frac{K_{h_n}(t-t^{\ast})}{\sigma_{t’\in T^n} K_{h_n}(t’-t^{\ast})} $$<br>对于一些平滑的核$K_{h_n}$。</p>
<h2 id="TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression"><a href="#TESLA-Temporally-Smoothed-L-1-regularized-logistic-regression" class="headerlink" title="TESLA: Temporally Smoothed $L_1$-regularized logistic regression"></a>TESLA: Temporally Smoothed $L_1$-regularized logistic regression</h2><p>TESLA对于一个节点的参数优化是基于所有的时间步的：<br>$$ \hat{\theta_i^T}, …, \hat{\theta_i^T} = argmin\sum_{i=1}^T l_{avg}(\theta_i^t) + \lambda_1 \sum_{t=1}^T \parallel\theta_{-1}^t \parallel_1 + \lambda_2\sum_{t=1}^T \parallel \theta_i^t - \theta_i^{t-1} \parallel $$<br>其中，$l_{avg}(\theta_i^t) = \frac{1}{N^t}\sum_{d=1}^{N^t} log\ P(x_{d,i}^t\mid x_{d, -i}^t, \theta_i^t) $是条件对数似然。不同于KELLER，当节点数达到5000时，这里我们不需要平滑Kernels，这里可以接受突变。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/31/HMM和CRF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HJY">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HJY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/31/HMM和CRF/" itemprop="url">HMM和CRF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-31T09:49:19+08:00">
                2018-05-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h1><p>隐马尔可夫模型如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<h2 id="公式表达"><a href="#公式表达" class="headerlink" title="公式表达"></a>公式表达</h2><p>对于隐马尔可夫模型，通常有三组参数：<br>$$ trasition\ probability\ matrix\ A: p(y_t^j = 1\mid y_{t-1}^i=1)=a_{i,j} $$   $$ initial\ probability: p(y_1)\sim Multinomial(\pi_1, \pi_2, …, \pi_M) $$    $$ emission\ probabilies: p(x_t\mid y_t^i)\sim Multinomial(b_{i,1}, b_{i,2}, …, b_{i,K}) $$</p>
<h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><ul>
<li><p>前向算法<br>$$ \alpha_t^k \equiv\mu_{t-1\rightarrow}(k)=P(x_1, x_2, …, x_t, y_t^k=1) $$<br>$$ \alpha_t^k = p(x_t\mid y_t^k=1)\sum_i \alpha_{t-1}^ia_{i,k} $$</p>
</li>
<li><p>后向算法<br>$$ \beta_t^k \equiv \mu_{t\leftarrow t+1}(k)=P(x_{t+1}, …, x_T\mid y_t^k=1) $$<br>$$ \beta_t^k = \sum_i a_{k,i}p(x_{t+1}\mid y_{t+1}^i = 1)\beta_{t+1}^i $$</p>
</li>
</ul>
<p>对于给定观测值下的任意隐变量状态，可以同过点乘前向和后向信息得到。<br>$$ \gamma_t^i = p(y_t^i = 1\mid x_{1:T})\propto \alpha_t^i\beta_t^i =\sum_j \xi_t^{i,j} $$<br>其中有定义：<br>\begin{equation}\begin{split} \xi_t^{i,j} &amp;= p(y_t^i=1,y_{t-1}^j=1, x_{1:T}) \\<br>&amp;\propto \mu_{t-1\rightarrow t}(y_t^i=1)\mu_{t\leftarrow t+1}(y_{t+1}^i=1)p(x_{x+1}\mid y_{t+1})p(y_{t+1}\mid y_t) \\<br>&amp;= \alpha_t^i\beta_{t+1}^j a_{i,j} p(x_{t+1}\mid y_{t+1}^i=1) \\<br>\end{split}\end{equation}<br>具体推导可以参考Youtube上徐亦达老师关于HMM的视频，主要思路就是message passing，运用一些迭代地技巧，可以先从最小的下标开始推导，这样比较容易发现规律，类似于数学归纳法。<br>在Matlab中可以将公式用向量表示，这样方便处理。<br>\begin{equation}\begin{split} &amp;B_t(i)=p(x_t\mid y_t^i=1)\\<br>&amp; A(i,j)=p(y_{t+1}^j=1\mid y_t^i=1) \\<br>&amp; \alpha_t = (A^T\alpha_{t-1}).\ast B_t \\<br>&amp; \beta_t = A(\beta_{t+1}.\ast B_{t+1}) \\<br>&amp; \xi_t = (\alpha_t(\beta_{t+1}.\ast B_{t+1})^T).\ast A  \\<br>&amp; \gamma_t = \alpha_t.\ast \beta_t \\<br>\end{split}\end{equation}</p>
<h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>当我们知道实际状态路径时，监督学习并不是一件困难的事情(trival)，我们只需要数出转移概率和发射概率的实例就可以得到最大似然估计。<br>$$ a_{ij}^{ML} = \frac{\sum_n\sum_{t=2}^T y_{n,t-1}^i y_{n,t}^j}{\sum_n\sum_{t=2}^T y_{n,t-1}^i} $$<br>$$ b_{ik}^{ML} = \frac{\sum_n\sum_{t=2}^T y_{n,t}^i x_{n,t}^k}{\sum_n\sum_{t=2}^T y_{n,t}^i} $$<br>使用了伪计数的方式，可以避免零概率的出现。对于不是多项分布的情况，特别是高斯分布，我们可以利用采样的方法计算均值和方差。</p>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>当隐状态不可观的时候，可以使用Baum Welch算法进行处理完全对数似然函数，这一算法就是EM算法对HMM的求解方法。似然函数可以写成：<br>$$ l_c(\theta;x,y)=lop\ p(x,y)=log\prod_n (p(y_{n,1})\prod_{t=1}^T p(y_{n,t}\mid y_{n,t-1})\prod_{t=1}^T p(x_{n,t}\mid y_{n,t})) $$<br>完全对数似然期望是：<br>$$ \langle l_c(\theta;x,y)\rangle = \sum_n (\langle y_{n,1}^i \rangle_{p(y_{n,1}\mid x_n)}log\ \pi_i) + \sum_n\sum_{t=2}^T (\langle y_{n,t-1}^i y_{n,t}^j\rangle_{p(y_{n,t-1},y_{n,t}\mid x_n)}log\ a_{i,j}) + \sum_n\sum_{t=1}^T (x_{n,t}^k\langle y_{n,t}^i\rangle_{p(y_{n,t}\mid x_n)}log\ b_{i,k}) $$</p>
<ul>
<li>E步：<br>$$ \gamma_{n,t}^i = \langle  y_{n,t}^i\rangle = p(y_{n,t}^i = 1\mid x_n) $$    $$ \xi_{n,t}^{i,j} = \langle y_{n,t-1}^i y_{n,t}^j\rangle = p(y_{n,t-1}^i=1, y_{n,t}^j=1\mid x_n) $$</li>
<li>M步：<br>$$ \pi_i=\frac{\sum_n \gamma_{n,1}^i}{N}, a_{i,j}=\frac{\sum_n\xi_{n,t}^{i,j}} {\sum_n\sum_{t=1}^{i,j} \gamma_{n,t}^i},  b_{ik}=\frac{\sum_N\sum_{t=1}^T \gamma_{n,t}^i x_{n,t}^k} {\sum_n\sum_{t=1}^{T-1}\gamma_{n,t}^i} $$</li>
</ul>
<h3 id="HMM的缺点"><a href="#HMM的缺点" class="headerlink" title="HMM的缺点"></a>HMM的缺点</h3><p>HMM的缺点也是HMM的最要特征，就是每个观测值只与一个隐状态相关，与其他状态都无关。另外就是预测目标函数与学习目标函数不一致，HMM学习状态和观测值的联合概率$P(Y,X)$，但是我们的预测要求是需要条件概率$P(Y\mid X)$，通过这样的考虑，有了一个新的模型MEMM。</p>
<h1 id="MEMM"><a href="#MEMM" class="headerlink" title="MEMM"></a>MEMM</h1><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>MEMM结构如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/MEMM.png" alt=""><br>MEMM的主要特点是，模型中的每个状态都与所有的观测值相关，同时模型是一个判别模型。<br>$$ P(y_{1:n}\mid x_{1:n}) = \prod_{i=1}^{n} P(y_i\mid y_{i-1},x_{1:n}) = \prod_{i=1}^n \frac{exp(W^T f(y_i,y_{i-1}, x_{1:n}))}{Z(y_{i-1}, x_{1:n})} $$</p>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>MEMM存在着标注偏置的问题(label bias preblem)，主要是因为状态转移的路径多少的问题，MEMM中的状态倾向于转移到转移状态路径少的状态，因为转移路径少的状态总能提供较大的转移概率。</p>
<h1 id="CRF"><a href="#CRF" class="headerlink" title="CRF"></a>CRF</h1><p>一个比较好的方法解决上面的问题就是改变原来的概率转移的方式，用势函数取代概率来表征局部的信息。</p>
<h2 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h2><p>CRF结构如下图所示：<br><img src="https://raw.githubusercontent.com/hjyai94/Blog/master/source/uploads/CRF.png" alt=""><br>\begin{equation}\begin{split} P(Y\mid X) &amp;= \frac{1}{Z(X)}\prod_{i=1}^n \phi(y_i,y_{i-1},X) \\<br>&amp;= \frac{1}{Z(X, \lambda, \mu)}exp(\sum_{i=1}^T(\sum_k \lambda_k f_k(y_i, y_{i-1}, X) + \sum_l \mu_l g_l(y_i, X))) \\<br>\end{split}\end{equation}<br>其中，$Z(X,\lambda, \mu)=\sum_y exp(\sum_{i=1}(\sum_k \lambda_k f_k(y_i, y_{i-1}, X) + \sum_l \mu_l g_l (y_i, X))) $，可以看出其中的正规因子是全局的，并不是局部的，这样就保证了对局部信息的处理具有全局一致性。</p>
<p>##　推断<br>所谓的推断问题就是在CRF给定参数$\lambda$和$\mu$，我们可以找到$y^{\ast}$使得$P(y\mid x)$最大。<br>$$ y^{\ast} = argmax_y exp(\sum_{i=1}^n (\sum_k \lambda_k f_k (y_i, y_{i-1}, X) + \sum_l \mu_l g_l (y_i, X))) $$<br>因为Z与y无关，最大值与y无关。为了解决优化问题，我们可以使用最大积算法在CRF上，这样类似了Viteerbi算法在HMM上的应用。</p>
<h2 id="学习-1"><a href="#学习-1" class="headerlink" title="学习"></a>学习</h2><p>尽管整个图都是可观的，CRF的学习问题仍然是比较难于解决的。原因是学习中需要进行推断。给定训练集$\lbrace x_d, y_d\rbrace_{d=1}^N$，寻找到最优的$\lambda^{\ast}$和$\mu^{\ast}$。<br>\begin{equation}\begin{split} \lambda^{\ast}, \mu^{\ast} &amp;= argmax_{\lambda, \mu}\prod_{d=1}^N P(y_d\mid x_d, \lambda, \mu) \\<br>&amp;= argmax_{\lambda, \mu}\prod_{d=1}^N \frac{1}{Z(x_d, \lambda, \mu)}exp(\sum_{i=1}^n (\lambda^T f(y_{d, i} y_{d, i-1}, x_d) + \mu^T g(y_{d,i}, x_d))) \\<br>&amp;= argmax_{\lambda, \mu}\sum_{d=1}^T (\sum_{i=1}^n(\lambda^T f(y_{d,i}, y_{d, i-1}) + \mu^T g(y_{d, i}, x_d)) - log\ Z(x_d, \lambda, \mu)) \\<br>\end{split}\end{equation}<br>对$\lambda$求偏导：<br>$$ \Delta_{\lambda}L(\lambda, \mu) = \sum_{d=1}^N(\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \sum_y (P(y\mid x_d) \sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d))) $$<br>从上式中可以看出第一项是特征值，第二项是特征值的期望，另外对数判分函数以指数族的形式呈现时，其梯度是特征值的期望。<br>解决上面的式子需要处理指数级数量的数据求和，我们可以利用message passing算法来计算对势，这样得到一个闭环的形式。<br>\begin{equation}\begin{split} \sum_y (P(y\mid x_d)\sum_{i=1}^n f(y_i, y_{i-1}, x_d)) &amp;= \sum_{i=1}^n(\sum_y f(y_i, y_{i-1}, x_d) P(y\mid x_d)) \\<br>&amp;= \sum_{i=1}^n(\sum_{y_i, y_{i-1}} f(y_i, y_{i-1}, x_d) P(y_i, y_{i-1}\mid x_d)) \\<br>\end{split}\end{equation}<br>这样意味着，学习过程中包含有推断过程，通过message passing算法，学习过程只需要多项式时间久可以完成。<br>下面使用校准势来计算特征期望：<br>\begin{equation}\begin{split} \Delta_{\lambda}L(\lambda, \mu) &amp;= \sum_{d=1}^N(\sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d) - \sum_y (P(y\mid x_d) \sum_{i=1}^n f(y_{d, i}, y_{d, i-1}, x_d)))  \\<br>&amp;= \sum_{d=1}^N(\sum_{i=1}^n f(y_{d,i}, y_{d,i-1】， x_d} - \sum_{y_i, y_{i-1}}\alpha’(y_i, y_{i-1}) f(y_d, y_{d, i-1}, x_d))) \\<br>\end{split}\end{equation}<br>其中$\alpha’(y_i, y_{i-1}, x_d) = P(y_i, y_{i-1}\mid x_d)$。我们可以使用梯度上升法学习参数。<br>$$ \lambda^{(t+1)} = \lambda^{(t)} + \eta\Delta_{\lambda}L(\lambda^{(t)}, \mu^{(t)}) $$     $$ \mu^{(t+1)} = \mu^{(t)} + \eta\Delta_{\mu}L(\lambda^{(t)}, \mu^{(t)}) $$<br>在实际中，我们会加入正则项来提高参数的泛化能力。<br>$$ \lambda^{\ast}, \mu^{\ast} = argmax_{\lambda, \mu}\sum_{d=1}^N log\ P(y_d\mid x_d, \lambda, \mu) - \frac{1}{2\sigma^2} (\lambda^T \lambda + \mu^T\mu) $$<br>第二项叫做高斯先验，因为我们想让$\lambda^{\ast},\mu^{\ast}$趋近于0,这样可以减少特征值的数量。第二项也能叫做拉普拉斯先验，在条件概率中，我们不想看到零概率出现，因为零概率是病态的。梯度上升法收敛速度较慢，以使用共轭梯度法和拟牛顿法来加快速度。<br>从经验的表现来看，CRF比HMM和MEMM有所提升，特别是当非局部的影响明显时。虽然提升不够明显，但是CRF为一系列的问题的解决提供了很好的范例。CRF的另一优点是能够让使用者灵活的自己设计随机特征。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>EM算法适应于处理存在隐变量的最大似然估计问题。</li>
<li>GMM和HMM被用于对静态和动态混合模型建模。</li>
<li>实现HMM主要需要处理的问题是，学习，推断和最大似然。推断可以通过前向和后向算法(变量去除)实现；最大似然问题可以通过Viterbi算法(最大积)实现；学习问题可以通过直接最大似然后者EM算法解决。</li>
<li>HMM具有十分强的马尔科夫性。HMM只能获得局部的关系，对于HMM的扩展MEMM，MEMM可以获得状态和全部可观序列之间的显性关系。但是，MEMM存在着标注偏置的问题。</li>
<li>CRF是部分有向的模型，其中转态之间是无向的，CRF使用全局的正规项克服了MEMM的标注偏置的问题。对于线性链式CRF，精确推断并不是困难的。推断问题可以通过最大积算法通过junction tree解决。学习问题可以通过梯度上升来解决最大似然。</li>
<li>具有任意图结构的CRF，精确推断就是比较困难的事情，这时就需要近似推断了，比如：采样，变分推断，loopy belief propagation。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>[2] Wallach H M. Conditional random fields: An introduction[J]. Technical Reports (CIS), 2004: 22.<br>注：本文主要参考[1]中第12讲视频以及笔记。另外，本文中公式的和全部采用\sum，本文之前使用的都是\Sigma，后面也会使用\sum。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="HJY" />
            
              <p class="site-author-name" itemprop="name">HJY</p>
              <p class="site-description motion-element" itemprop="description">HJY的装逼小站</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hjyai94" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HJY</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.3"></script>



  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
